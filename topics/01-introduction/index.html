<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>01. Introduction to Convex Optimization — Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/modern-widgets.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
</head>
<body class="dark-theme">
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">
          <img src="../../static/assets/branding/logo.svg" alt="Logo" class="logo"/>
          <span>Convex Optimization</span>
        </a>
      </div>
      <nav class="nav">
        <a href="../../index.html">All Lectures</a>
        <a href="../00-linear-algebra-primer/index.html">← Previous</a>
        <a href="../02-convex-sets/index.html">Next →</a>
      </nav>
    </div>
  </header>

  <div class="lecture-container">
    <aside class="sidebar">
      <div id="toc-container">
        <h2>Table of Contents</h2>
        <nav id="toc"></nav>
      </div>
    </aside>
    <main class="lecture-content">
      <header class="lecture-header card">
        <h1>01. Introduction: The What, Why, and How of Convex Optimization</h1>
        <div class="lecture-meta">
          <span>Date: 2025-10-21</span>
          <span>Duration: 90 min</span>
          <span>Tags: intro, motivation, overview, modeling</span>
        </div>
        <div class="lecture-summary">
          <p><strong>Overview:</strong> This lecture introduces convex optimization by defining what makes a problem "convex" and proving that any local minimum is also global. We examine the canonical problem families (LP, QP, SOCP, SDP) and present the "loss + regularizer + constraints" modeling framework.</p>
          <p><strong>Prerequisites:</strong> <a href="../00-linear-algebra-primer/index.html">Lecture 00: Linear Algebra Primer</a> is required, particularly projections, PSD matrices, and norms.</p>
          <p><strong>Forward Connections:</strong> Least squares and QP examples build on projection theory from <a href="../00-linear-algebra-primer/index.html">Lecture 00</a>. Feasible sets introduced here connect to geometric concepts in <a href="../02-convex-sets/index.html">Lecture 02</a>.</p>
        </div>
      </header>

      <section class="card">
        <h2>Learning Objectives</h2>
        <ul>
          <li><b>Define Convex Problems:</b> Articulate the precise three-part definition and distinguish convex from nonconvex problems.</li>
          <li><b>Prove Global Optimality:</b> Show that every local minimum is global, and understand why this property fundamentally changes optimization.</li>
          <li><b>Recognize Canonical Families:</b> Identify LP, QP, SOCP, SDP by sight and know which real-world scenarios each family models.</li>
          <li><b>Apply Loss + Regularizer Paradigm:</b> Formulate problems using the "loss + regularizer + constraints" template and explain the bias-variance tradeoff.</li>
          <li><b>Use Safe Rewrites:</b> Transform norms, absolute values, and max functions into standard convex forms.</li>
          <li><b>Formulate and Sanity-Check:</b> Translate real-world problems to mathematical form, verify feasibility, and check for unboundedness.</li>
          <li><b>Understand the Solver Workflow:</b> Grasp the "formulate → canonicalize → solve → verify" pipeline.</li>
        </ul>
      </section>

      <article>
        <section class="card" id="section-1">
          <h2>1. What is a Convex Optimization Problem?</h2>
          <p>In the vast landscape of optimization, problems divide into two categories: <b>convex</b> and <b>nonconvex</b>. This is not arbitrary—it's the fundamental line between problems we can solve efficiently and reliably, and those we generally cannot.</p>
          <figure>
            <img src="../../static/assets/topics/01-introduction/optimization-schematic.png" alt="Schematic overview of the optimization problem landscape" />
            <figcaption>Figure 1.1: The optimization landscape—convex vs. nonconvex problems.</figcaption>
          </figure>
          <h3>Formal Definition</h3>
          <p>An optimization problem is <b>convex</b> if it can be written in the form:</p>
          $$
          \begin{aligned}
          \min_{x \in \mathbb{R}^n} \quad & f_0(x) && \text{(Objective)} \\
          \text{subject to} \quad & f_i(x) \le 0, && i=1,\dots,m \quad \text{(Inequalities)}\\
          & Ax = b && \text{(Equalities)}
          \end{aligned}
          $$
          <p>where <b>three critical conditions</b> are met:</p>
          <ol>
            <li>The objective function $f_0$ is a <b>convex function</b>.</li>
            <li>All inequality constraint functions $f_i$ are <b>convex functions</b>.</li>
            <li>All equality constraints are <b>affine</b> (i.e., of the form $Ax = b$).</li>
          </ol>
        </section>

        <section class="card" id="section-2">
          <h2>2. The Crown Jewel: Local = Global</h2>
          <p>This property is what makes convex optimization fundamentally different from general optimization. In nonconvex problems, algorithms can get stuck in local minima, but for convex problems, any local minimum is guaranteed to be the global solution.</p>
          <figure>
            <img src="../../static/assets/topics/01-introduction/convex_function_chord.gif" alt="Animated visualization of the chord property for convex functions" />
            <figcaption>Figure 2.1: Animation showing how the chord between any two points stays above a convex function's graph.</figcaption>
          </figure>
        </section>

        <section class="card" id="section-3">
          <h2>3. Canonical Problem Families</h2>
          <p>A vast number of real-world models reduce to one of a few standard forms. Recognizing them is a crucial modeling skill.</p>
          <figure>
            <img src="../../static/assets/topics/01-introduction/hierarchy-of-convex-optimization-problems-dark.svg" alt="Hierarchy diagram showing relationships between LP, QP, SOCP, and SDP" />
            <figcaption>Figure 3.1: The hierarchy of convex optimization problems.</figcaption>
          </figure>
          <div class="subsection">
              <h3>3.1 Linear Program (LP)</h3>
              <p>An LP has a linear objective and linear constraints. The feasible set is a polyhedron, and the solution is always at a vertex.</p>
              $$ \min_x\ c^\top x \quad \text{s.t. } Ax \le b, \quad Fx = g $$
          </div>
          <div class="subsection">
              <h3>3.2 Quadratic Program (QP)</h3>
              <p>A QP has a convex quadratic objective and linear constraints. The level sets of the objective are ellipsoids.</p>
              $$ \min_x\ \frac{1}{2} x^\top Q x + c^\top x \quad \text{s.t. } Ax \le b, \quad Fx = g, \quad Q \succeq 0 $$
          </div>
          <div class="subsection">
              <h3>3.3 Second-Order Cone Program (SOCP)</h3>
              <p>An SOCP is an LP with additional second-order cone constraints, which involve Euclidean norms.</p>
               $$ \min_x\ c^\top x \quad \text{s.t. } \|A_i x + b_i\|_2 \le c_i^\top x + d_i, \quad Fx = g $$
          </div>
          <div class="subsection">
              <h3>3.4 Semidefinite Program (SDP)</h3>
              <p>In an SDP, the variable is a symmetric matrix that is constrained to be positive semidefinite.</p>
               $$ \min_X\ \langle C, X \rangle \quad \text{s.t. } \langle A_i, X \rangle = b_i, \quad X \succeq 0 $$
          </div>
        </section>

        <section class="card" id="section-4">
          <h2>4. The Loss + Regularizer Paradigm</h2>
          <p>Many problems in statistics and machine learning use this modeling template:</p>
          $$
          \min_x \quad \underbrace{\text{loss}(x; \text{data})}_{\text{Data Fidelity}} + \underbrace{\lambda \cdot \text{regularizer}(x)}_{\text{Model Complexity}}
          $$
          <p>This balances fitting the data (loss) with preventing overfitting (regularizer). The parameter $\lambda \ge 0$ controls the trade-off. Common examples include:</p>
          <ul>
            <li><b>Loss Functions:</b> Least Squares $(\|Ax-b\|_2^2)$, Logistic Loss.</li>
            <li><b>Regularizers:</b> Ridge $(\|x\|_2^2)$, LASSO $(\|x\|_1)$ for promoting sparsity.</li>
          </ul>
        </section>
      </article>

      <section class="card" id="section-5">
        <h2>5. Exercises</h2>
        <div class="problem">
          <h3>Problem 1: Convexity Classification</h3>
          <p>For each problem, state if it is convex and provide a one-sentence justification.</p>
          <ol type="a">
            <li>$\min \|Ax - b\|_2^2$ subject to $Fx = g$.</li>
            <li>$\min -\|x\|_2$ subject to $Ax \le b$.</li>
            <li>$\min \|x\|_1$ subject to $\|Bx - c\|_\infty \le 1$.</li>
            <li>$\min x^\top Q x$ subject to $Dx \le e$, where $Q$ is not guaranteed to be PSD.</li>
            <li>$\min \|x\|_2^2$ subject to $x_i \in \{0, 1\}$ for all $i$.</li>
          </ol>
          <div class="solution">
            <h4>Solutions</h4>
            <ol type="a">
              <li><b>Convex.</b> The objective is a convex quadratic and the constraint is affine.</li>
              <li><b>Not Convex.</b> The objective function, negative of the L2-norm, is concave.</li>
              <li><b>Convex.</b> The objective and the constraint function are both norms, which are convex.</li>
              <li><b>Not Convex.</b> The objective is only guaranteed to be convex if $Q \succeq 0$.</li>
              <li><b>Not Convex.</b> The integer constraint $x_i \in \{0, 1\}$ makes the feasible set non-convex.</li>
            </ol>
          </div>
        </div>
        <div class="problem">
            <h3>Problem 2: Warehouse Placement</h3>
            <p>You are tasked with optimizing the placement of a distribution warehouse. The goal is to minimize the sum of squared Euclidean distances to a set of $k$ retail locations, $r_1, \dots, r_k \in \mathbb{R}^2$. The warehouse must be located within a region defined by the linear inequalities $C x \le d$. Formulate this as a convex optimization problem.</p>
            <div class="solution">
                <h4>Solution</h4>
                <p>Let the warehouse location be $x \in \mathbb{R}^2$. The objective is to minimize the sum of squared distances to the retail locations.</p>
                <p>The objective function is:</p>
                $$ f_0(x) = \sum_{i=1}^{k} \|x - r_i\|_2^2 $$
                This is a convex quadratic function. The constraints are given as $Cx \le d$, which are linear. The problem is a Quadratic Program (QP):
                $$ \min_{x \in \mathbb{R}^2} \sum_{i=1}^{k} \|x - r_i\|_2^2 \quad \text{s.t.} \quad Cx \le d $$
                This is a convex optimization problem.
            </div>
        </div>
      </section>

      <footer class="site-footer">
        <div class="container">
          <p>© <span id="year"></span> Convex Optimization Course</p>
        </div>
      </footer>
    </main>
  </div>

  <div class="theme-switcher">
    <button class="theme-button" id="theme-button">
      <svg class="palette-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2.25c-5.376 0-9.75 4.374-9.75 9.75s4.374 9.75 9.75 9.75 9.75-4.374 9.75-9.75S17.376 2.25 12 2.25zm0 1.5c4.549 0 8.25 3.701 8.25 8.25s-3.701 8.25-8.25 8.25-8.25-3.701-8.25-8.25S7.451 3.75 12 3.75zm0 1.953c-.328 0-.651.031-.966.091 2.893.63 5.021 3.228 5.021 6.206 0 3.52-2.859 6.379-6.379 6.379-.236 0-.469-.013-.695-.038a8.217 8.217 0 007.039-7.04c.025-.226.038-.459.038-.695 0-2.978-2.128-5.576-5.02-6.206.315-.06.638-.091.966-.091z"/></svg>
    </button>
    <div class="theme-options" id="theme-options">
      <button data-theme="dark-theme">Dark</button>
      <button data-theme="light-theme">Light</button>
      <button data-theme="solarized-theme">Solarized</button>
    </div>
  </div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/theme-switcher.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- Widget Loaders -->
  <script type="module">
    import { initConvexCombination } from './widgets/js/convex-combination.js';
    initConvexCombination('widget-convex-combination');
  </script>
  <script type="module">
    import { initConvexVsNonconvex } from './widgets/js/convex-vs-nonconvex.js';
    initConvexVsNonconvex('widget-convex-vs-nonconvex');
  </script>
  <script type="module">
    import { initLandscapeViewer } from './widgets/js/landscape-viewer.js';
    initLandscapeViewer('widget-landscape-viewer');
  </script>
  <script type="module">
    import { initConvergenceComparison } from './widgets/js/convergence-comparison.js';
    initConvergenceComparison('widget-convergence-comparison');
  </script>
  <script type="module">
    import { initProblemFlowchart } from './widgets/js/problem-flowchart.js';
    initProblemFlowchart('widget-problem-flowchart');
  </script>
  <script type="module">
    import { initProblemGallery } from './widgets/js/problem-gallery.js';
    initProblemGallery('widget-problem-gallery');
  </script>
</body>
</html>
