<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>05. Duality: Lagrangian, KKT, Strong Duality ‚Äî Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
</head>
<body>
  <!-- Header with navigation -->
  <header class="site-header">
    <div class="container header-inner">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html">All Lectures</a>
        <a href="#widgets">Interactive</a>
        <a href="#readings">Readings</a>
      </nav>
    </div>
  </header>

  <!-- Main content -->
  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <!-- Lecture header -->
    <article class="section-card" style="margin-bottom: 32px;">
      <h1 style="margin-top: 0;">05. Duality: Lagrangian, KKT, Strong Duality</h1>
      <div class="meta">
        Date: 2025-11-18 ¬∑ Duration: 90 min ¬∑ Tags: duality, theory, KKT, Lagrangian
      </div>

      <!-- Brief introduction -->
      <section style="margin-top: 16px;">
        <p><strong>Overview:</strong> This lecture covers duality theory in convex optimization‚Äîthe mathematical framework that connects every optimization problem to a "dual" problem, establishes optimality conditions, and provides the foundation for modern algorithms. We develop the Lagrangian function, prove weak and strong duality theorems, derive the KKT conditions, and explore applications across problem classes.</p>
        <p><strong>Prerequisites:</strong> <a href="../07-convex-problems-standard/index.html">Lecture 07-08</a> (convex optimization problem formulations), <a href="../06-convex-functions-advanced/index.html">Lecture 06</a> (convex functions and subgradients)</p>
      </section>
    </article>

    <!-- Learning objectives -->
    <section class="section-card" style="margin-bottom: 32px;">
      <h2>Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul style="line-height: 1.8;">
        <li>Construct the Lagrangian function and derive the dual function for any convex problem</li>
        <li>Formulate the dual problem and understand the primal-dual relationship</li>
        <li>Apply weak duality to obtain lower bounds on optimal values</li>
        <li>State and prove strong duality under Slater's condition</li>
        <li>Derive and verify the Karush-Kuhn-Tucker (KKT) optimality conditions</li>
        <li>Use complementary slackness to analyze solution structure</li>
        <li>Interpret dual variables as shadow prices and sensitivity coefficients</li>
        <li>Formulate duals for LP, QP, and SDP problems</li>
      </ul>
    </section>

    <!-- Section 1: The Lagrangian and Dual Function -->
    <section class="section-card" id="section-1">
      <h2>1. The Lagrangian and Dual Function</h2>

      <h3>1.1 The Primal Problem</h3>
      <p>Consider the <strong>primal problem</strong> in standard form:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <p style="margin: 0;">
          $
          \begin{aligned}
          \text{minimize} \quad & f_0(x) \\
          \text{subject to} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
          & h_j(x) = 0, \quad j = 1, \dots, p
          \end{aligned}
          $
        </p>
      </div>

      <p>with variable $x \in \mathbb{R}^n$, optimal value $p^*$, and feasible set $\mathcal{F}$.</p>

      <h3>1.2 The Lagrangian Function</h3>
      <p>The <a href="#" class="definition-link">Lagrangian</a> $L: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is defined as:</p>

      <p style="text-align: center;">
        $
        L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $
      </p>

      <p>where:</p>
      <ul>
        <li>$\lambda \in \mathbb{R}^m$ are the <a href="#" class="definition-link">dual variables</a> (or <strong>Lagrange multipliers</strong>) for inequality constraints</li>
        <li>$\nu \in \mathbb{R}^p$ are the dual variables for equality constraints</li>
        <li>The domain is $\mathcal{D} = \text{dom}(f_0) \cap \bigcap_{i=1}^m \text{dom}(f_i) \cap \bigcap_{j=1}^p \text{dom}(h_j)$</li>
      </ul>

      <p><strong>Intuition:</strong> The Lagrangian augments the objective with weighted constraint violations. It transforms a constrained problem into an unconstrained one by penalizing constraint violations.</p>

      <h3>1.3 The Lagrange Dual Function</h3>
      <p>The <a href="#" class="definition-link">Lagrange dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is:</p>

      <p style="text-align: center;">
        $
        g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) = \inf_{x \in \mathcal{D}} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $
      </p>

      <div class="proof-box">
        <h4>Theorem: Concavity of the Dual Function</h4>
        <p><strong>Statement:</strong> The dual function $g(\lambda, \nu)$ is concave, even if the primal problem is not convex.</p>

        <div class="proof-step">
          <strong>Proof:</strong> For any $(\lambda_1, \nu_1)$ and $(\lambda_2, \nu_2)$, and $\theta \in [0, 1]$:
          $
          \begin{aligned}
          g(\theta \lambda_1 + (1-\theta) \lambda_2, \theta \nu_1 + (1-\theta) \nu_2) &= \inf_x L(x, \theta \lambda_1 + (1-\theta) \lambda_2, \theta \nu_1 + (1-\theta) \nu_2) \\
          &= \inf_x \left[ \theta L(x, \lambda_1, \nu_1) + (1-\theta) L(x, \lambda_2, \nu_2) \right] \\
          &\ge \theta \inf_x L(x, \lambda_1, \nu_1) + (1-\theta) \inf_x L(x, \lambda_2, \nu_2) \\
          &= \theta g(\lambda_1, \nu_1) + (1-\theta) g(\lambda_2, \nu_2)
          \end{aligned}
          $
          Thus $g$ is concave (pointwise infimum of affine functions in $(\lambda, \nu)$).
        </div>
      </div>

      <h3>1.4 Computing the Dual Function</h3>
      <p>To compute $g(\lambda, \nu)$, we minimize the Lagrangian over $x$:</p>
      <ol>
        <li>Form $L(x, \lambda, \nu)$</li>
        <li>Compute $\inf_x L(x, \lambda, \nu)$ (often by setting $\nabla_x L = 0$ if differentiable)</li>
        <li>The result is $g(\lambda, \nu)$</li>
      </ol>

      <p><strong>Example:</strong> For an LP minimize $c^T x$ s.t. $Ax = b$, $x \ge 0$:</p>
      <p style="text-align: center;">
        $
        L(x, \lambda, \nu) = c^\top x - \lambda^\top x + \nu^\top (Ax - b)
        $
      </p>
      <p>Taking $\inf_x$: if $c - \lambda + A^\top \nu \ne 0$, the infimum is $-\infty$. Otherwise, $g(\lambda, \nu) = -b^\top \nu$.</p>

      <figure style="margin: 16px 0; text-align: center;">
        <img src="../../static/assets/topics/09-duality/saddle-point-illustration.png" alt="Illustration of a saddle point" style="max-width: 500px; height: auto; border-radius: 8px;" />
        <figcaption style="font-size: 13px; color: var(--muted); margin-top: 8px;">
          The Lagrangian exhibits a saddle point structure: minimized over $x$ (primal variables), maximized over $\lambda, \nu$ (dual variables). Source: Statistical Odds & Ends.
        </figcaption>
      </figure>

      <!-- Widget 1: Lagrangian Explainer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Lagrangian Explainer</h3>
        <p><strong>Purpose:</strong> Visualize how the Lagrangian function $L(x, \lambda, \nu)$ changes as dual variables $\lambda, \nu$ vary.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Adjust $\lambda$ (penalty on inequality constraints) and see Lagrangian surface update</li>
          <li>Observe the infimum $g(\lambda, \nu)$ as a function of dual variables</li>
          <li>Understand the saddle-point structure</li>
        </ul>
        <div id="widget-1" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 2: The Dual Problem and Weak Duality -->
    <section class="section-card" id="section-2">
      <h2>2. The Dual Problem and Weak Duality</h2>

      <h3>2.1 Lower Bound Property</h3>
      <div class="proof-box">
        <h4>Lemma: Dual Function Provides Lower Bound</h4>
        <p><strong>Statement:</strong> For any $\lambda \succeq 0$ (componentwise) and any $\nu$, we have $g(\lambda, \nu) \le p^*$.</p>

        <div class="proof-step">
          <strong>Proof:</strong> Let $\tilde{x}$ be any feasible point for the primal. Then $f_i(\tilde{x}) \le 0$ and $h_j(\tilde{x}) = 0$. Thus:
          $
          \begin{aligned}
          L(\tilde{x}, \lambda, \nu) &= f_0(\tilde{x}) + \sum_{i=1}^m \lambda_i f_i(\tilde{x}) + \sum_{j=1}^p \nu_j h_j(\tilde{x}) \\
          &\le f_0(\tilde{x}) \quad \text{(since $\lambda_i \ge 0$ and $f_i(\tilde{x}) \le 0$)}
          \end{aligned}
          $
          Taking the infimum over all $x$ (including feasible $\tilde{x}$):
          $
          g(\lambda, \nu) = \inf_x L(x, \lambda, \nu) \le L(\tilde{x}, \lambda, \nu) \le f_0(\tilde{x})
          $
          This holds for all feasible $\tilde{x}$, so $g(\lambda, \nu) \le p^*$.
        </div>
      </div>

      <h3>2.2 The Dual Problem</h3>
      <p>The <a href="#" class="definition-link">Lagrange dual problem</a> is:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <p style="margin: 0;">
          $
          \begin{aligned}
          \text{maximize} \quad & g(\lambda, \nu) \\
          \text{subject to} \quad & \lambda \succeq 0
          \end{aligned}
          $
        </p>
      </div>

      <p>with dual optimal value $d^*$. Key observations:</p>
      <ul>
        <li>The dual is always a <strong>concave maximization</strong> (equivalently, convex minimization of $-g$)</li>
        <li>The dual is convex even if the primal is not convex</li>
        <li>Variables: $\lambda \in \mathbb{R}^m$, $\nu \in \mathbb{R}^p$</li>
      </ul>

      <h3>2.3 Weak Duality Theorem</h3>
      <div class="proof-box">
        <h4>Theorem: <a href="#" class="definition-link">Weak Duality</a></h4>
        <p><strong>Statement:</strong> $d^* \le p^*$ always holds.</p>

        <div class="proof-step">
          <strong>Proof:</strong> This is immediate from the lower bound property: for any dual feasible $(\lambda, \nu)$ with $\lambda \succeq 0$, we have $g(\lambda, \nu) \le p^*$. Taking the supremum over all such $(\lambda, \nu)$ gives $d^* \le p^*$.
        </div>
      </div>

      <h3>2.4 The Duality Gap</h3>
      <p>The <a href="#" class="definition-link">duality gap</a> is $p^* - d^* \ge 0$. It measures how far the best dual bound is from the primal optimum.</p>
      <ul>
        <li>If $p^* - d^* = 0$, we have <a href="#" class="definition-link">strong duality</a></li>
        <li>If $p^* - d^* > 0$, we have a <strong>duality gap</strong></li>
      </ul>

      <h3>2.5 Max-Min Interpretation</h3>
      <p>Weak duality can be stated as:</p>
      <p style="text-align: center;">
        $
        \sup_{\lambda \succeq 0, \nu} \inf_x L(x, \lambda, \nu) \le \inf_x \sup_{\lambda \succeq 0, \nu} L(x, \lambda, \nu)
        $
      </p>
      <p>Strong duality means these are equal (saddle point property).</p>

      <!-- Widget 2: Duality Visualizer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Primal-Dual Visualizer</h3>
        <p><strong>Purpose:</strong> Visualize primal and dual problems for a 2D LP, showing feasible regions and optimal points.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>See primal feasible region (polyhedron) and dual feasible region</li>
          <li>Observe primal optimal $x^*$ and dual optimal $(\lambda^*, \nu^*)$</li>
          <li>Verify strong duality: $c^\top x^* = b^\top \nu^*$</li>
        </ul>
        <div id="widget-2" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>

      <!-- Widget 4: Weak vs Strong Duality Race -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Duality Gap Animation</h3>
        <p><strong>Purpose:</strong> Animate convergence of primal and dual objectives, showing duality gap shrinking.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Watch primal objective $f_0(x^{(k)})$ descend and dual $g(\lambda^{(k)}, \nu^{(k)})$ ascend</li>
          <li>See the gap $p^* - d^*$ close to zero (strong duality)</li>
          <li>Explore cases where gap remains (weak duality)</li>
        </ul>
        <div id="widget-4" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 3: Strong Duality and Slater's Condition -->
    <section class="section-card" id="section-3">
      <h2>3. Strong Duality and Slater's Condition</h2>

      <h3>3.1 When Does Strong Duality Hold?</h3>
      <p>Strong duality ($p^* = d^*$) does not always hold. Example: Consider a non-convex problem where we break the assumptions.</p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad x^3 \quad \text{s.t.} \quad x \ge 1
        $
      </p>
      <p>The primal is easy: $x^* = 1, p^* = 1$. The dual function is $g(\lambda) = \inf_x (x^3 - \lambda(x-1))$.
      For any $\lambda \ge 0$, as $x \to -\infty$, $x^3 - \lambda x \to -\infty$. Thus $g(\lambda) = -\infty$.
      So $d^* = -\infty$. The duality gap is $\infty$. This happens because $f_0(x)=x^3$ is not convex on $\mathbb{R}$ (only on $\mathbb{R}_+$), and the domain isn't restricted.</p>

      <div class="insight">
        <h4>üí° Geometric Interpretation of Duality</h4>
        <p>We can visualize the primal and dual problems using a <b>hyperplane lifting</b> argument in the space of (constraint value, objective value). Let $\mathcal{G} = \{(f_1(x), \dots, f_m(x), f_0(x)) \mid x \in \mathcal{D}\}$.</p>
        <ul>
          <li>The primal problem is finding the point in $\mathcal{G}$ that intersects the vertical axis ($u=0$) at the lowest height.</li>
          <li>The dual problem corresponds to finding a non-vertical supporting hyperplane to the set $\mathcal{A} = \mathcal{G} + \mathbb{R}^m_+ \times \mathbb{R}_+$ that passes below the set. This relies directly on the <b>Separating Hyperplane Theorem</b> from <a href="../04-convex-sets-cones/index.html">Lecture 04</a>.</li>
          <li>The intercept of this hyperplane with the vertical axis is the dual value $g(\lambda)$.</li>
          <li><b>Strong Duality</b> holds if the supporting hyperplane at the optimal point is non-vertical. This non-verticality is exactly what Slater's condition ensures!</li>
        </ul>
      </div>

      <p>For convex problems, we have a powerful condition:</p>

      <div class="proof-box">
        <h4>Theorem: <a href="#" class="definition-link">Slater's Condition</a> for Strong Duality</h4>
        <p><strong>Statement:</strong> For a convex problem (convex $f_0, f_i$ and affine $h_j$), if there exists a point $\tilde{x} \in \text{relint}(\mathcal{D})$ such that:</p>
        <ul>
          <li>$f_i(\tilde{x}) < 0$ for $i = 1, \dots, m$ (strict inequality)</li>
          <li>$h_j(\tilde{x}) = 0$ for $j = 1, \dots, p$</li>
        </ul>
        <p>then <strong>strong duality</strong> holds: $p^* = d^*$.</p>

        <div class="proof-step">
          <strong>Step 1: Define the set of achievable values.</strong>
          Consider the set of values $(\text{constraint}, \text{objective})$ in $\mathbb{R}^{m+1}$:
          $$ \mathcal{A} = \{(u, t) \mid \exists x, f_i(x) \le u_i, f_0(x) \le t\} $$
          Since $f_i$ are convex, this set $\mathcal{A}$ is convex.
        </div>

        <div class="proof-step">
          <strong>Step 2: Apply Separating Hyperplane Theorem.</strong>
          Assume $d^* < p^*$ (duality gap). We want to find a contradiction.
          The point $(0, p^*)$ is on the boundary of $\mathcal{A}$. But strictly speaking, $(0, d^*)$ is not in $\mathcal{A}$ if we assume the gap.
          Let's separate $\mathcal{A}$ from the ray $(-\infty, d^*)$ in the objective dimension?
          Standard proof: Consider the set $\mathcal{B} = \{(0, t) \mid t < p^*\}$. This is disjoint from $\mathcal{A}$.
          By the Separating Hyperplane Theorem, there exists a hyperplane $(\lambda, \mu)$ separating $\mathcal{A}$ and $\mathcal{B}$.
          $$ \lambda^\top u + \mu t \ge \alpha \quad \forall (u, t) \in \mathcal{A} $$
          $$ \lambda^\top \cdot 0 + \mu t < \alpha \quad \forall t < p^* $$
        </div>

        <div class="proof-step">
          <strong>Step 3: Analyze Dual Variables.</strong>
          From the second inequality ($0 < \alpha - \mu t$ for $t < p^*$), we deduce $\mu \ge 0$. Also $\lambda \ge 0$ (if any $\lambda_i < 0$, we could take $u_i \to \infty$ in $\mathcal{A}$, violating the upper bound $\alpha$).
          <br><b>Case 1: Non-vertical hyperplane ($\mu > 0$).</b> Divide by $\mu$ to define $\tilde{\lambda} = \lambda/\mu$. The inequality becomes:
          $$ \tilde{\lambda}^\top u + t \ge \alpha/\mu \quad \forall (u, t) \in \mathcal{A} $$
          This implies $\inf_{(u, t) \in \mathcal{A}} (t + \tilde{\lambda}^\top u) \ge \alpha/\mu$.
          Since $\inf_x L(x, \tilde{\lambda}) = \inf \{ t + \tilde{\lambda}^\top u \mid (u, t) \in \mathcal{A} \}$, we have $g(\tilde{\lambda}) \ge \alpha/\mu$.
          Also, as $t \nearrow p^*$, $\mu t \le \alpha$, so $\mu p^* \le \alpha$, i.e., $p^* \le \alpha/\mu$.
          Combining: $d^* \ge g(\tilde{\lambda}) \ge p^*$. Since weak duality gives $d^* \le p^*$, we must have $d^* = p^*$.
        </div>

        <div class="proof-step">
          <strong>Step 4: Use Slater's Point to prove $\mu > 0$.</strong>
          Suppose for contradiction that $\mu = 0$. Then the separation inequality becomes $\lambda^\top u \ge \alpha \ge 0$ for all $u \in \mathcal{A}$.
          Applying this to the Slater point $\tilde{x}$: let $\tilde{u}_i = f_i(\tilde{x})$ and $\tilde{t} = f_0(\tilde{x})$. Then $(\tilde{u}, \tilde{t}) \in \mathcal{A}$.
          The inequality implies $\sum_{i=1}^m \lambda_i f_i(\tilde{x}) \ge 0$.
          <br>However, we know:
          <ul>
            <li>$\lambda \succeq 0$ and $\lambda \neq 0$ (since $(\lambda, \mu) \neq 0$ and $\mu=0$).</li>
            <li>$f_i(\tilde{x}) < 0$ for all $i$ (strictly feasible).</li>
          </ul>
          Since $\lambda$ has at least one positive component $\lambda_k > 0$, and $f_k(\tilde{x}) < 0$, the term $\lambda_k f_k(\tilde{x})$ is strictly negative. All other terms are non-positive.
          Thus, $\sum \lambda_i f_i(\tilde{x}) < 0$.
          <br>This contradicts $\sum \lambda_i f_i(\tilde{x}) \ge 0$. Therefore, the assumption $\mu=0$ must be false.
          <br>Conclusion: $\mu > 0$ holds, so Strong Duality holds.
        </div>

        <div class="insight">
          <h4>Why Interior Points Matter</h4>
          <p>Slater's condition requires a point in the <b>relative interior</b> of the feasible set. Geometrically, this ensures the feasible set has "volume" and doesn't collapse into a lower-dimensional degenerate shape where the supporting hyperplane could become vertical ($\mu=0$). A vertical hyperplane corresponds to an infinite dual value or a gap, signifying that the constraints are "infinitely hard" to satisfy in a differential sense.</p>
        </div>
      </div>

      <h3>3.2 Example: Strong Duality for LP</h3>
      <p>Consider the LP:</p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad c^\top x \quad \text{s.t.} \quad Ax = b, \; x \ge 0
        $
      </p>
      <p>The dual is:</p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad b^\top \nu \quad \text{s.t.} \quad A^\top \nu \preceq c
        $
      </p>
      <p>By LP duality theory (a special case of convex duality), strong duality holds if both are feasible. The geometric proof relies on polyhedral separation (<a href="../03-convex-sets-geometry/index.html">Lecture 03</a>).</p>
    </section>

    <!-- Section 4: KKT Optimality Conditions -->
    <section class="section-card" id="section-4">
      <h2>4. Karush-Kuhn-Tucker (KKT) Optimality Conditions</h2>

      <h3>4.1 Motivation</h3>
      <p>The <strong>KKT conditions</strong> provide necessary (and for convex problems, sufficient) conditions for a point to be optimal. They generalize the Lagrange multiplier conditions from calculus.</p>

      <h3>4.2 The KKT Conditions</h3>
      <p>Let $x^*$ be a candidate optimal point, and $(\lambda^*, \nu^*)$ be candidate dual variables. The <a href="#" class="definition-link">KKT conditions</a> are:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <ol>
          <li><strong>Stationarity:</strong> $\nabla f_0(x^*) + \sum_{i=1}^m \lambda_i^* \nabla f_i(x^*) + \sum_{j=1}^p \nu_j^* \nabla h_j(x^*) = 0$</li>
          <li><strong>Primal feasibility:</strong> $f_i(x^*) \le 0$, $h_j(x^*) = 0$</li>
          <li><strong>Dual feasibility:</strong> $\lambda^* \succeq 0$</li>
          <li><strong>Complementary slackness:</strong> $\lambda_i^* f_i(x^*) = 0$ for all $i$</li>
        </ol>
      </div>

      <h3>4.3 Complementary Slackness</h3>
      <p>The complementary slackness condition $\lambda_i^* f_i(x^*) = 0$ has a powerful interpretation:</p>
      <ul>
        <li>If $\lambda_i^* > 0$, then $f_i(x^*) = 0$ (constraint $i$ is <strong>active</strong>)</li>
        <li>If $f_i(x^*) < 0$ (constraint $i$ is <strong>inactive</strong>), then $\lambda_i^* = 0$</li>
      </ul>
      <p><strong>Intuition:</strong> Non-zero dual variables correspond to binding constraints. Slack constraints have zero dual variables.</p>

      <div class="proof-box">
        <h4>Theorem: KKT Conditions for Convex Problems</h4>
        <p><strong>Statement:</strong> For a convex problem with differentiable $f_0, f_i, h_j$, if strong duality holds and $x^*, (\lambda^*, \nu^*)$ are primal and dual optimal, then they satisfy the KKT conditions. Conversely, if the KKT conditions hold for some $(x^*, \lambda^*, \nu^*)$, then $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal.</p>

        <div class="insight">
          <h4>Geometric Connection</h4>
          <p>The <b>stationarity</b> condition $\nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) = 0$ is exactly the "Supporting Hyperplane" concept from <a href="../04-convex-sets-cones/index.html">Lecture 04</a>: the negative gradient of the objective lies in the normal cone of the feasible set. It also matches the "First-Order Optimality Condition" variational inequality $\nabla f_0(x^*)^\top (y - x^*) \ge 0$ discussed in <a href="../06-convex-functions-advanced/index.html">Lecture 06</a>.</p>
        </div>

        <div class="proof-step">
          <strong>Necessity (‚áí):</strong> Suppose $x^*$ is primal optimal and strong duality holds. Then $x^*$ minimizes $L(x, \lambda^*, \nu^*)$, so $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$ (stationarity). Primal and dual feasibility follow by definition. Complementary slackness follows from $g(\lambda^*, \nu^*) = f_0(x^*)$ at optimality.
        </div>

        <div class="proof-step">
          <strong>Sufficiency (‚áê):</strong> Suppose $(x^*, \lambda^*, \nu^*)$ satisfy KKT. Then:
          $
          \begin{aligned}
          g(\lambda^*, \nu^*) &= \inf_x L(x, \lambda^*, \nu^*) \\
          &\le L(x^*, \lambda^*, \nu^*) \quad \text{(by definition of inf)} \\
          &= f_0(x^*) + \sum_i \lambda_i^* f_i(x^*) + \sum_j \nu_j^* h_j(x^*) \\
          &= f_0(x^*) \quad \text{(complementary slackness and $h_j(x^*) = 0$)}
          \end{aligned}
          $
          By weak duality, $g(\lambda^*, \nu^*) \le p^*$. But $f_0(x^*) \ge p^*$ (since $x^*$ is feasible). Thus $g(\lambda^*, \nu^*) = f_0(x^*) = p^* = d^*$, so $x^*$ is optimal.
        </div>
      </div>

      <h3>4.4 Using KKT to Solve Problems</h3>
      <p>For small problems, we can solve the KKT system directly:</p>
      <ol>
        <li>Write out the stationarity condition: $\nabla_x L = 0$</li>
        <li>Write primal and dual feasibility</li>
        <li>Write complementary slackness</li>
        <li>Solve the resulting system of equations and inequalities</li>
      </ol>

      <!-- Widget 3: KKT Condition Checker -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: KKT Condition Checker</h3>
        <p><strong>Purpose:</strong> Verify which KKT conditions are satisfied for a candidate solution.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Input candidate $x^*$, $\lambda^*$, $\nu^*$ for a simple problem</li>
          <li>Check stationarity, feasibility, complementary slackness individually</li>
          <li>Get feedback on which conditions fail (if any)</li>
        </ul>
        <div id="widget-3" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>

      <!-- Widget 6: Complementary Slackness Explorer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Complementary Slackness Explorer</h3>
        <p><strong>Purpose:</strong> Interactive demonstration of complementary slackness for a 2D LP.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Visualize constraints: active (binding) vs inactive (slack)</li>
          <li>Display $\lambda_i^*$ for each constraint</li>
          <li>Verify $\lambda_i^* f_i(x^*) = 0$ for all $i$</li>
        </ul>
        <div id="widget-6" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 5: Perturbation and Sensitivity Analysis -->
    <section class="section-card" id="section-5">
      <h2>5. Perturbation and Sensitivity Analysis</h2>

      <h3>5.1 Perturbed Problem</h3>
      <p>Consider perturbing the RHS of constraints:</p>
      <p style="text-align: center;">
        $
        \begin{aligned}
        \text{minimize} \quad & f_0(x) \\
        \text{subject to} \quad & f_i(x) \le u_i, \quad i = 1, \dots, m \\
        & h_j(x) = v_j, \quad j = 1, \dots, p
        \end{aligned}
        $
      </p>
      <p>Let $p^*(u, v)$ be the optimal value as a function of $(u, v)$. The unperturbed problem has $(u, v) = (0, 0)$.</p>

      <div class="proof-box">
        <h4>Theorem: Sensitivity via Dual Variables</h4>
        <p><strong>Statement:</strong> Let $p^*(u, v)$ be the optimal value of the perturbed problem with constraints $f_i(x) \le u_i$ and $h_j(x) = v_j$. If $p^*(u, v)$ is differentiable at $(0,0)$ and strong duality holds, then:</p>
        $$ \nabla_u p^*(0,0) = -\lambda^* \quad \text{and} \quad \nabla_v p^*(0,0) = -\nu^* $$

        <div class="proof-step">
          <strong>Proof (Heuristic):</strong>
          Assume strong duality holds for the perturbed problem and that the optimal dual variables $(\lambda^*, \nu^*)$ for the unperturbed problem remain optimal for small perturbations (this is a strong assumption).
          $$
          \begin{aligned}
          p^*(u, v) &= \inf_x \left( f_0(x) + \sum \lambda_i^* (f_i(x) - u_i) + \sum \nu_j^* (h_j(x) - v_j) \right) \\
          &= \inf_x \left( L(x, \lambda^*, \nu^*) - \sum \lambda_i^* u_i - \sum \nu_j^* v_j \right) \\
          &= g(\lambda^*, \nu^*) - \lambda^{*\top} u - \nu^{*\top} v \\
          &= p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v
          \end{aligned}
          $$
          This suggests that $p^*(u, v)$ is locally linear with gradients $-\lambda^*$ and $-\nu^*$.
        </div>

        <div class="proof-step">
          <strong>Global Sensitivity View:</strong>
          Without assuming differentiability, we can prove a global lower bound using weak duality. For any feasible perturbation $(u,v)$ and any dual optimal $(\lambda^*, \nu^*)$:
          $$ p^*(u, v) \ge p^*(0,0) - \lambda^{*\top} u - \nu^{*\top} v $$
          This means that $(-\lambda^*, -\nu^*)$ is a <b>subgradient</b> of the function $p^*(u, v)$ at $(0,0)$.
        </div>

        <div class="proof-step">
          <strong>Interpretation:</strong> The dual variable $\lambda_i^*$ measures the rate of change of the optimal value with respect to relaxing constraint $i$. This is the <strong>shadow price</strong>. If $\lambda_i^*$ is large, the constraint is expensive; relaxing it (increasing $u_i$) yields significant savings.
        </div>

        <div class="insight">
          <h4>üí° Connection to Conjugates (Profit Maximization)</h4>
          <p>Recall from <a href="../06-convex-functions-advanced/index.html#section-1">Lecture 06</a> that the conjugate function $f^*(y)$ represents the maximum profit at price vector $y$. In duality, the dual variables $\lambda$ play the role of "shadow prices" or internal prices for the constraints.
          <br>Just as the conjugate maps prices to profit, the dual function $g(\lambda)$ maps these shadow prices to a bound on the optimal value.</p>
        </div>
      </div>


      </div>

      <h3>5.2 Example: Water Filling</h3>
      <p>In communication systems, "water filling" allocates power across channels. The dual variable represents the "water level" (Lagrange multiplier), and active constraints correspond to filled channels.</p>

      <!-- Widget 5: Shadow Prices & Sensitivity -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Shadow Prices & Sensitivity Analysis</h3>
        <p><strong>Purpose:</strong> Perturb constraints and observe how optimal value $p^*(u)$ changes; verify $\lambda^* = -\nabla p^*(0)$.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Adjust RHS $u_i$ of constraint $i$ and see $p^*(u)$ update</li>
          <li>Compare numerical derivative to dual variable $\lambda_i^*$</li>
          <li>Understand economic interpretation (shadow price)</li>
        </ul>
        <div id="widget-5" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 6: Duality for Specific Problem Classes -->
    <section class="section-card" id="section-6">
      <h2>6. Duality for Specific Problem Classes</h2>

      <h3>6.1 Linear Programming Duality</h3>
      <p><strong>Primal:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad c^\top x \quad \text{s.t.} \quad Ax = b, \; x \ge 0
        $
      </p>

      <p><strong>Dual:</strong></p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad b^\top \nu \quad \text{s.t.} \quad A^\top \nu \preceq c
        $
      </p>

      <p><strong>Key properties:</strong></p>
      <ul>
        <li>Strong duality holds if both are feasible</li>
        <li>Dual of dual is primal (symmetric duality)</li>
        <li>Complementary slackness: $(c - A^\top \nu^*)^\top x^* = 0$</li>
      </ul>

      <h3>6.2 Quadratic Programming Duality</h3>
      <p>We derive the dual of a QP with inequality constraints. Assume $P \succ 0$ (positive definite).</p>

      <p><strong>Primal QP:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad \frac{1}{2} x^\top P x + q^\top x \quad \text{s.t.} \quad Ax \le b
        $
      </p>

      <div class="proof-box">
        <h4>Derivation of the Dual QP</h4>

        <div class="proof-step">
          <strong>Step 1: Form the Lagrangian.</strong>
          Introduce dual variable $\lambda \in \mathbb{R}^m$ for the inequality constraint $Ax \le b$.
          $$ L(x, \lambda) = \frac{1}{2} x^\top P x + q^\top x + \lambda^\top (Ax - b) $$
          $$ = \frac{1}{2} x^\top P x + (q + A^\top \lambda)^\top x - b^\top \lambda $$
        </div>

        <div class="proof-step">
          <strong>Step 2: Minimize Lagrangian w.r.t $x$.</strong>
          Since $P \succ 0$, $L(x, \lambda)$ is strictly convex in $x$. The minimum occurs where the gradient vanishes.
          $$ \nabla_x L(x, \lambda) = Px + q + A^\top \lambda = 0 $$
          Solving for $x$:
          $$ x^* = -P^{-1}(q + A^\top \lambda) $$
        </div>

        <div class="proof-step">
          <strong>Step 3: Evaluate the Dual Function $g(\lambda)$.</strong>
          Substitute $x^*$ back into the Lagrangian:
          $$ g(\lambda) = \frac{1}{2} (x^*)^\top P x^* + (q + A^\top \lambda)^\top x^* - b^\top \lambda $$
          $$ = \frac{1}{2} [-(q+A^\top \lambda)^\top P^{-1}] P [-P^{-1}(q+A^\top \lambda)] + (q+A^\top \lambda)^\top [-P^{-1}(q+A^\top \lambda)] - b^\top \lambda $$
          $$ = \frac{1}{2} (q+A^\top \lambda)^\top P^{-1} (q+A^\top \lambda) - (q+A^\top \lambda)^\top P^{-1} (q+A^\top \lambda) - b^\top \lambda $$
          $$ = -\frac{1}{2} (q + A^\top \lambda)^\top P^{-1} (q + A^\top \lambda) - b^\top \lambda $$
        </div>

        <div class="proof-step">
          <strong>Step 4: State the Dual Problem.</strong>
          The dual problem is to maximize $g(\lambda)$ subject to $\lambda \ge 0$.
          $$
          \begin{aligned}
          \text{maximize} \quad & -\frac{1}{2} (q + A^\top \lambda)^\top P^{-1} (q + A^\top \lambda) - b^\top \lambda \\
          \text{subject to} \quad & \lambda \ge 0
          \end{aligned}
          $$
          This is itself a Quadratic Program (concave maximization) in the variable $\lambda$.
        </div>
      </div>

      <h3>6.3 Semidefinite Programming Duality</h3>
      <p>Semidefinite programming (SDP) generalizes linear programming to the cone of positive semidefinite matrices. We derive the dual explicitly to show the symmetry between the primal and dual forms.</p>

      <p><strong>Primal SDP:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad \text{tr}(C X) \quad \text{s.t.} \quad \text{tr}(A_i X) = b_i, \quad i=1,\dots,m; \quad X \succeq 0
        $
      </p>

      <div class="proof-box">
        <h4>Derivation of the Dual SDP</h4>

        <div class="proof-step">
          <strong>Step 1: Form the Lagrangian.</strong>
          We associate dual variables $y \in \mathbb{R}^m$ with the equality constraints $\text{tr}(A_i X) = b_i$.
          We associate a dual matrix variable $S \in \mathbb{S}^n$ with the inequality constraint $X \succeq 0$ (represented as $-X \preceq 0$). The Lagrangian term for a generalized inequality $G(x) \preceq_K 0$ is $\text{tr}(\Lambda^\top G(x))$ with $\Lambda \in K^*$. Here $K = \mathbb{S}^n_+$, so $S \in \mathbb{S}^n_+$.
          $$ L(X, y, S) = \text{tr}(CX) + \sum_{i=1}^m y_i (b_i - \text{tr}(A_i X)) - \text{tr}(SX) $$
          where $S \succeq 0$.
        </div>

        <div class="proof-step">
          <strong>Step 2: Group terms by X.</strong>
          We use the linearity of the trace operator $\text{tr}(A+B) = \text{tr}(A) + \text{tr}(B)$ and $\text{tr}(cA) = c\text{tr}(A)$.
          $$ L(X, y, S) = \sum_{i=1}^m y_i b_i + \text{tr}(CX) - \sum_{i=1}^m \text{tr}(y_i A_i X) - \text{tr}(SX) $$
          $$ = b^\top y + \text{tr}\left( \left( C - \sum_{i=1}^m y_i A_i - S \right) X \right) $$
        </div>

        <div class="proof-step">
          <strong>Step 3: Minimize over X.</strong>
          The dual function is $g(y, S) = \inf_X L(X, y, S)$.
          The term involving $X$ is a linear function of $X$: $\text{tr}(M X)$ where $M = C - \sum y_i A_i - S$.
          If $M \neq 0$, the infimum is $-\infty$ (we can choose $X = -k M$ with $k \to \infty$ effectively, or project onto a direction where trace is negative).
          For the infimum to be bounded, we must have $M = 0$.
          $$ C - \sum_{i=1}^m y_i A_i - S = 0 $$
          In this case, $g(y, S) = b^\top y$.
        </div>

        <div class="proof-step">
          <strong>Step 4: State the Dual Problem.</strong>
          Maximize the dual function subject to the domain constraints ($S \succeq 0$ and the stationarity condition):
          $$
          \begin{aligned}
          \text{maximize} \quad & b^\top y \\
          \text{subject to} \quad & \sum_{i=1}^m y_i A_i + S = C \\
          & S \succeq 0
          \end{aligned}
          $$
          Eliminating the slack variable $S$, we get the standard LMI form:
          $$ \sum_{i=1}^m y_i A_i \preceq C $$
        </div>
      </div>

      <p><strong>Properties:</strong></p>
      <ul>
        <li><b>Weak Duality:</b> $\text{tr}(CX) - b^\top y = \text{tr}(SX) \ge 0$ since $X, S \succeq 0$.</li>
        <li><b>Strong Duality:</b> Holds if Slater's condition is satisfied (strictly feasible primal or dual).</li>
        <li><b>Complementary Slackness:</b> $X^* S^* = 0$ (matrix product is zero). This implies optimal matrices commute and share eigenvectors.</li>
      </ul>

      <h3>6.4 Conic Duality</h3>
      <p>General conic programs have dual cones (see <a href="../04-convex-sets-cones/index.html">Lecture 04</a> for the definition of dual cones). For a cone $K$ and its dual $K^*$:</p>
      <p style="text-align: center;">
        $
        \text{Primal: } \min c^\top x \text{ s.t. } Ax = b, \; x \in K
        $
      </p>
      <p style="text-align: center;">
        $
        \text{Dual: } \max b^\top \nu \text{ s.t. } c - A^\top \nu \in K^*
        $
      </p>
    </section>

    <!-- Section 7: Examples and Applications -->
    <section class="section-card" id="section-7">
      <h2>7. Examples and Applications</h2>

      <h3>7.1 Support Vector Machines (SVM)</h3>
      <p>The primal SVM problem (soft margin) is:</p>
      <p style="text-align: center;">
        $
        \min_{w, b, \xi} \frac{1}{2} \|w\|_2^2 + C \sum_i \xi_i \quad \text{s.t.} \quad y_i (w^\top x_i + b) \ge 1 - \xi_i, \; \xi_i \ge 0
        $
      </p>

      <p>The dual SVM is:</p>
      <p style="text-align: center;">
        $
        \max_\alpha \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j \quad \text{s.t.} \quad 0 \le \alpha_i \le C, \; \sum_i \alpha_i y_i = 0
        $
      </p>

      <p>The dual formulation enables the "kernel trick" for nonlinear classification.</p>

      <h3>7.2 Minimum-Volume Ellipsoid</h3>
      <p>Finding the minimum-volume ellipsoid enclosing points has a dual interpretation related to optimal experimental design.</p>

      <h3>7.3 Network Flow</h3>
      <p>The max-flow min-cut theorem is a consequence of LP duality applied to network flow problems.</p>
    </section>


    <section class="section-card" id="section-8">
      <h2>8. Review & Cheat Sheet</h2>

      <h3>Key Concepts</h3>
      <ul>
        <li><strong>Lagrangian:</strong> $L(x, \lambda, \nu) = f_0(x) + \sum \lambda_i f_i(x) + \sum \nu_j h_j(x)$. This converts a constrained problem into an unconstrained one by pricing the constraints.</li>
        <li><strong>Dual Function:</strong> $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$. This function is always concave, regardless of the convexity of the primal.</li>
        <li><strong>Weak Duality:</strong> $d^* \le p^*$. The best lower bound from the dual is always less than or equal to the primal optimal value.</li>
        <li><strong>Strong Duality:</strong> $d^* = p^*$. This holds for convex problems under Slater's condition (strict feasibility).</li>
      </ul>

      <h3>KKT Conditions (Optimality Certificate)</h3>
      <p>For convex problems where strong duality holds, the vectors $x^*, \lambda^*, \nu^*$ are optimal if and only if they satisfy:</p>
      <ol>
        <li><strong>Stationarity:</strong> $\nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0$ (Forces balance).</li>
        <li><strong>Primal Feasibility:</strong> Constraints are satisfied.</li>
        <li><strong>Dual Feasibility:</strong> $\lambda^* \succeq 0$ (Prices are non-negative).</li>
        <li><strong>Complementary Slackness:</strong> $\lambda_i^* f_i(x^*) = 0$ (Inactive constraints have zero price).</li>
      </ol>
    </section>


<section class="section-card" id="section-9">
      <h2><i data-feather="edit-3"></i> 9. Exercises</h2>
      <p>These problems consolidate the duality theory and provide practice in deriving duals, verifying KKT conditions, and applying sensitivity analysis.</p>

      <!-- Problem 5.1 -->

<div class="problem">
  <h3>P5.1 ‚Äî Derive the Dual of a Simple QP</h3>
  <p>Consider the QP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \frac{1}{2} x^\top x + c^\top x \quad \text{s.t.} \quad Ax = b
          $
        </p>
        <p><strong>(a)</strong> Form the Lagrangian.</p>
        <p><strong>(b)</strong> Compute the dual function $g(\nu)$.</p>
        <p><strong>(c)</strong> Write the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Conjugate Relation:</b> The dual function of a QP is explicitly derived from the convex conjugate of the quadratic form. Specifically, $\inf_x (\frac{1}{2}x^\top x + c^\top x) = -\frac{1}{2}\|c\|^2$. Adding constraints shifts the linear term.</li>
            <li><b>Unconstrained Dual:</b> Since the primal only has equality constraints, the dual variables $\nu$ are free (unconstrained). The dual problem is an unconstrained concave maximization of a quadratic form.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>The dual of a QP is also a QP. The relationship relies on the conjugacy of the quadratic form $1/2 x^\top x$.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Lagrangian.</strong>
            $
            L(x, \nu) = \frac{1}{2} x^\top x + c^\top x + \nu^\top (Ax - b)
            $
          </div>

          <div class="proof-step">
            <strong>Part (b): Dual function.</strong> To find $g(\nu) = \inf_x L(x, \nu)$, we minimize over $x$:
            $
            \nabla_x L = x + c + A^\top \nu = 0 \implies x^* = -(c + A^\top \nu)
            $
            Substituting back:
            $
            \begin{aligned}
            g(\nu) &= \frac{1}{2} (c + A^\top \nu)^\top (c + A^\top \nu) + c^\top (-(c + A^\top \nu)) - b^\top \nu \\
            &= -\frac{1}{2} (c + A^\top \nu)^\top (c + A^\top \nu) - b^\top \nu \\
            &= -\frac{1}{2} \|c + A^\top \nu\|_2^2 - b^\top \nu
            \end{aligned}
            $
          </div>

          <div class="proof-step">
            <strong>Part (c): Dual problem.</strong>
            $
            \text{maximize} \quad -\frac{1}{2} \|c + A^\top \nu\|_2^2 - b^\top \nu
            $
            This is an unconstrained concave maximization (or convex minimization of the negative).
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.2 ‚Äî Verify KKT Conditions for a 2D Problem</h3>
  <p>Consider:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x_1^2 + x_2^2 \quad \text{s.t.} \quad x_1 + x_2 \ge 1, \; x_1, x_2 \ge 0
          $
        </p>
        <p>Verify that $(x_1^*, x_2^*) = (1/2, 1/2)$ with $\lambda^* = (1, 0, 0)$ satisfies the KKT conditions.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Stationarity (Force Balance):</b> The gradient of the objective $\nabla f_0$ is balanced by the forces from active constraints $\nabla f_i$. At the optimum, no net force exists to move the point while staying feasible.</li>
            <li><b>Complementary Slackness Logic:</b> Dual variables act as "switches". If a constraint is loose (inactive), the switch must be off ($\lambda_i=0$). If the switch is on ($\lambda_i > 0$), the constraint must be tight (active).</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>KKT conditions are a system of equations/inequalities representing force balance (stationarity) and geometric constraints.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Step 1: Reformulate with standard form.</strong> Convert to minimization with $f_0(x) = x_1^2 + x_2^2$, constraints $-x_1 - x_2 \le -1$, $-x_1 \le 0$, $-x_2 \le 0$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Stationarity.</strong> The Lagrangian is:
            $
            L(x, \lambda) = x_1^2 + x_2^2 + \lambda_1 (-x_1 - x_2 + 1) + \lambda_2 (-x_1) + \lambda_3 (-x_2)
            $
            $
            \nabla_x L = \begin{bmatrix} 2x_1 - \lambda_1 - \lambda_2 \\ 2x_2 - \lambda_1 - \lambda_3 \end{bmatrix}
            $
            At $(x^*, \lambda^*) = ((1/2, 1/2), (1, 0, 0))$:
            $
            \nabla_x L = \begin{bmatrix} 2(1/2) - 1 - 0 \\ 2(1/2) - 1 - 0 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Step 3: Primal feasibility.</strong>
            $
            -x_1^* - x_2^* + 1 = -1/2 - 1/2 + 1 = 0 \le 0 \quad \checkmark
            $
            $
            -x_1^* = -1/2 \le 0, \quad -x_2^* = -1/2 \le 0 \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Step 4: Dual feasibility.</strong> $\lambda^* = (1, 0, 0) \succeq 0$ $\checkmark$
          </div>

          <div class="proof-step">
            <strong>Step 5: Complementary slackness.</strong>
            $
            \lambda_1^* (-x_1^* - x_2^* + 1) = 1 \cdot 0 = 0 \quad \checkmark
            $
            $
            \lambda_2^* (-x_1^*) = 0 \cdot (-1/2) = 0, \quad \lambda_3^* (-x_2^*) = 0 \cdot (-1/2) = 0 \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Conclusion.</strong> All KKT conditions are satisfied, so $(1/2, 1/2)$ is optimal.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.3 ‚Äî LP Duality: Derive and Verify</h3>
  <p>Consider the LP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad 3x_1 + 2x_2 \quad \text{s.t.} \quad x_1 + x_2 \ge 4, \; 2x_1 + x_2 \ge 5, \; x_1, x_2 \ge 0
          $
        </p>
        <p><strong>(a)</strong> Derive the dual LP.</p>
        <p><strong>(b)</strong> Solve both primal and dual graphically.</p>
        <p><strong>(c)</strong> Verify strong duality.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Standard LP Dual Construction:</b> The dual of a minimization LP with $\ge$ constraints is a maximization LP with $\le$ constraints. The constraint matrix is transposed ($A \to A^\top$) and the cost/RHS vectors swap roles ($b \leftrightarrow c$).</li>
            <li><b>Strong Duality in LP:</b> For Linear Programs, strong duality holds if either problem is feasible. The only gap occurs in pathological cases where both are infeasible.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>LP duality is symmetric. Constraints in primal become variables in dual, and cost vectors swap with RHS vectors.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Derive dual.</strong> Rewrite in standard form:
            $
          \text{min } c^\top x \text{ s.t. } -A x \le -b, \; x \ge 0
            $
            where $c = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, $A = \begin{bmatrix} 1 & 1 \\ 2 & 1 \end{bmatrix}$, $b = \begin{bmatrix} 4 \\ 5 \end{bmatrix}$.

            The dual is:
            $
            \text{maximize} \quad 4\lambda_1 + 5\lambda_2
            $
            $
            \text{subject to} \quad \lambda_1 + 2\lambda_2 \le 3, \; \lambda_1 + \lambda_2 \le 2, \; \lambda_1, \lambda_2 \ge 0
            $
          </div>

          <div class="proof-step">
            <strong>Part (b): Graphical solution.</strong>
            <ul>
              <li><strong>Primal:</strong> Plot feasible region $x_1 + x_2 \ge 4$, $2x_1 + x_2 \ge 5$, $x_1, x_2 \ge 0$. Minimize $3x_1 + 2x_2$ at vertex $(1, 3)$ with $p^* = 9$.</li>
              <li><strong>Dual:</strong> Plot feasible region $\lambda_1 + 2\lambda_2 \le 3$, $\lambda_1 + \lambda_2 \le 2$, $\lambda_1, \lambda_2 \ge 0$. Maximize $4\lambda_1 + 5\lambda_2$ at vertex $(1, 1)$ with $d^* = 9$.</li>
            </ul>
          </div>

          <div class="proof-step">
            <strong>Part (c): Verify strong duality.</strong> Since $p^* = d^* = 9$, strong duality holds.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.4 ‚Äî Slater's Condition</h3>
  <p>Consider the problem:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x^2 \quad \text{s.t.} \quad (x - 1)^2 \le 0
          $
        </p>
        <p><strong>(a)</strong> Is Slater's condition satisfied?</p>
        <p><strong>(b)</strong> Does strong duality hold?</p>
        <p><strong>(c)</strong> Compute $p^*$ and $d^*$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Slater's Necessity:</b> Slater's condition (strict feasibility) is a sufficient condition for strong duality. When it fails (e.g., the feasible set has no interior), strong duality may break, as seen in this example where $p^* > d^*$.</li>
            <li><b>Constraint Singularity:</b> The constraint $(x-1)^2 \le 0$ describes a single point but has a vanishing gradient at that point. This singularity prevents the dual variable from "pricing" the constraint correctly, leading to a duality gap.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>Slater's condition (strict feasibility) is the standard certificate for strong duality. Without it, duality gaps can occur even in convex problems.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Slater's condition.</strong> The constraint $(x - 1)^2 \le 0$ is satisfied only when $x = 1$ (since squares are nonnegative). There is no point with $(x - 1)^2 < 0$ (strict inequality). Thus, Slater's condition is NOT satisfied.
          </div>

          <div class="proof-step">
            <strong>Part (b): Strong duality.</strong> Without Slater's condition, strong duality may not hold. Let's check.
          </div>

          <div class="proof-step">
            <strong>Part (c): Compute $p^*$ and $d^*$.</strong>
            <ul>
              <li><strong>Primal:</strong> The only feasible point is $x = 1$, so $p^* = 1^2 = 1$.</li>
              <li><strong>Dual:</strong> The Lagrangian is $L(x, \lambda) = x^2 + \lambda (x - 1)^2$. Taking $\inf_x$:
                $
                \nabla_x L = 2x + 2\lambda (x - 1) = 0 \implies x = \frac{\lambda}{\lambda + 1}
                $
                Substituting:
                $
                g(\lambda) = \left(\frac{\lambda}{\lambda + 1}\right)^2 + \lambda \left(\frac{\lambda}{\lambda + 1} - 1\right)^2 = -\frac{\lambda^2}{(\lambda + 1)^2}
                $
                As $\lambda \to \infty$, $g(\lambda) \to -1$. But $g(\lambda) \le 0$ for all $\lambda \ge 0$, so $d^* = 0$.
              </li>
            </ul>
            Thus $p^* = 1 > 0 = d^*$, and there is a duality gap. Strong duality does NOT hold.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.5 ‚Äî Sensitivity Analysis: Shadow Prices</h3>
  <p>Consider the LP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x_1 + x_2 \quad \text{s.t.} \quad x_1 + 2x_2 \ge 3, \; x_1, x_2 \ge 0
          $
        </p>
        <p>The optimal solution is $x^* = (3, 0)$ with $\lambda^* = 1$ for the first constraint.</p>
        <p><strong>(a)</strong> Interpret $\lambda^* = 1$ as a shadow price.</p>
        <p><strong>(b)</strong> Perturb the RHS to $3 + u$ and compute $p^*(u)$ for small $u$.</p>
        <p><strong>(c)</strong> Verify $\frac{dp^*}{du}\big|_{u=0} = -\lambda^*$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Shadow Prices:</b> The optimal dual variable $\lambda_i^*$ represents the "shadow price" of the $i$-th constraint: it is the rate of improvement in the optimal objective value per unit of relaxation of the constraint.</li>
            <li><b>Sensitivity Formula:</b> The relation $\nabla p^*(0) = -\lambda^*$ quantifies sensitivity. If $\lambda^*$ is large, the constraint is a major bottleneck; relaxing it yields significant gains.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>The dual variable $\lambda_i$ is the derivative of the optimal value with respect to the constraint bound. It prices the resource.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Shadow price interpretation.</strong> $\lambda^* = 1$ means that if we relax the constraint $x_1 + 2x_2 \ge 3$ to $x_1 + 2x_2 \ge 3 - u$ (i.e., perturb RHS by $+u$), the optimal value decreases at rate $\lambda^* = 1$. In other words, each unit decrease in the RHS requirement saves 1 unit of cost.
          </div>

          <div class="proof-step">
            <strong>Part (b): Perturbed problem.</strong>
            $
            \text{minimize} \quad x_1 + x_2 \quad \text{s.t.} \quad x_1 + 2x_2 \ge 3 + u, \; x_1, x_2 \ge 0
            $
            The new optimal solution (for small $u$) is $x^*(u) = (3 + u, 0)$ (moving along the $x_1$ axis), so:
            $
            p^*(u) = (3 + u) + 0 = 3 + u
            $
          </div>

          <div class="proof-step">
            <strong>Part (c): Verify sensitivity.</strong>
            $
            \frac{dp^*}{du}\bigg|_{u=0} = 1
            $
            And indeed, $-\lambda^* = -1 \cdot (-1) = 1$ (note: sign convention depends on how perturbation is defined). The magnitude matches the shadow price.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.6 ‚Äî SVM Dual Formulation</h3>
  <p>For the hard-margin SVM:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \frac{1}{2} \|w\|_2^2 \quad \text{s.t.} \quad y_i (w^\top x_i + b) \ge 1, \; i = 1, \dots, n
          $
        </p>
        <p><strong>(a)</strong> Write the Lagrangian.</p>
        <p><strong>(b)</strong> Derive the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Dual Representation:</b> The KKT stationarity condition $\nabla_w L = 0$ implies $w = \sum \alpha_i y_i x_i$. This shows the optimal weights lie in the span of the data points.</li>
            <li><b>The Kernel Trick:</b> Since the dual objective involves data only through dot products $\langle x_i, x_j \rangle$, we can replace the Euclidean inner product with any valid kernel function $K(x_i, x_j)$, enabling non-linear classification in infinite-dimensional spaces.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>The dual SVM allows using kernels because it depends only on dot products $x_i^\top x_j$. This projects data into high dimensions implicitly.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Lagrangian.</strong>
            $
            L(w, b, \alpha) = \frac{1}{2} \|w\|_2^2 + \sum_{i=1}^n \alpha_i (1 - y_i (w^\top x_i + b))
            $
            where $\alpha_i \ge 0$ are dual variables.
          </div>

          <div class="proof-step">
            <strong>Part (b): Dual function.</strong> Minimize over $w$ and $b$:
            $
            \nabla_w L = w - \sum_i \alpha_i y_i x_i = 0 \implies w = \sum_i \alpha_i y_i x_i
            $
            $
            \frac{\partial L}{\partial b} = -\sum_i \alpha_i y_i = 0 \implies \sum_i \alpha_i y_i = 0
            $
            Substituting $w = \sum_i \alpha_i y_i x_i$ back:
            $
            \begin{aligned}
            g(\alpha) &= \frac{1}{2} \left\|\sum_i \alpha_i y_i x_i\right\|_2^2 + \sum_i \alpha_i - \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j \\
            &= \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j
            \end{aligned}
            $
          </div>

          <div class="proof-step">
            <strong>Dual problem:</strong>
            $
            \text{maximize} \quad \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j
            $
            $
            \text{subject to} \quad \alpha_i \ge 0, \; \sum_i \alpha_i y_i = 0
            $
            This is a QP in $\alpha$, enabling the kernel trick: replace $x_i^\top x_j$ with $K(x_i, x_j)$.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.7 ‚Äî Complementary Slackness in Portfolio Optimization</h3>
  <p>Consider the portfolio problem (Lecture 07-08):</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x^\top \Sigma x \quad \text{s.t.} \quad \mu^\top x \ge r_{\text{target}}, \; \mathbf{1}^\top x = 1, \; x \ge 0
          $
        </p>
        <p>Suppose at optimality, only asset 3 has $x_3^* = 0$ (all others positive), and the return constraint is active.</p>
        <p><strong>(a)</strong> What can you conclude about the dual variable $\lambda_3$ for constraint $x_3 \ge 0$?</p>
        <p><strong>(b)</strong> What does complementary slackness say about the return constraint?</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Reduced Cost Interpretation:</b> The dual variable for the non-negativity constraint ($x_i \ge 0$) is the "reduced cost". If $x_i^*=0$, then $\lambda_i > 0$ implies that the asset is "too expensive" relative to its risk/return contribution‚Äîinvesting in it would worsen the objective.</li>
            <li><b>Complementary Slackness in Finance:</b> If an asset is not held ($x_i^*=0$), the non-negativity constraint is active. If an asset <i>is</i> held ($x_i^* > 0$), the constraint is inactive, so its shadow price $\lambda_i^*$ must be zero (marginal benefit equals marginal cost).</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>Complementary slackness links primal geometry (active constraints) to dual variables (nonzero forces).</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Part (a): Dual variable $\lambda_3$.</strong> The constraint is $x_3 \ge 0$, or equivalently $-x_3 \le 0$ in standard form. The complementary slackness condition is $\lambda_3 x_3^* = 0$.
            Since $x_3^* = 0$, this condition is trivially satisfied for any $\lambda_3 \ge 0$.
            <br>However, we can infer more from the stationarity condition. The KKT stationarity condition is:
            $$ \nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*) = 0 $$
            For this problem:
            $$ 2(\Sigma x^*)_3 - \nu_{\text{ret}} \mu_3 - \nu_{\text{budget}} \cdot 1 - \lambda_3 = 0 $$
            Solving for $\lambda_3$:
            $$ \lambda_3 = 2(\Sigma x^*)_3 - \nu_{\text{ret}} \mu_3 - \nu_{\text{budget}} $$
            Since $\lambda_3 \ge 0$, this tells us that the marginal benefit of investing in asset 3 (based on return and covariance) is less than or equal to the "shadow price" cost. If $\lambda_3 > 0$, it strictly indicates that the non-negativity constraint is binding and preventing the objective from improving further (i.e., we would want to short-sell asset 3 if allowed).
          </div>

          <div class="proof-step">
            <strong>Part (b): Return constraint.</strong> The return constraint $\mu^\top x \ge r_{\text{target}}$ (or $-\mu^\top x \le -r_{\text{target}}$) is active, meaning $\mu^\top x^* = r_{\text{target}}$. The complementary slackness condition is $\nu_{\text{ret}} (\mu^\top x^* - r_{\text{target}}) = 0$, which is satisfied.
            Typically, if a constraint is active, its associated dual variable $\nu_{\text{ret}}$ is positive ($\nu_{\text{ret}} > 0$), reflecting the "cost" or sensitivity of the optimal value to the return requirement.
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.8 ‚Äî Entropy Maximization Dual</h3>
  <p>Consider the entropy maximization problem:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \sum_{i=1}^n x_i \log x_i \quad \text{s.t.} \quad Ax = b, \; \mathbf{1}^\top x = 1, \; x > 0
          $
        </p>
        <p>Derive the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Geometric Programming Connection:</b> The dual of minimizing entropy (or maximizing likelihood) naturally leads to Log-Sum-Exp functions. This connects information theory primal problems to geometric programming duals.</li>
            <li><b>Maximum Entropy Principle:</b> The primal seeks the distribution closest to uniform (max entropy) satisfying moment constraints. The dual finds the parameters of the corresponding exponential family distribution.</li>
        </ul>
      </div>

  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p>Maximum entropy is dual to maximum likelihood (exponential families). The dual involves the Log-Sum-Exp function.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
            <strong>Step 1: Conjugate of negative entropy.</strong>
            The objective function is $f_0(x) = \sum x_i \log x_i$. This is separable, so we can find the conjugate of the scalar function $\phi(u) = u \log u$.
            $\phi^*(y) = \sup_{u > 0} (uy - u \log u)$.
            Setting derivative to zero: $y - (\log u + 1) = 0 \implies \log u = y - 1 \implies u = e^{y-1}$.
            Substituting back: $\phi^*(y) = e^{y-1} y - e^{y-1}(y-1) = e^{y-1}(y - y + 1) = e^{y-1}$.
            Thus, $f_0^*(y) = \sum_{i=1}^n e^{y_i - 1}$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Dual Function.</strong>
            The problem has equality constraints $Ax = b$ and $\mathbf{1}^\top x = 1$. Let $\nu \in \mathbb{R}^m$ be dual variables for $Ax=b$ and $\mu \in \mathbb{R}$ for $\mathbf{1}^\top x = 1$.
            The dual function is:
            $$ g(\nu, \mu) = \inf_x \left( f_0(x) + \nu^\top(Ax - b) + \mu(\mathbf{1}^\top x - 1) \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu + \inf_x \left( f_0(x) + (A^\top \nu + \mu \mathbf{1})^\top x \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - \sup_x \left( -(A^\top \nu + \mu \mathbf{1})^\top x - f_0(x) \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - f_0^*(-(A^\top \nu + \mu \mathbf{1})) $$
          </div>

          <div class="proof-step">
            <strong>Step 3: Substitute Conjugate.</strong>
            $$ g(\nu, \mu) = -b^\top \nu - \mu - \sum_{i=1}^n e^{-(A^\top \nu)_i - \mu - 1} $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - e^{-\mu-1} \sum_{i=1}^n e^{-(A^\top \nu)_i} $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Dual Problem.</strong>
            maximize $g(\nu, \mu)$.
            We can analytically maximize over $\mu$. Let $S(\nu) = \sum_{i=1}^n e^{-(A^\top \nu)_i}$.
            $$ \frac{\partial g}{\partial \mu} = -1 - e^{-\mu-1} S(\nu) \cdot (-1) = -1 + e^{-\mu-1} S(\nu) = 0 $$
            $$ e^{-\mu-1} = \frac{1}{S(\nu)} \implies -\mu-1 = -\log S(\nu) \implies \mu = \log S(\nu) - 1 $$
            Substitute $\mu$ back into $g$:
            $$ g(\nu) = -b^\top \nu - (\log S(\nu) - 1) - \frac{1}{S(\nu)} S(\nu) $$
            $$ g(\nu) = -b^\top \nu - \log S(\nu) + 1 - 1 = -b^\top \nu - \log\left(\sum_{i=1}^n e^{-(A^\top \nu)_i}\right) $$
            The dual problem is:
            $$ \text{maximize} \quad -b^\top \nu - \log\left(\sum_{i=1}^n e^{-a_i^\top \nu}\right) $$
            This is an unconstrained geometric programming dual (Log-Sum-Exp).
          </div>
  </div>
</div>

<div class="problem">
  <h3>P5.9 ‚Äî Farkas' Lemma for SDP</h3>
  <p>Prove the following theorem of alternatives for semidefinite systems (a generalization of Farkas' Lemma):</p>
  <p>Exactly one of the following two systems has a solution:</p>
  <ol>
    <li>Strict primal feasibility: $\exists X \succ 0$ such that $\text{tr}(A_i X) = b_i$ for $i=1,\dots,m$.</li>
    <li>Dual infeasibility certificate: $\exists y \in \mathbb{R}^m$ such that $\sum_{i=1}^m y_i A_i \preceq 0$ and $b^\top y > 0$.</li>
  </ol>
  <p>(Assume linear independence of $A_i$ to ensure regularity).</p>

  <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Theorems of Alternatives:</b> These theorems (like Farkas, Gordan, Stiemke) state that exactly one of two systems is feasible. They are the algebraic equivalent of the geometric Separating Hyperplane Theorem.</li>
        <li><b>SDP Farkas:</b> This generalizes the linear Farkas lemma ($Ax=b, x \ge 0$ vs $A^\top y \ge 0, b^\top y < 0$) to the cone of positive definite matrices. It is used to prove strong duality and detect infeasibility in SDP solvers.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Mutually Exclusive (Easy Direction).</strong>
      Suppose both systems have solutions $X$ and $y$.
      Compute the inner product:
      $$ \text{tr}\left( \left(\sum y_i A_i\right) X \right) = \sum y_i \text{tr}(A_i X) = \sum y_i b_i = b^\top y $$
      From (2), we know $b^\top y > 0$. Let $S = \sum y_i A_i \preceq 0$.
      We examine the trace term $\text{tr}(SX)$. Since $X \succ 0$, we can write $X = L L^\top$.
      Then $\text{tr}(SX) = \text{tr}(S L L^\top) = \text{tr}(L^\top S L)$.
      Let $Y = L^\top S L$. For any vector $v$, $v^\top Y v = (Lv)^\top S (Lv) \le 0$ because $S \preceq 0$. Thus $Y$ is negative semidefinite, so its trace (sum of eigenvalues) is non-positive.
      This implies $b^\top y = \text{tr}(SX) \le 0$.
      We have reached a contradiction: $0 < b^\top y \le 0$. Thus, both systems cannot have solutions simultaneously.
    </div>

    <div class="proof-step">
      <strong>Step 2: Exhaustive (Hard Direction).</strong>
      We use the Separating Hyperplane Theorem.
      Let $\mathcal{K} = \{ (\text{tr}(A_1 X), \dots, \text{tr}(A_m X)) \mid X \succ 0 \} \subseteq \mathbb{R}^m$.
      This set is the image of the open convex cone $\mathbb{S}^n_{++}$ under the linear map $\mathcal{A}(X)$. Since linear maps preserve convexity, $\mathcal{K}$ is a convex set (specifically, a convex cone).
      <br>System 1 states that $b \in \mathcal{K}$.
      <br>If System 1 has no solution, then $b \notin \mathcal{K}$. Since $\mathcal{K}$ is a convex cone, we can strictly separate the point $b$ from $\mathcal{K}$ using a hyperplane passing through the origin.
      There exists a vector $y \in \mathbb{R}^m$ such that:
      $$ y^\top z \le 0 \quad \forall z \in \mathcal{K} \quad \text{and} \quad y^\top b > 0 $$
      Substituting the definition of $\mathcal{K}$:
      $$ y^\top \mathcal{A}(X) \le 0 \implies \sum_{i=1}^m y_i \text{tr}(A_i X) \le 0 \implies \text{tr}\left( \left(\sum_{i=1}^m y_i A_i\right) X \right) \le 0 \quad \forall X \succ 0 $$
      The condition $\text{tr}(SX) \le 0$ for all $X \succ 0$ implies that $S \preceq 0$.
      Thus $\sum y_i A_i \preceq 0$.
      Combined with $y^\top b > 0$, this vector $y$ is a solution to System 2.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P5.10 ‚Äî The Dual via Conjugates</h3>
  <p>Consider the problem:
  $$ \text{minimize } f(x) \quad \text{s.t.} \quad Ax \preceq b, \quad Cx = d $$
  where $f: \mathbb{R}^n \to \mathbb{R}$ is a closed convex function.
  <ol type="a">
    <li>Derive the dual problem solely in terms of the convex conjugate $f^*$, the problem data ($A, b, C, d$), and the dual variables $(\lambda, \nu)$.</li>
    <li>Apply this formula to derive the dual of the <b>Entropy Maximization</b> problem:
    $$ \text{minimize } \sum_{i=1}^n x_i \log x_i \quad \text{s.t.} \quad Ax \le b, \quad \mathbf{1}^\top x = 1 $$
    (Assume implicitly $x \ge 0$ via the domain of the entropy function).</li>
  </ol></p>

  <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Conjugates and Duals:</b> The Lagrange dual function $g(\lambda, \nu)$ is intimately related to the convex conjugate $f^*(y)$. Specifically, $g(\lambda, \nu)$ is often of the form $-f^*(-A^\top \lambda - C^\top \nu) - b^\top \lambda - d^\top \nu$. This provides a mechanical recipe for dualizing problems.</li>
        <li><b>Conjugate Application:</b> This exercise ties the conjugate derivations in Lecture 06 directly to the duality theory in Lecture 09, showing how abstract tools ($f^*$) simplify complex derivations.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Part (a): General Derivation.</strong>
      The Lagrangian is:
      $$ L(x, \lambda, \nu) = f(x) + \lambda^\top (Ax - b) + \nu^\top (Cx - d) $$
      $$ = f(x) + (A^\top \lambda + C^\top \nu)^\top x - b^\top \lambda - d^\top \nu $$
      The dual function is $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$.
      $$ \inf_x \left( f(x) + (A^\top \lambda + C^\top \nu)^\top x \right) = - \sup_x \left( -(A^\top \lambda + C^\top \nu)^\top x - f(x) \right) $$
      Using the definition $f^*(y) = \sup_x (y^\top x - f(x))$, we identify $y = -(A^\top \lambda + C^\top \nu)$.
      Thus:
      $$ g(\lambda, \nu) = -f^*(-(A^\top \lambda + C^\top \nu)) - b^\top \lambda - d^\top \nu $$
      The dual problem is:
      $$ \text{maximize } -b^\top \lambda - d^\top \nu - f^*(-A^\top \lambda - C^\top \nu) \quad \text{s.t. } \lambda \succeq 0 $$
    </div>

    <div class="proof-step">
      <strong>Part (b): Entropy Application.</strong>
      Here $f(x) = \sum x_i \log x_i$. From Lecture 06, the conjugate is $f^*(y) = \sum e^{y_i - 1}$.
      The constraints are $Ax \preceq b$ (multiplier $\lambda \succeq 0$) and $\mathbf{1}^\top x = 1$ (multiplier $\nu \in \mathbb{R}$).
      Applying the formula:
      $$ y = -(A^\top \lambda + \nu \mathbf{1}) = -A^\top \lambda - \nu \mathbf{1} $$
      The dual objective is:
      $$ -b^\top \lambda - \nu - f^*(-A^\top \lambda - \nu \mathbf{1}) $$
      $$ = -b^\top \lambda - \nu - \sum_{i=1}^n \exp( -(A^\top \lambda)_i - \nu - 1 ) $$
      $$ = -b^\top \lambda - \nu - e^{-\nu-1} \sum_{i=1}^n e^{-(A^\top \lambda)_i} $$
      This matches the manual derivation result in P5.8 (after optimizing out $\nu$), but was obtained directly via the general formula.
    </div>
  </div>
</div>

    </section>

<section class="section-card" id="section-10" style="margin-bottom: 32px;">
      <h2>10. Readings & Resources</h2>
      <ul class="link-list">
        <li><strong>Boyd & Vandenberghe, Convex Optimization:</strong> Chapter 5 ‚Äî Duality</li>
        <li><strong>Bertsekas, Convex Optimization Theory:</strong> Chapter 4 ‚Äî Lagrange Multiplier Theory</li>
        <li><strong>Rockafellar, Convex Analysis:</strong> Section 28 ‚Äî Saddle-Functions and Minimax Theory</li>
        <li><strong>Nocedal & Wright, Numerical Optimization:</strong> Chapter 12 ‚Äî Theory of Constrained Optimization</li>
      </ul>
    </section>

    <!-- Readings -->


    <!-- SECTION 10: PROBLEM SET -->

  <footer class="site-footer">
    <div class="container">
      <p style="margin: 0;">
        ¬© <span id="year"></a> Convex Optimization Course ¬∑
        <a href="../../README.md" style="color: var(--brand);">About</a>
      </p>
    </div>
  </footer>
  </main></div>

  <!-- Load Pyodide for Python widgets (optional) -->
  <script defer src="https://cdn.jsdelivr.net/pyodide/v0.26.4/full/pyodide.js"></script>

  <!-- Widget loaders -->
  <script type="module">
    import { initLagrangianExplainer } from './widgets/js/lagrangian-explainer.js';
    initLagrangianExplainer('widget-1');
  </script>
  <script type="module">
    import { initDualityVisualizer } from './widgets/js/duality-visualizer.js';
    initDualityVisualizer('widget-2');
  </script>
  <script type="module">
    import { initKKTChecker } from './widgets/js/kkt-checker.js';
    initKKTChecker('widget-3');
  </script>
  <script type="module">
    import { initDualityRace } from './widgets/js/duality-race.js';
    initDualityRace('widget-4');
  </script>
  <script type="module">
    import { initShadowPrices } from './widgets/js/shadow-prices.js';
    initShadowPrices('widget-5');
  </script>
  <script type="module">
    import { initComplementarySlacknessExplorer } from './widgets/js/complementary-slackness.js';
    initComplementarySlacknessExplorer('widget-6');
  </script>

  <!-- Global utilities -->
  <script src="../../static/js/math-renderer.js"></script>
<script src="../../static/js/ui.js"></script>
<script src="../../static/js/toc.js"></script>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
