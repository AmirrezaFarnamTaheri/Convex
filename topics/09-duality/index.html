<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>09. Duality â€” Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../08-convex-problems-conic/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../10-approximation-fitting/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>09. Duality Theory</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-25</span>
        <span>Duration: 90 min</span>
        <span>Tags: duality, lagrangian, KKT, slater</span>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the core of duality theory. We construct the Lagrangian dual function and prove weak and strong duality theorems. We derive the KKT conditions, interpret dual variables as shadow prices, and show how to use duality for sensitivity analysis and reformulation.</p>
        <p><strong>Prerequisites:</strong> <a href="../04-convex-sets-cones/index.html">Lecture 04: Convex Sets Cones</a> (separating hyperplane theorem), <a href="../06-convex-functions-advanced/index.html">Lecture 06: Advanced Functions</a> (conjugate functions).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul>
        <li>Construct the Lagrangian and Dual Function for any optimization problem</li>
        <li>State and prove Weak Duality and Slater's Condition for Strong Duality</li>
        <li>Derive KKT conditions and use them to solve problems analytically</li>
        <li>Interpret dual variables as sensitivities ("shadow prices")</li>
        <li>Compute duals of LP, QP, SOCP, and SDP problems</li>
      </ul>
    </section>

    <article>
      <section class="section-card" id="section-1">
        <h2>1. The Lagrangian</h2>

        <h3>1.1 Standard Form Primal Problem</h3>
        <p>We consider an optimization problem in standard form (not necessarily convex):</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{minimize} \quad & f_0(x) \\
            \text{subject to} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
            & h_j(x) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>Variable $x \in \mathbb{R}^n$, domain $\mathcal{D} = \bigcap \mathrm{dom}\, f_i \cap \bigcap \mathrm{dom}\, h_j$. Optimal value $p^*$.</p>

        <h3>1.2 The Lagrangian Function</h3>
        <p>The <a href="#" class="definition-link">Lagrangian</a> $L: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ augments the objective with a weighted sum of constraints:</p>
        $$
        L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $$
        <p>where $\lambda_i$ is the Lagrange multiplier associated with $f_i(x) \le 0$, and $\nu_j$ with $h_j(x) = 0$.
        <br>Domain: $\mathrm{dom}\, L = \mathcal{D} \times \mathbb{R}^m \times \mathbb{R}^p$.</p>

        <div class="insight">
          <h4>ðŸ’¡ Idea: Lower Bound Property</h4>
          <p>For any feasible $x$ and any $\lambda \succeq 0, \nu$, we have:
          $$ \sum \lambda_i f_i(x) \le 0 \quad \text{and} \quad \sum \nu_j h_j(x) = 0 $$
          Thus, $L(x, \lambda, \nu) \le f_0(x)$. The Lagrangian is a <b>pointwise underestimator</b> of the objective function on the feasible set.</p>
        </div>
      </section>

      <section class="section-card" id="section-2">
        <h2>2. The Lagrange Dual Function</h2>

        <h3>2.1 Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is the minimum value of the Lagrangian over $x$:
        $$
        g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) = \inf_{x \in \mathcal{D}} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $$
        </p>

        <div class="theorem-box">
          <h4>Key Property: Concavity</h4>
          <p>The dual function $g(\lambda, \nu)$ is <b>concave</b>, even if the primal problem is not convex.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For each fixed $x$, the function $(\lambda, \nu) \mapsto L(x, \lambda, \nu)$ is affine in $(\lambda, \nu)$.
            <br>The dual function $g$ is the pointwise infimum of a family of affine functions.
            <br>The infimum of concave (linear) functions is concave.</p>
          </div>
        </div>

        <h3>2.2 Lower Bound on Optimal Value</h3>
        <p>For any $\lambda \succeq 0$ and any $\nu$, we have:</p>
        $$ g(\lambda, \nu) \le p^* $$
        <div class="proof-box">
          <h4>Proof</h4>
          <p>Let $x^*$ be an optimal feasible solution. By definition of the infimum:
          $$ g(\lambda, \nu) = \inf_x L(x, \lambda, \nu) \le L(x^*, \lambda, \nu) $$
          Expanding the Lagrangian at the optimal point:
          $$ L(x^*, \lambda, \nu) = f_0(x^*) + \sum_{i=1}^m \lambda_i f_i(x^*) + \sum_{j=1}^p \nu_j h_j(x^*) $$
          Since $x^*$ is feasible, $h_j(x^*) = 0$ for all $j$. Also $f_i(x^*) \le 0$. Given $\lambda_i \ge 0$, we have $\lambda_i f_i(x^*) \le 0$. Thus:
          $$ L(x^*, \lambda, \nu) \le f_0(x^*) + 0 + 0 = p^* $$
          Combining the inequalities gives $g(\lambda, \nu) \le p^*$.</p>
        </div>

        <h3>2.3 Examples of Dual Functions</h3>

        <div class="example">
          <h4>1. Least Squares (Quadratic)</h4>
          <p>Primal: $\min x^\top x$ subject to $Ax = b$.
          <br>Lagrangian: $L(x, \nu) = x^\top x + \nu^\top (Ax - b)$.
          <br>Minimize over $x$: $\nabla_x L = 2x + A^\top \nu = 0 \implies x = -A^\top \nu / 2$.
          <br>Substitute back:
          $$ g(\nu) = L(-A^\top \nu / 2, \nu) = \frac{1}{4} \nu^\top A A^\top \nu + \nu^\top (A(-A^\top \nu / 2) - b) $$
          $$ = \frac{1}{4} \|\nu^\top A\|^2 - \frac{1}{2} \|\nu^\top A\|^2 - \nu^\top b = -\frac{1}{4} \nu^\top A A^\top \nu - b^\top \nu $$
          This is a concave quadratic function of $\nu$.
          <br>Dual Problem: Maximize $g(\nu)$. Unconstrained quadratic maximization.</p>
        </div>

        <div class="example">
          <h4>2. Linear Program (Standard Form)</h4>
          <p>Primal: $\min c^\top x$ s.t. $Ax = b, x \ge 0$.
          <br>Constraints: $h(x) = Ax - b$, $f(x) = -x$.
          <br>Lagrangian: $L(x, \lambda, \nu) = c^\top x - \sum \lambda_i x_i + \nu^\top (Ax - b) = -b^\top \nu + (c + A^\top \nu - \lambda)^\top x$.
          <br>Dual function:
          $$ g(\lambda, \nu) = \inf_{x} L(x, \lambda, \nu) = \begin{cases} -b^\top \nu & \text{if } c + A^\top \nu - \lambda = 0 \\ -\infty & \text{otherwise} \end{cases} $$
          Dual Problem: Maximize $-b^\top \nu$ subject to $A^\top \nu + c = \lambda, \lambda \ge 0$.
          <br>Eliminating $\lambda$: Maximize $-b^\top \nu$ subject to $A^\top \nu + c \ge 0$ (i.e., $A^\top (-\nu) \le c$).
          <br>Usually written with $y = -\nu$: Maximize $b^\top y$ s.t. $A^\top y \le c$. Standard LP dual.</p>
        </div>

        <div class="example">
          <h4>3. Conjugate Functions</h4>
          <p>Primal: $\min f(x)$ subject to $x = 0$ (constraint $x=0$).
          <br>Lagrangian: $L(x, \nu) = f(x) + \nu^\top x$.
          <br>Dual function: $g(\nu) = \inf_x (f(x) + \nu^\top x) = -\sup_x ((-\nu)^\top x - f(x)) = -f^*(-\nu)$.
          <br>Here, the dual function is directly related to the <b>convex conjugate</b>.</p>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. The Dual Problem</h2>

        <h3>3.1 Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual problem</a> is to find the best lower bound on $p^*$:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{maximize} \quad & g(\lambda, \nu) \\
            \text{subject to} \quad & \lambda \succeq 0
            \end{aligned}
            $
          </p>
        </div>
        <p>This is a <b>convex optimization problem</b> (concave maximization is equivalent to convex minimization), regardless of the primal's properties.</p>

        <h3>3.2 Weak Duality</h3>
        <p>Let $d^*$ be the optimal value of the dual problem. The weak duality theorem states:</p>
        $$ \boxed{ d^* \le p^* } $$
        <p>This holds for <b>any</b> optimization problem. The difference $p^* - d^*$ is called the <b>duality gap</b>.</p>
        <div class="example">
            <h4>Example: Non-Convex Problem with Gap</h4>
            <p>Consider $\min x^2$ subject to $x \ge 1$ or $x \le -1$ (non-convex constraint $x^2 \ge 1$). Optimal value $p^* = 1$.
            <br>Lagrangian $L(x, \lambda) = x^2 + \lambda(1 - x^2) = (1-\lambda)x^2 + \lambda$.
            <br>Dual function $g(\lambda) = \inf_x L(x, \lambda) = \begin{cases} \lambda & \lambda \le 1 \\ -\infty & \lambda > 1 \end{cases}$.
            <br>Dual problem $\max \lambda$ s.t. $\lambda \le 1$. Dual optimal $d^* = 1$.
            <br>Wait, this example has zero gap! Let's try a different one.
            <br><b>Integer LP:</b> $\min x$ subject to $2x = 1, x \in \{0, 1\}$. Feasible set empty, $p^* = \infty$.
            <br>Relaxed problem (LP): $x=0.5$.
            <br>Often, weak duality gives a bound, but for non-convex problems, $d^* < p^*$. For instance, $\min x^3 - 3x$ has local minima, and the dual might stall at a lower bound.</p>
        </div>

        <h3>3.3 Strong Duality and Slater's Condition</h3>
        <p>Strong duality means $d^* = p^*$ (zero duality gap). It does not hold generally but usually holds for convex problems under mild conditions.</p>

        <div class="theorem-box">
          <h4>Theorem (Slater's Condition)</h4>
          <p>For a convex optimization problem:
          $$ \min f_0(x) \quad \text{s.t.} \quad f_i(x) \le 0, \quad Ax = b $$
          If there exists a point $x \in \mathrm{relint}(\mathcal{D})$ such that:
          $$ f_i(x) < 0, \quad i=1,\dots,m, \quad Ax = b $$
          (strictly feasible for non-affine inequalities), then <b>strong duality holds</b> ($d^* = p^*$) and the dual optimal value is attained (if $p^* > -\infty$).</p>
        </div>

        <div class="proof-box">
          <h4>Geometric Proof via Separation</h4>
          <div class="proof-step">
            <strong>Step 1: Define the Epigraph Set.</strong>
            Define the set of achievable constraint and objective values:
            $$ \mathcal{A} = \{ (u, v, t) \in \mathbb{R}^m \times \mathbb{R}^p \times \mathbb{R} \mid \exists x \in \mathcal{D}, f_i(x) \le u_i, h_j(x) = v_j, f_0(x) \le t \} $$
            Because $f_i$ are convex and $h_j$ are affine, $\mathcal{A}$ is a convex set.
          </div>
          <div class="proof-step">
            <strong>Step 2: Separation.</strong>
            The point $(0, 0, p^* - \epsilon)$ is not in $\mathcal{A}$ (otherwise we could achieve a value better than optimal).
            By the Separating Hyperplane Theorem, there is a non-zero normal $(\lambda, \nu, \mu)$ separating $(0, 0, p^*)$ from $\mathcal{A}$.
            Analysis shows $\lambda \succeq 0$ and $\mu \ge 0$.
            The separation inequality gives:
            $$ \inf_{(u,v,t) \in \mathcal{A}} (\lambda^\top u + \nu^\top v + \mu t) \ge \mu p^* $$
          </div>
          <div class="proof-step">
            <strong>Step 3: Slater's Condition implies $\mu > 0$.</strong>
            Suppose $\mu = 0$. Then for all $x \in \mathcal{D}$, $\sum \lambda_i f_i(x) + \sum \nu_j h_j(x) \ge 0$.
            Apply this to the Slater point $\tilde{x}$:
            $$ \sum \lambda_i f_i(\tilde{x}) + \sum \nu_j (0) \ge 0 $$
            Since $f_i(\tilde{x}) < 0$ and $\lambda_i \ge 0$, the sum can only be $\ge 0$ if all $\lambda_i = 0$.
            But if $\lambda=0$ and $\mu=0$, then $\sum \nu_j h_j(x) \ge 0$ for all $x$. Since $h_j$ are affine ($Ax-b$), $A^\top \nu = 0$ implies $\nu=0$ (assuming full rank). Or more simply, linearity implies equality to 0.
            This contradicts the non-zero normal vector. Thus $\mu > 0$.
          </div>
          <div class="proof-step">
            <strong>Step 4: Strong Duality.</strong>
            Divide by $\mu > 0$ to get normalized multipliers $\tilde{\lambda} = \lambda/\mu, \tilde{\nu} = \nu/\mu$.
            The separation inequality becomes:
            $$ \inf_x (f_0(x) + \sum \tilde{\lambda}_i f_i(x) + \sum \tilde{\nu}_j h_j(x)) \ge p^* $$
            The LHS is exactly the dual function $g(\tilde{\lambda}, \tilde{\nu})$.
            Thus $d^* \ge g(\tilde{\lambda}, \tilde{\nu}) \ge p^*$.
            Combined with weak duality ($d^* \le p^*$), we have $d^* = p^*$.
          </div>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. KKT Conditions</h2>

        <p>The Karush-Kuhn-Tucker (KKT) conditions provide a unified framework for optimality. For convex problems, they are necessary and sufficient.</p>

        <div class="theorem-box">
          <h4>Theorem (KKT Conditions)</h4>
          <p>Given a convex problem with differentiable functions that satisfies Slater's condition. $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal <b>if and only if</b>:</p>
          <ol>
            <li><b>Primal Feasibility:</b> $f_i(x^*) \le 0$, $h_j(x^*) = 0$.</li>
            <li><b>Dual Feasibility:</b> $\lambda^* \succeq 0$.</li>
            <li><b>Complementary Slackness:</b> $\lambda_i^* f_i(x^*) = 0$ for all $i$.</li>
            <li><b>Stationarity (Lagrangian Gradient):</b> $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$:
              $$ \nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0 $$
            </li>
          </ol>
        </div>

        <div class="proof-box">
          <h4>Derivation from Strong Duality</h4>
          <p>If strong duality holds ($p^* = d^*$):
          $$
          \begin{aligned}
          f_0(x^*) &= g(\lambda^*, \nu^*) \\
          &= \inf_x \left( f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_j^* h_j(x) \right) \\
          &\le f_0(x^*) + \sum \lambda_i^* f_i(x^*) + \sum \nu_j^* h_j(x^*) \\
          &\le f_0(x^*)
          \end{aligned}
          $$
          Since the LHS equals the RHS, all inequalities must be equalities.
          <br><b>Equality 1 (Stationarity):</b> The infimum of the Lagrangian with respect to $x$ is attained at $x^*$. For differentiable functions, this implies $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$.
          <br><b>Equality 2 (Complementary Slackness):</b> The term $\sum \lambda_i^* f_i(x^*)$ must be 0. Since $\lambda_i^* \ge 0$ and $f_i(x^*) \le 0$, the sum is non-positive. For it to be zero, each term must be zero: $\lambda_i^* f_i(x^*) = 0$.</p>
        </div>

        <div class="example">
          <h4>Application: Water-Filling (Channel Capacity)</h4>
          <p>Problem: $\min -\sum \log(\alpha_i + x_i)$ subject to $x \ge 0, \sum x_i = 1$.
          <br>Lagrangian: $L = -\sum \log(\alpha_i + x_i) - \sum \lambda_i x_i + \nu (\sum x_i - 1)$.
          <br>Stationarity: $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
          <br>Complementary Slackness: $\lambda_i x_i = 0$.
          <ul>
            <li>If $x_i > 0$, then $\lambda_i = 0 \implies \alpha_i + x_i = 1/\nu$.</li>
            <li>If $x_i = 0$, then $\alpha_i = 1/(\nu-\lambda_i)$. Since $\lambda_i \ge 0$, $\nu - \lambda_i \le \nu$, so $1/(\nu-\lambda_i) \ge 1/\nu$. Thus $\alpha_i \ge 1/\nu$.</li>
          </ul>
          Result: $x_i = \max(0, 1/\nu - \alpha_i)$. This is "water-filling" on the levels $\alpha_i$. We solve for $\nu$ such that $\sum x_i = 1$.</p>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>5. Perturbation and Sensitivity Analysis</h2>

        <p>Duality provides powerful insights into how the optimal value changes when constraints are perturbed.</p>

        <h3>5.1 Perturbed Problem</h3>
        <p>Consider the perturbed primal problem with optimal value $p^*(u, v)$:</p>
        $$
        \begin{aligned}
        \min \quad & f_0(x) \\
        \text{s.t.} \quad & f_i(x) \le u_i, \quad i=1\dots m \\
        & h_j(x) = v_j, \quad j=1\dots p
        \end{aligned}
        $$
        <p>Note: $p^*(0, 0)$ is the original optimal value. $p^*(u, v)$ is a convex function of $(u, v)$.</p>

        <h3>5.2 Global Inequality</h3>
        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>If strong duality holds for the unperturbed problem with dual optimum $(\lambda^*, \nu^*)$, then for any $u, v$:</p>
          $$ p^*(u, v) \ge p^*(0, 0) - \sum \lambda_i^* u_i - \sum \nu_j^* v_j $$
          <p><b>Interpretation:</b> The optimal dual variables define a supporting hyperplane to the perturbation function $p^*(u, v)$ at $(0, 0)$.
          <br>$\lambda_i^*$ is the rate of improvement in objective per unit relaxation of constraint $i$.
          <br>This is why dual variables are called <b>shadow prices</b>.</p>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>
          <p>Let $x$ be feasible for the perturbed problem.
          $$
          \begin{aligned}
          p^*(0, 0) &= g(\lambda^*, \nu^*) \\
          &\le f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_j^* h_j(x) \\
          &\le f_0(x) + \sum \lambda_i^* u_i + \sum \nu_j^* v_j
          \end{aligned}
          $$
          Rearranging: $f_0(x) \ge p^*(0, 0) - \sum \lambda_i^* u_i - \sum \nu_j^* v_j$.
          Minimizing over feasible $x$ gives the result.</p>
        </div>

        <h3>5.3 Local Sensitivity</h3>
        <p>If $p^*(u, v)$ is differentiable at $(0, 0)$, then:</p>
        $$ \frac{\partial p^*(0, 0)}{\partial u_i} = -\lambda_i^*, \quad \frac{\partial p^*(0, 0)}{\partial v_j} = -\nu_j^* $$
        <p>Relaxing constraint $i$ ($u_i > 0$) improves the objective by approximately $\lambda_i^* u_i$. Tightening it ($u_i < 0$) worsens it.</p>
      </section>

      <section class="section-card" id="section-6">
        <h2>6. Examples of Dual Problems</h2>

        <h3>6.1 Linear Programming</h3>
        <p>Primal: $\min c^\top x$ s.t. $Ax \le b, x \ge 0$.
        <br>Dual: $\max -b^\top \lambda$ s.t. $A^\top \lambda + c \ge 0, \lambda \ge 0$. (See Sec 2.3).</p>

        <h3>6.2 Quadratic Programming</h3>
        <p>Primal: $\min \frac{1}{2}x^\top P x + q^\top x$ s.t. $Ax \le b$. ($P \succ 0$).
        <br>Lagrangian: $L(x, \lambda) = \frac{1}{2}x^\top P x + q^\top x + \lambda^\top (Ax - b)$.
        <br>Minimize over $x$: $Px + q + A^\top \lambda = 0 \implies x = -P^{-1}(q + A^\top \lambda)$.
        <br>Dual Function (after algebra):
        $$ g(\lambda) = -\frac{1}{2} \lambda^\top (A P^{-1} A^\top) \lambda - (b + A P^{-1} q)^\top \lambda - \frac{1}{2} q^\top P^{-1} q $$
        This is a concave quadratic maximization.</p>

        <h3>6.3 Semidefinite Programming</h3>
        <p>Primal: $\min \mathrm{tr}(CX)$ s.t. $\mathrm{tr}(A_i X) = b_i, X \succeq 0$.
        <br>We derive the dual using the generalized Lagrangian with matrix inner product.
        <br>Lagrangian: $L(X, \nu) = \mathrm{tr}(CX) + \sum \nu_i (b_i - \mathrm{tr}(A_i X))$. We minimize this over the cone $X \succeq 0$.
        <br>Grouping terms by $X$: $L(X, \nu) = \sum \nu_i b_i + \mathrm{tr}( (C - \sum \nu_i A_i) X )$.
        <br>The infimum of $\mathrm{tr}(MX)$ over $X \succeq 0$ is $-\infty$ unless $M \succeq 0$ (otherwise we can align $X$ with a negative eigenvector). If $M \succeq 0$, the infimum is 0.
        <br>Thus, the dual function is finite only if $C - \sum \nu_i A_i \succeq 0$.
        <br>Dual:
        $$
        \begin{aligned}
        \text{maximize} \quad & b^\top \nu \\
        \text{subject to} \quad & \sum_{i=1}^m \nu_i A_i \preceq C
        \end{aligned}
        $$
        This is another SDP.</p>
      </section>

      <section class="section-card" id="section-7">
        <h2>7. Generalized Inequalities</h2>
        <p>Duality extends to proper cones $K$.
        <br>Primal constraint: $g(x) \preceq_K 0$ (i.e., $g(x) \in -K$).
        <br>Lagrangian term: $\lambda^\top g(x)$ where $\lambda \in K^*$ (dual cone).
        <br>Dual constraint: $\lambda \succeq_{K^*} 0$.
        <br>Complementary slackness: $\lambda^\top g(x) = 0$.</p>
      </section>

      <section class="section-card" id="section-8">
        <h2>8. Review & Cheat Sheet</h2>
        <h3>Key Definitions</h3>
        <ul>
          <li><b>Lagrangian:</b> $L(x, \lambda, \nu) = f_0(x) + \lambda^\top f(x) + \nu^\top h(x)$.</li>
          <li><b>Dual Function:</b> $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$. (Always Concave).</li>
          <li><b>Weak Duality:</b> $d^* \le p^*$. (Always true).</li>
          <li><b>Strong Duality:</b> $d^* = p^*$. (Usually true for convex via Slater).</li>
        </ul>

        <h3>KKT Conditions (Convex + Slater $\iff$ Optimal)</h3>
        <ol>
          <li>$f_i(x) \le 0, h_j(x) = 0$ (Primal Feas)</li>
          <li>$\lambda_i \ge 0$ (Dual Feas)</li>
          <li>$\lambda_i f_i(x) = 0$ (Comp. Slackness)</li>
          <li>$\nabla f_0 + \sum \lambda_i \nabla f_i + \sum \nu_j \nabla h_j = 0$ (Stationarity)</li>
        </ol>
      </section>

      <section class="section-card" id="section-9">
        <h2><i data-feather="edit-3"></i> 9. Exercises</h2>

      <div class="insight">
        <h4>Recap & Key Concepts</h4>
        <p>These exercises consolidate your understanding of Lagrangian duality. We move from deriving duals of standard problems (QP, LP) to applying KKT conditions for analytic solutions (Water-filling), and finally using Strong Duality to prove fundamental theorems like Farkas' Lemma.</p>
      </div>

<div class="problem">
  <h3>P9.1 â€” Deriving the Dual of a Quadratic Program</h3>
  <p>Consider the QP: $\min x^\top x$ subject to $Ax \preceq b$.
  <br>(a) Derive the Lagrange dual function $g(\lambda)$.
  <br>(b) State the dual problem explicitly.
  <br>(c) Verify weak duality directly for any feasible $x$ and $\lambda$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>The dual of a strictly convex QP is another QP. Minimizing the primal quadratic is related to maximizing a concave quadratic in the dual variables. Weak duality can be verified algebraically by completing the square.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>(a) Dual Function:</strong>
      $L(x, \lambda) = x^\top x + \lambda^\top (Ax - b)$.
      $\nabla_x L = 2x + A^\top \lambda = 0 \implies x^* = -1/2 A^\top \lambda$.
      $g(\lambda) = (-1/2 A^\top \lambda)^\top (-1/2 A^\top \lambda) + \lambda^\top (A(-1/2 A^\top \lambda) - b)$
      $= 1/4 \lambda^\top A A^\top \lambda - 1/2 \lambda^\top A A^\top \lambda - b^\top \lambda$
      $= -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$.
    </div>
    <div class="proof-step">
      <strong>(b) Dual Problem:</strong>
      $\max -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$ subject to $\lambda \ge 0$.
    </div>
    <div class="proof-step">
      <strong>(c) Weak Duality:</strong>
      $x^\top x - (-1/4 \lambda^\top A A^\top \lambda - b^\top \lambda) = \|x + 1/2 A^\top \lambda\|^2 - \lambda^\top(Ax - b)$.
      Since $\lambda \ge 0$ and $Ax - b \le 0$, the term $-\lambda^\top(Ax-b) \ge 0$. The norm is $\ge 0$. Sum $\ge 0$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.2 â€” KKT Conditions for Entropy Maximization</h3>
  <p>Maximize the entropy $-\sum x_i \log x_i$ subject to $\mathbf{1}^\top x = 1$ and $Ax \le b$.
  <br>Derive the KKT conditions. Show that the optimal solution has the form $x_i = e^{-\nu - 1 - (A^\top \lambda)_i}$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>Entropy maximization naturally leads to exponential family distributions. The dual variables in the exponent correspond to the constraints (Gibbs distribution). This is the foundation of Maximum Entropy modeling.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>Lagrangian: $L = \sum x_i \log x_i + \nu(\sum x_i - 1) + \lambda^\top (Ax - b)$. (Note: minimizing neg entropy).
    <br>Stationarity: $1 + \log x_i + \nu + (A^\top \lambda)_i = 0$.
    <br>Solving for $x_i$: $\log x_i = -1 - \nu - (A^\top \lambda)_i \implies x_i = \exp(\dots)$.
    <br>Constraints: $\lambda \ge 0$, $\lambda^\top (Ax - b) = 0$, primal feasibility.</p>
  </div>
</div>

<div class="problem">
  <h3>P9.3 â€” Sensitivity Analysis and Shadow Prices</h3>
  <p>Consider $\min x^2$ s.t. $x \le -1$. Optimal $x^*=-1, p^*=1$.
  <br>Perturb to $x \le -1 + u$. New optimum $x^* = -1+u$ (for small $u$), $p^*(u) = (-1+u)^2 \approx 1 - 2u$.
  <br>Find the dual optimal $\lambda^*$ of the original problem and verify $p^*(u) \approx p^*(0) - \lambda^* u$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>The optimal dual variable $\lambda^*$ acts as a sensitivity coefficient (shadow price). It tells you how much the optimal value improves if you relax the constraint by one unit. Here, relaxing the constraint to $x \le 0$ reduces the cost significantly.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>$L(x, \lambda) = x^2 + \lambda(x+1)$. $\nabla_x L = 2x + \lambda = 0 \implies x = -\lambda/2$.
    <br>Dual $g(\lambda) = \lambda^2/4 - \lambda^2/2 + \lambda = -1/4 \lambda^2 + \lambda$.
    <br>Max at $\lambda^* = 2$. Dual value $-1 + 2 = 1 = p^*$.
    <br>Sensitivity: $p^*(u) \approx 1 - \lambda^* u = 1 - 2u$. Matches first order expansion of $(1-u)^2$.</p>
  </div>
</div>
<div class="problem">
  <h3>P9.4 â€” Dual of a Linear Program</h3>
  <p>Derive the dual of the standard form LP:
  $$ \min c^\top x \quad \text{s.t.} \quad Ax = b, \ x \ge 0 $$
  Show it is $\max -b^\top \nu$ s.t. $A^\top \nu + c \ge 0$ (or equivalently $\max b^\top y$ s.t. $A^\top y \le c$ via reparameterization).</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>The dual of an LP is another LP. The variables of the dual correspond to the constraints of the primal. This symmetric relationship is unique to Linear Programming.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Lagrangian.</strong>
      The constraints are $Ax - b = 0$ and $-x \le 0$.
      $L(x, \lambda, \nu) = c^\top x - \lambda^\top x + \nu^\top (Ax - b) = -b^\top \nu + (c - \lambda + A^\top \nu)^\top x$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Dual Function.</strong>
      $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$.
      If the coefficient of $x$ is not zero, the infimum is $-\infty$.
      Thus $g(\lambda, \nu) = -b^\top \nu$ if $c - \lambda + A^\top \nu = 0$, else $-\infty$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Problem.</strong>
      Maximize $-b^\top \nu$ subject to $\lambda \ge 0$ and $c - \lambda + A^\top \nu = 0$.
      Eliminate $\lambda$: $\lambda = c + A^\top \nu$. The condition $\lambda \ge 0$ becomes $c + A^\top \nu \ge 0$, or $A^\top (-\nu) \le c$.
      Let $y = -\nu$. Then we maximize $b^\top y$ subject to $A^\top y \le c$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.5 â€” Farkas' Lemma</h3>
  <p>Use Strong Duality for LP to prove Farkas' Lemma:
  Exactly one of the following systems has a solution:
  <ol>
    <li>$Ax = b, \ x \ge 0$</li>
    <li>$A^\top y \ge 0, \ b^\top y < 0$</li>
  </ol>
  </p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>Farkas' Lemma is a theorem of alternatives. It says that if a linear system is infeasible, there is a certificate (hyperplane) proving it. Strong duality provides the mechanism to find this certificate (an unbounded dual ray).</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      Consider the LP: $p^* = \min \{ 0^\top x \mid Ax = b, x \ge 0 \}$.
      If (1) is feasible, $p^* = 0$. If infeasible, $p^* = \infty$.
    </div>
    <div class="proof-step">
      The dual is: $d^* = \max \{ -b^\top \nu \mid A^\top \nu \ge 0 \}$.
      (Here we use $\nu$ for equality multiplier, and absorb sign).
      Or standard dual of $\min 0$ s.t. $Ax=b, x \ge 0$ is $\max b^\top y$ s.t. $A^\top y \le 0$.
      Let's stick to standard form.
      Dual of $\min 0^\top x$ s.t. $Ax=b, x \ge 0$ is $\max b^\top y$ s.t. $A^\top y \le 0$.
    </div>
    <div class="proof-step">
      <strong>Case 1: (1) has a solution (Feasible).</strong>
      If there exists $x \ge 0$ such that $Ax=b$, the primal optimal value is $p^* = 0^\top x = 0$.
      <br>Since the primal is an LP, Strong Duality holds (assuming feasibility). Thus, the dual optimal value is also $d^* = 0$.
      <br>The dual problem is to maximize $b^\top y$ subject to $A^\top y \le 0$.
      Since the maximum is 0, for <i>every</i> feasible dual variable $y$ (where $A^\top y \le 0$), we must have $b^\top y \le 0$.
      <br>This means there is <b>no</b> vector $y$ satisfying $A^\top y \le 0$ AND $b^\top y > 0$.
      <br>Let $z = -y$. The non-existence of such a $y$ implies there is no $z$ such that $A^\top (-z) \le 0 \implies A^\top z \ge 0$ AND $b^\top (-z) > 0 \implies b^\top z < 0$.
      <br>Thus, system (2) has <b>no solution</b>.
      <br><i>Connection:</i> This is the "Alternative Systems" logic. Strong duality says "Primal Feasible $\iff$ Dual Bounded". If Primal is Infeasible ($p^* = \infty$), then Dual is Unbounded ($d^* = \infty$), which means there exists an improving direction $y$ making $b^\top y \to \infty$. This direction is exactly the certificate of infeasibility.
    </div>
    <div class="proof-step">
      <strong>Case 2: (1) has no solution (Infeasible).</strong>
      If the primal is infeasible, then $p^* = +\infty$ (by convention for minimization).
      <br>By Strong Duality for LPs, $d^* = p^* = +\infty$.
      <br>This means the dual problem $\max \{ b^\top y \mid A^\top y \le 0 \}$ is unbounded above.
      <br>For the objective $b^\top y$ to grow arbitrarily large while $y$ remains in the cone $A^\top y \le 0$, there must exist a direction $y$ such that $A^\top y \le 0$ and $b^\top y > 0$ (otherwise the max would be 0).
      <br>Let $z = -y$. Then $A^\top (-z) \le 0 \implies A^\top z \ge 0$ and $b^\top (-z) > 0 \implies b^\top z < 0$.
      <br>This $z$ is a solution to system (2). Thus, system (2) <b>has a solution</b>.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.6 â€” KKT for Water-filling</h3>
  <p>Solve $\min \sum_{i=1}^n -\log(\alpha_i + x_i)$ subject to $x \ge 0, \mathbf{1}^\top x = 1$. Assume $\alpha_i > 0$. Derive the water-filling solution.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>Water-filling is the analytic solution to allocating a limited resource to maximize the sum of concave utility functions. The KKT conditions reveal that the marginal gain must be equal for all active channels, up to a threshold.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Lagrangian:</strong> $L(x, \lambda, \nu) = -\sum \log(\alpha_i + x_i) - \lambda^\top x + \nu(\sum x_i - 1)$.
    </div>
    <div class="proof-step">
      <strong>Stationarity:</strong> $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
    </div>
    <div class="proof-step">
      <strong>Complementary Slackness:</strong> $\lambda_i x_i = 0, \lambda_i \ge 0, x_i \ge 0$.
      <ul>
        <li>Case 1: $x_i > 0$. Then $\lambda_i = 0$. The stationarity condition becomes $\frac{1}{\alpha_i + x_i} = \nu \implies \alpha_i + x_i = \frac{1}{\nu}$. Thus $x_i = \frac{1}{\nu} - \alpha_i$. (Note: for $x_i > 0$, we need $1/\nu > \alpha_i$).</li>
        <li>Case 2: $x_i = 0$. The stationarity condition is $\frac{1}{\alpha_i} = \nu - \lambda_i$. Since $\lambda_i \ge 0$, we have $\nu - \lambda_i \le \nu$.
        Assuming $\nu > 0$ and $\nu - \lambda_i > 0$, taking reciprocals reverses the inequality:
        $$ \frac{1}{\nu - \lambda_i} \ge \frac{1}{\nu} $$
        Substituting back: $\alpha_i \ge \frac{1}{\nu}$.
        </li>
      </ul>
    </div>
    <div class="proof-step">
      <strong>Combined Solution:</strong>
      Combining the cases:
      $$ x_i = \max\left(0, \frac{1}{\nu} - \alpha_i\right) $$
      Here $\mu = 1/\nu$ acts as the "water level". We choose the water level such that the total amount of water poured equals the budget: $\sum x_i = 1$.
    </div>
  </div>
</div>


      </section>
    </article>

    <footer class="site-footer">
      <div class="container">
        <p>Â© <span id="year"></a> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
