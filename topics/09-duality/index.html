<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>09. Duality — Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../08-convex-problems-conic/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../10-approximation-fitting/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>09. Duality Theory</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-25</span>
        <span>Duration: 90 min</span>
        <span>Tags: duality, lagrangian, KKT, slater</span>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the core of duality theory. We construct the Lagrangian dual function and prove weak and strong duality theorems. We derive the KKT conditions, interpret dual variables as shadow prices, and show how to use duality for sensitivity analysis and reformulation.</p>
        <p><strong>Prerequisites:</strong> <a href="../04-convex-sets-cones/index.html">Lecture 04: Convex Sets Cones</a> (separating hyperplane theorem), <a href="../06-convex-functions-advanced/index.html">Lecture 06: Advanced Functions</a> (conjugate functions).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul>
        <li>Construct the Lagrangian and Dual Function for any optimization problem</li>
        <li>State and prove Weak Duality and Slater's Condition for Strong Duality</li>
        <li>Derive KKT conditions and use them to solve problems analytically</li>
        <li>Interpret dual variables as sensitivities ("shadow prices")</li>
        <li>Compute duals of LP, QP, SOCP, and SDP problems</li>
      </ul>
    </section>

    <article>
      <section class="section-card" id="section-1">
        <h2>1. Conjugates and Support Functions: The Machinery of Duality</h2>

        <p>Before diving into the Lagrangian, we need the "engine" that manufactures dual problems: the convex conjugate. This tool turns geometry (supporting hyperplanes) into algebra.</p>

        <h3>1.1 Convex Conjugate (Fenchel Conjugate)</h3>
        <p>For a function $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$, the conjugate is:
        $$ \boxed{f^*(y) = \sup_{x \in \mathrm{dom}(f)} \big( y^\top x - f(x) \big)} $$
        Interpretation: $f^*(y)$ is the maximum "profit" of using a linear function with slope $y$ to estimate $f$. Equivalently, for any $y$, the affine function $h(x) = y^\top x - f^*(y)$ is a global underestimator of $f$:
        $$ f(x) \ge y^\top x - f^*(y) \quad \text{(Fenchel-Young Inequality)} $$
        </p>

        <div class="proof-box">
          <h4>Key Fact: $f^*$ is always convex</h4>
          <p>For each fixed $x$, the function $g_x(y) = y^\top x - f(x)$ is affine in $y$.
          <br>$f^*(y)$ is the pointwise supremum of a family of affine functions.
          <br>The supremum of any collection of convex functions is convex. Thus, $f^*$ is convex (and lower semicontinuous), regardless of whether $f$ is convex.</p>
        </div>

        <h3>1.2 Subgradients and Conjugate Equality</h3>
        <p>For a closed convex function $f$, the Fenchel-Young inequality becomes an equality exactly when $y$ is a subgradient of $f$ at $x$ (or vice-versa):
        $$ \boxed{y \in \partial f(x) \iff f(x) + f^*(y) = x^\top y \iff x \in \partial f^*(y)} $$
        This is the "bridge" fact that connects analytic optimality (gradients) with dual algebraic identities.</p>

        <h3>1.3 Support Functions and Dual Norms</h3>
        <p>For a set $C$, the <b>indicator function</b> $I_C(x)$ is 0 if $x \in C$ and $+\infty$ otherwise. Its conjugate is the <b>support function</b>:
        $$ I_C^*(y) = \sup_x (y^\top x - I_C(x)) = \sup_{x \in C} y^\top x =: \sigma_C(y) $$
        If $C$ is the unit ball of a norm $\|\cdot\|$, then $\sigma_C(y)$ is exactly the <b>dual norm</b> $\|y\|_*$.
        $$ \boxed{ (\|\cdot\|)^* = I_{\{\|y\|_* \le 1\}} } $$
        Conjugating a norm gives the indicator of the dual unit ball. This is how norms in the primal turn into constraints in the dual.</p>
      </section>

      <section class="section-card" id="section-2">
        <h2>2. Lagrangian Duality</h2>

        <h3>2.1 The Problem and the Lagrangian</h3>
        <p>We consider the standard minimization problem:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{minimize} \quad & f_0(x) \\
            \text{subject to} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
            & h_j(x) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>The <b>Lagrangian</b> $L: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ "softens" the constraints:
        $$ L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) $$
        with domain $\mathcal{D} \times \mathbb{R}^m \times \mathbb{R}^p$. We require $\lambda \succeq 0$.
        </p>

        <h3>2.2 The Dual Function</h3>
        <p>The <b>Lagrange dual function</b> $g(\lambda, \nu)$ is the minimum value of the Lagrangian over $x$:
        $$ \boxed{ g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) } $$
        Since it is the pointwise infimum of affine functions of $(\lambda, \nu)$, <b>$g$ is always concave</b>.</p>

        <h3>2.3 Weak Duality</h3>
        <p>For any feasible $x$ and any $\lambda \succeq 0, \nu$:
        $$ L(x, \lambda, \nu) = f_0(x) + \underbrace{\sum \lambda_i f_i(x)}_{\le 0} + \underbrace{\sum \nu_j h_j(x)}_{= 0} \le f_0(x) $$
        Minimizing the LHS over all $x$ (feasible or not) gives $g(\lambda, \nu)$. Minimizing the RHS over feasible $x$ gives $p^*$. Thus:
        $$ \boxed{ g(\lambda, \nu) \le p^* } $$
        This lower bound holds for any optimization problem.</p>

        <h3>2.4 The Dual Problem</h3>
        <p>To get the best lower bound, we maximize the dual function:
        $$
        \begin{aligned}
        \text{maximize} \quad & g(\lambda, \nu) \\
        \text{subject to} \quad & \lambda \succeq 0
        \end{aligned}
        $$
        Let $d^*$ be the optimal value. Weak duality says $d^* \le p^*$. The difference $p^* - d^*$ is the <b>duality gap</b>.</p>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. Strong Duality and Slater's Condition</h2>

        <p>When does $d^* = p^*$? This is <b>Strong Duality</b>. It does not hold generally (duality gap > 0 is possible for nonconvex problems), but for convex problems, it usually holds under mild regularity conditions.</p>

        <div class="theorem-box">
          <h4>Theorem (Slater's Condition)</h4>
          <p>For a convex problem (convex $f_i$, affine $h_j$), if there exists a point $x \in \mathrm{relint}(\mathcal{D})$ such that:
          $$ f_i(x) < 0 \quad \text{for all non-affine } f_i, \quad Ax = b $$
          then <b>strong duality holds</b> ($d^* = p^*$) and the dual optimal value is attained (if $p^* > -\infty$).</p>
        </div>

        <div class="proof-box">
          <h4>Geometric Intuition via Value Function</h4>
          <p>Let $v(u, w) = \inf \{ f_0(x) \mid f_i(x) \le u_i, h_j(x) = w_j \}$ be the <b>perturbation function</b> (optimal value as a function of constraint RHS).
          <br>This function is convex. $p^* = v(0,0)$.
          <br>The dual problem corresponds to finding a supporting hyperplane to the epigraph of $v$ at $(0,0,p^*)$.
          <br>Slater's condition ensures that $(0,0)$ is in the "nice interior" of the domain of $v$, which guarantees the existence of a non-vertical supporting hyperplane. The slopes of this hyperplane are the optimal Lagrange multipliers.</p>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. KKT Conditions</h2>

        <p>The Karush-Kuhn-Tucker (KKT) conditions provide a unified framework for optimality. For convex problems, they are necessary and sufficient.</p>

        <div class="theorem-box">
          <h4>Theorem (KKT Conditions)</h4>
          <p>Given a convex problem with differentiable functions that satisfies Slater's condition. $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal <b>if and only if</b>:</p>
          <ol>
            <li><b>Primal Feasibility:</b> $f_i(x^*) \le 0$, $h_j(x^*) = 0$.</li>
            <li><b>Dual Feasibility:</b> $\lambda^* \succeq 0$.</li>
            <li><b>Complementary Slackness:</b> $\lambda_i^* f_i(x^*) = 0$ for all $i$.</li>
            <li><b>Stationarity (Lagrangian Gradient):</b> $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$:
              $$ \nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0 $$
            </li>
          </ol>
        </div>

        <div class="proof-box">
          <h4>Derivation from Strong Duality</h4>
          <p>Assume strong duality holds ($p^* = d^*$) and let $x^*$ and $(\lambda^*, \nu^*)$ be primal and dual optimal.</p>
          <div class="proof-step">
            <strong>The Duality Sandwich:</strong>
            We construct a chain of inequalities starting from the optimal dual value and ending at the optimal primal value.
            $$
            \begin{aligned}
            d^* &= g(\lambda^*, \nu^*) \quad \text{(Definition of Dual Optimal)} \\
            &= \inf_x \left( f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_j^* h_j(x) \right) \quad \text{(Definition of Dual Function)} \\
            &\le f_0(x^*) + \sum \lambda_i^* f_i(x^*) + \sum \nu_j^* h_j(x^*) \quad \text{(Infimum is } \le \text{ value at } x^*) \\
            &\le f_0(x^*) \quad \text{(Since } \lambda^* \ge 0 \text{ and } f_i(x^*) \le 0 \text{, the sum is } \le 0) \\
            &= p^* \quad \text{(Definition of Primal Optimal)}
            \end{aligned}
            $$
            Because Strong Duality holds ($d^* = p^*$), the start and end of this chain are equal. This forces <b>every inequality in the middle to be an equality</b>.
          </div>
          <div class="proof-step">
            <strong>Conclusion 1: Stationarity.</strong>
            The inequality $\inf_x L(x, \lambda^*, \nu^*) \le L(x^*, \lambda^*, \nu^*)$ becomes an equality.
            This implies that $x^*$ is a global minimizer of the Lagrangian function $L(x, \lambda^*, \nu^*)$ with respect to $x$.
            If the functions are differentiable, the gradient at a global minimizer (of an unconstrained problem) must be zero:
            $$ \nabla_x L(x^*, \lambda^*, \nu^*) = 0 $$
          </div>
          <div class="proof-step">
            <strong>Conclusion 2: Complementary Slackness.</strong>
            The inequality $L(x^*, \lambda^*, \nu^*) \le f_0(x^*)$ is also an equality. This means:
            $$ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0 $$
            Since every term $\lambda_i^* f_i(x^*)$ is non-positive (product of $\ge 0$ and $\le 0$), the sum can only be zero if <b>every single term is zero</b>.
            $$ \lambda_i^* f_i(x^*) = 0, \quad \forall i $$
          </div>
        </div>

        <div class="example">
          <h4>Application: Water-Filling (Channel Capacity)</h4>
          <p>Problem: $\min -\sum \log(\alpha_i + x_i)$ subject to $x \ge 0, \sum x_i = 1$.
          <br>Lagrangian: $L = -\sum \log(\alpha_i + x_i) - \sum \lambda_i x_i + \nu (\sum x_i - 1)$.
          <br>Stationarity: $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
          <br>Complementary Slackness: $\lambda_i x_i = 0$.
          <ul>
            <li>If $x_i > 0$, then $\lambda_i = 0 \implies \alpha_i + x_i = 1/\nu$.</li>
            <li>If $x_i = 0$, then $\alpha_i = 1/(\nu-\lambda_i)$. Since $\lambda_i \ge 0$, $\nu - \lambda_i \le \nu$, so $1/(\nu-\lambda_i) \ge 1/\nu$. Thus $\alpha_i \ge 1/\nu$.</li>
          </ul>
          Result: $x_i = \max(0, 1/\nu - \alpha_i)$. This is "water-filling" on the levels $\alpha_i$. We solve for $\nu$ such that $\sum x_i = 1$.</p>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>5. Perturbation and Sensitivity Analysis</h2>

        <p>Dual variables ($\lambda, \nu$) are not just "bookkeeping" variables—they are <b>derivatives of the optimal value</b>. They quantify the sensitivity of the optimum to constraints.</p>

        <h3>5.1 The Value Function</h3>
        <p>Consider the perturbed primal problem where we relax inequalities by $u_i$ and shift equalities by $v_j$:</p>
        $$ p^*(u, v) = \inf \{ f_0(x) \mid f_i(x) \le u_i, h_j(x) = v_j \} $$
        <p>The original optimal value is $p^*(0, 0)$.
        <br><b>Fact:</b> If the problem is convex, $p^*(u, v)$ is a convex function of $(u, v)$. (Proof: The epigraph of $p^*$ is a projection of a convex set).</p>

        <h3>5.2 Multipliers as Subgradients</h3>
        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>If strong duality holds and the dual optimum $(\lambda^*, \nu^*)$ is attained, then:
          $$ (-\lambda^*, -\nu^*) \in \partial p^*(0, 0) $$
          This means that for any perturbation $(u, v)$:
          $$ p^*(u, v) \ge p^*(0, 0) - (\lambda^*)^\top u - (\nu^*)^\top v $$
          </p>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>
          <p>By weak duality for the perturbed problem, for any feasible $x$ (satisfying constraints with $u, v$):
          $$
          \begin{aligned}
          p^*(0, 0) = g(\lambda^*, \nu^*) &= \inf_z \left( f_0(z) + \sum \lambda_i^* f_i(z) + \sum \nu_j^* h_j(z) \right) \\
          &\le f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_j^* h_j(x) \\
          &\le f_0(x) + \sum \lambda_i^* u_i + \sum \nu_j^* v_j \quad \text{(since } \lambda^* \ge 0, f_i(x) \le u_i)
          \end{aligned}
          $$
          Thus $f_0(x) \ge p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v$. Minimizing over $x$ gives the result.</p>
        </div>

        <h3>5.3 Shadow Prices (Economic Interpretation)</h3>
        <p>If $p^*(u, v)$ is differentiable at $(0, 0)$, then $\nabla p^*(0, 0) = (-\lambda^*, -\nu^*)$.
        <br>$\lambda_i^* = -\frac{\partial p^*}{\partial u_i}$.
        <br>Since relaxing a constraint ($u_i > 0$) usually decreases the optimal cost, the negative sign makes sense. $\lambda_i^*$ is the <b>marginal improvement</b> in the objective per unit relaxation of constraint $i$. If $\lambda_i^* = 0$, the constraint is not binding (slack); relaxing it does nothing locally.</p>
      </section>

      <section class="section-card" id="section-6">
        <h2>6. Conic Duality</h2>

        <p>Everything unifies under the conic template. Let $K \subseteq \mathbb{R}^n$ be a proper cone. Its <b>dual cone</b> is $K^* = \{s \mid s^\top x \ge 0 \ \forall x \in K\}$.</p>

        <h3>6.1 Primal and Dual Conic Problems</h3>
        <p><b>Primal:</b> $\min c^\top x$ s.t. $Ax = b, x \in K$.
        <br><b>Dual:</b> $\max b^\top y$ s.t. $c - A^\top y = s, s \in K^*$.</p>

        <h3>6.2 Examples of Cones</h3>
        <ul>
          <li><b>LP ($K = \mathbb{R}^n_+$):</b> Self-dual ($K^* = K$). Dual constraints are $c - A^\top y \ge 0$.</li>
          <li><b>SOCP ($K = \text{Second-order cone}$):</b> Self-dual. Constraints involve $\ell_2$ norms.</li>
          <li><b>SDP ($K = \mathbb{S}^n_+$):</b> Self-dual. Constraints are Linear Matrix Inequalities (LMIs). $C - \sum y_i A_i \succeq 0$.</li>
        </ul>

        <h3>6.3 Conic Complementary Slackness</h3>
        <p>If $x$ and $(y, s)$ are primal/dual optimal, then $x^\top s = 0$.
        <br>Since $x \in K, s \in K^*$, we always have $x^\top s \ge 0$. The condition $x^\top s = 0$ means the vectors are orthogonal (on the boundary of their respective cones).</p>
      </section>

      <section class="section-card" id="section-8">
        <h2>8. Review & Cheat Sheet</h2>
        <h3>Key Definitions</h3>
        <ul>
          <li><b>Lagrangian:</b> $L(x, \lambda, \nu) = f_0(x) + \lambda^\top f(x) + \nu^\top h(x)$.</li>
          <li><b>Dual Function:</b> $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$. (Always Concave).</li>
          <li><b>Weak Duality:</b> $d^* \le p^*$. (Always true).</li>
          <li><b>Strong Duality:</b> $d^* = p^*$. (Usually true for convex via Slater).</li>
        </ul>

        <h3>KKT Conditions (Convex + Slater $\iff$ Optimal)</h3>
        <ol>
          <li>$f_i(x) \le 0, h_j(x) = 0$ (Primal Feas)</li>
          <li>$\lambda_i \ge 0$ (Dual Feas)</li>
          <li>$\lambda_i f_i(x) = 0$ (Comp. Slackness)</li>
          <li>$\nabla f_0 + \sum \lambda_i \nabla f_i + \sum \nu_j \nabla h_j = 0$ (Stationarity)</li>
        </ol>
      </section>

      <section class="section-card" id="section-9">
        <h2><i data-feather="edit-3"></i> 9. Exercises</h2>

        <div class="insight">
          <h4>Recap & Key Concepts</h4>
          <p>These exercises consolidate your understanding of Lagrangian duality. We move from deriving duals of standard problems (QP, LP) to applying KKT conditions for analytic solutions (Water-filling), and finally using Strong Duality to prove fundamental theorems like Farkas' Lemma.</p>
        </div>

        <h3>Appendix: The Micro-Toolbox</h3>
        <p>Before solving, master these 4 lemmas. You will use them in almost every dual derivation.</p>

        <div class="problem">
          <h4>Lemma A1: Linear Term Blow-up</h4>
          <p>$\inf_{x} a^\top x = \begin{cases} 0 & a=0 \\ -\infty & a \ne 0 \end{cases}$. This generates dual constraints (like $A^\top y + c = 0$).</p>
        </div>

        <div class="problem">
          <h4>Lemma A2: Quadratic Minimization</h4>
          <p>For $P \succ 0$: $\inf_x (\frac{1}{2}x^\top P x + q^\top x) = -\frac{1}{2} q^\top P^{-1} q$. The minimizer is $x^* = -P^{-1}q$.</p>
        </div>

        <div class="problem">
          <h4>Lemma A3: Conjugate of a Norm</h4>
          <p>$(\rho \|x\|)^* (z) = I_{\{\|z\|_* \le \rho\}}(z)$. This generates dual norm constraints (like $\|A^\top y\|_\infty \le \lambda$).</p>
        </div>

        <div class="problem">
          <h4>Lemma A4: Indicator Duality</h4>
          <p>$I_C^*(y) = \sigma_C(y)$ (Support Function). This turns constraints into support functions.</p>
        </div>

        <h3>P9.1 — Least Squares Dual (Residual Form)</h3>
        <p>Derive the dual of $\min \frac{1}{2}\|r\|_2^2$ s.t. $r = Ax - b$.
        <br><b>Solution:</b> $\max_y b^\top y - \frac{1}{2}\|y\|_2^2$ s.t. $A^\top y = 0$. (Check: dual variable $y$ is related to residual $r$ by $y = -r$).</p>

        <h3>P9.2 — Ridge Regression Dual</h3>
        <p>Derive the dual of $\min \frac{1}{2}\|Ax-b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$.
        <br><b>Hint:</b> Use variable splitting $r = Ax-b$ or conjugate calculus.
        <br><b>Solution:</b> $\max_y b^\top y - \frac{1}{2}\|y\|_2^2 - \frac{1}{2\lambda}\|A^\top y\|_2^2$.
        <br><b>Recover Primal:</b> $x^* = \frac{1}{\lambda} A^\top y^*$.
        <br><b>Gap Certificate:</b> $p(x) - d(y) \ge 0$. Use $y = b-Ax$ as a candidate.</p>

        <h3>P9.3 — LASSO Dual</h3>
        <p>Derive the dual of $\min \frac{1}{2}\|Ax-b\|_2^2 + \lambda \|x\|_1$.
        <br><b>Solution:</b> $\max_y b^\top y - \frac{1}{2}\|y\|_2^2$ s.t. $\|A^\top y\|_\infty \le \lambda$.
        <br><b>Geometric Interpretation:</b> The dual constraint $\|A^\top y\|_\infty \le \lambda$ enforces the correlation of the residual with every feature to be bounded. When the constraint binds, the feature enters the model.</p>

        <h3>P9.4 — Basis Pursuit</h3>
        <p>Derive the dual of $\min \|x\|_1$ s.t. $Ax=b$.
        <br><b>Solution:</b> $\max b^\top y$ s.t. $\|A^\top y\|_\infty \le 1$.
        <br><b>Certificate:</b> If you have a feasible $x$ and $y$ with small gap, you have a proof of near-optimality.</p>

        <h3>P9.5 — SVM Dual (Soft Margin)</h3>
        <p>Standard derivation. Key result: $0 \le \alpha_i \le C$. Support vectors are where $\alpha_i > 0$. Margin violations are where $\alpha_i = C$.
        <br><b>Dual:</b> $\max \sum \alpha_i - \frac{1}{2} \sum \alpha_i \alpha_j y_i y_j x_i^\top x_j$ s.t. $0 \le \alpha \le C, \sum \alpha_i y_i = 0$.</p>

        <h3>P9.6 — Trust Region Subproblem</h3>
        <p>$\min x^\top Q x + c^\top x$ s.t. $\|x\|_2^2 \le 1$ ($Q$ may be indefinite).
        <br><b>Dual:</b> $\max_{\lambda \ge 0} -\frac{1}{2} c^\top (Q + \lambda I)^{-1} c - \lambda$ s.t. $Q + \lambda I \succeq 0$.
        <br>This is a 1D convex optimization problem in $\lambda$. Can be solved by Newton's method or bisection.</p>

        <h3>P9.7 — Analytic Center / Log-Sum-Exp</h3>
        <p>Dual of $\min -\sum \log x_i$ s.t. $Ax=b$ (Analytic Center).
        <br>Dual of $\min \log \sum e^{a_i^\top x + b_i}$ (Geometric Programming / Logistic Regression core).
        <br>Uses the entropy conjugate relation: $(x \log x)^* = e^{y-1}$.</p>

        <h3>P9.8 — SDP Dual</h3>
        <p>Derive the dual of $\min \mathrm{tr}(CX)$ s.t. $\mathcal{A}(X) = b, X \succeq 0$.
        <br><b>Solution:</b> $\max b^\top y$ s.t. $\mathcal{A}^*(y) \preceq C$. (See Sec 6.3).</p>

        <h3>P9.9 — SOCP Dual</h3>
        <p>Derive the dual of $\min c^\top x$ s.t. $\|A_i x + b_i\|_2 \le d_i^\top x + e_i$.
        <br>Uses the self-duality of the Second-Order Cone.</p>

        <h3>P9.10 — Simplex Projection</h3>
        <p>$\min \frac{1}{2}\|x-y\|_2^2$ s.t. $x^\top \mathbf{1} = 1, x \ge 0$.
        <br><b>KKT Approach:</b> $x_i = (y_i - \nu)_+$. Find $\nu$ by sorting $y$ (water-filling). Algorithm is $O(n \log n)$.</p>


      </section>
    </article>

    <footer class="site-footer">
      <div class="container">
        <p>© <span id="year"></span> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
