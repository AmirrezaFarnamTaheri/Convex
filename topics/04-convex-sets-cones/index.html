<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>04. Convex Sets: Cones and Separation â€” Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../03-convex-sets-geometry/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../05-convex-functions-basics/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

    <article>
      <section class="section-card" id="section-1">
        <h2>1. Separating and Supporting Hyperplane Theorems</h2>

        <p>These theorems form the geometric backbone of duality theory, optimality conditions, and many algorithms in convex optimization. They formalize the intuition that convex sets can be "separated" from points outside them and "supported" by planes at their boundaries.</p>

        <h3>1.1 The Separating Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Separating Hyperplane)</h4>
          <p>Let $C, D \subseteq \mathbb{R}^n$ be nonempty, disjoint, convex sets. Then there exists a hyperplane that separates them: there exist $a \in \mathbb{R}^n \setminus \{0\}$ and $b \in \mathbb{R}$ such that:</p>
          $$
          a^\top x \le b \quad \forall x \in C, \qquad a^\top y \ge b \quad \forall y \in D
          $$
          <p>If additionally one of $C$ or $D$ is closed and the other is compact, then we can achieve <b>strict separation</b> (where $a^\top x < b < a^\top y$).</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/separating-hyperplane-strict.png"
               alt="Illustration of the Separating Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.1:</i> A hyperplane separating two disjoint convex sets $C$ and $D$. For closed sets, we can construct the separator using the projection of 0 onto their difference set $C-D$.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof (Constructive via Projection)</h4>

          <div class="proof-step">
            <strong>Step 1: Construct the Difference Set.</strong> Define the Minkowski difference $S = C - D = \{c - d \mid c \in C, d \in D\}$.
            <br>Since $C$ and $D$ are convex, their difference $S$ is also convex.
            <br>Because $C$ and $D$ are disjoint, the origin $0$ is <b>not</b> in $S$. (If $0 = c-d$, then $c=d \in C \cap D$).
          </div>

          <div class="proof-step">
            <strong>Step 2: Project Zero onto the Closure.</strong> Let $\bar{S} = \mathrm{cl}(S)$. Since $S$ is convex, $\bar{S}$ is closed and convex.
            <br>Let $p = \Pi_{\bar{S}}(0)$ be the projection of the origin onto $\bar{S}$.
            <br>Assuming $0 \notin \bar{S}$ (which holds if $C, D$ are closed and one is compact), then $p \neq 0$.
          </div>

          <div class="proof-step">
            <strong>Step 3: Characterize Projection.</strong> By the projection theorem, the projection $p$ of a point $x$ (here $x=0$) onto a closed convex set $\bar{S}$ is characterized by the inequality $(z - p)^\top (x - p) \le 0$ for all $z \in \bar{S}$.
            <br>Substitute $x=0$:
            $$ (z - p)^\top (0 - p) \le 0 \implies (z - p)^\top (-p) \le 0 $$
            Expand the inner product:
            $$ -z^\top p + p^\top p \le 0 \implies z^\top p \ge p^\top p = \|p\|_2^2 $$
            Since $0 \notin \bar{S}$, $p \ne 0$, so $\|p\|_2^2 > 0$.
            <br>Since every $z \in S$ is of the form $c - d$:
            $$ (c - d)^\top p \ge \|p\|_2^2 \implies p^\top c - p^\top d \ge \|p\|_2^2 \implies p^\top c \ge p^\top d + \|p\|_2^2 $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Define the Hyperplane.</strong> Set the normal vector $a = p$.
            <br><i>Why?</i> Because $p$ points from the origin (which represents points in $D$ relative to $C$) towards $S=C-D$.
            <br>The vector $p = \Pi_{\bar{S}}(0)$ is the shortest vector in the difference set. The hyperplane normal to $p$ passing through $p$ separates $S$ from 0.
            <br>Define the scalar $b$ halfway between the boundaries:
            $$ b = \sup_{d \in D} a^\top d + \frac{1}{2}\|p\|_2^2 $$
            Then for all $c \in C, d \in D$:
            $$ a^\top c = a^\top (c-d+d) = a^\top (c-d) + a^\top d \ge \|p\|_2^2 + a^\top d $$
            Since this holds for any $d$, $a^\top c \ge \sup_d a^\top d + \|p\|_2^2 > b$.
            And $b > \sup_d a^\top d \ge a^\top d$.
            Thus, the hyperplane $\{x \mid a^\top x = b\}$ strictly separates $C$ and $D$.
          </div>
        </div>

        <h3>1.2 The Supporting Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Supporting Hyperplane)</h4>
          <p>Let $C \subseteq \mathbb{R}^n$ be a nonempty convex set, and let $x_0 \in \partial C$ (the boundary of $C$). Then there exists a <b>supporting hyperplane</b> to $C$ at $x_0$: there exists $a \in \mathbb{R}^n \setminus \{0\}$ such that:</p>
          $$
          a^\top x \le a^\top x_0 \quad \forall x \in C
          $$
          <p>The hyperplane $\{x \mid a^\top x = a^\top x_0\}$ "supports" $C$ at $x_0$â€”it touches $C$ at $x_0$ and $C$ lies entirely on one side.</p>
        </div>

        <div class="proof-box">
          <h4>Proof (Limit of Separating Hyperplanes)</h4>
          <div class="proof-step">
            <strong>Step 1: Point outside interior.</strong> Since $x_0 \in \partial C$ and $C$ is convex, $\mathrm{int}(C)$ is also convex. If $\mathrm{int}(C) = \emptyset$, $C$ lies in a lower-dimensional affine space, and any hyperplane containing that space supports $C$. Assume $\mathrm{int}(C) \neq \emptyset$. Then $x_0 \notin \mathrm{int}(C)$.
          </div>
          <div class="proof-step">
            <strong>Step 2: Separation.</strong> By the Separating Hyperplane Theorem, there exists a hyperplane separating the disjoint convex sets $\{x_0\}$ and $\mathrm{int}(C)$. Let $a \neq 0$ be the normal such that:
            $$ a^\top z \le a^\top x_0 \quad \forall z \in \mathrm{int}(C) $$
          </div>
          <div class="proof-step">
            <strong>Step 3: Continuity to Closure.</strong> Since the linear function $f(z) = a^\top z$ is continuous, the inequality holds for all points in the closure of $\mathrm{int}(C)$. For a convex set with nonempty interior, $\mathrm{cl}(\mathrm{int}(C)) = \mathrm{cl}(C)$.
            Thus, $a^\top x \le a^\top x_0$ for all $x \in \mathrm{cl}(C)$, and specifically for all $x \in C$.
          </div>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/supporting-hyperplane-tangent.png"
               alt="Illustration of the Supporting Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.2:</i> A supporting hyperplane to a convex set at a boundary point. It "kisses" the set without cutting into it.</figcaption>
        </figure>

        <h3>1.3 The Support Function</h3>

        <p>The concept of supporting hyperplanes leads naturally to the <b>support function</b>, which provides an alternative, dual description of a convex set. While a set is typically defined by its internal points ("what it contains"), the support function describes it by its external boundaries ("what contains it").</p>

        <div class="theorem-box">
          <h4>Definition (Support Function)</h4>
          <p>For a set $C \subseteq \mathbb{R}^n$, the support function $S_C: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ is defined as:</p>
          $$ S_C(y) := \sup_{x \in C} y^\top x $$
          <p><b>Geometric Meaning:</b> For a direction $y$, $S_C(y)$ quantifies the maximum extent of the set $C$ in that direction. The hyperplane $H = \{x \mid y^\top x = S_C(y)\}$ is a <b>supporting hyperplane</b> to $C$ with normal vector $y$. The set $C$ lies entirely in the halfspace $\{x \mid y^\top x \le S_C(y)\}$.</p>
          <p><b>Forward Connection:</b> The support function $S_C(y)$ is exactly the <b>convex conjugate</b> of the indicator function $I_C(x)$ (see <a href="../06-convex-functions-advanced/index.html">Lecture 06</a>). This duality allows us to manipulate sets algebraically.</p>
        </div>

        <div class="insight">
          <h4>ðŸ”‘ Why These Theorems Matter</h4>
          <ul>
            <li><b>Duality:</b> The separating hyperplane theorem is the geometric foundation of <b>Lagrangian duality</b> (<a href="../09-duality/index.html">Lecture 09</a>). Specifically, Strong Duality holds because we can separate the set of achievable values from the "better-than-optimal" region.</li>
            <li><b>Optimality:</b> The supporting hyperplane theorem leads to first-order optimality conditions (KKT conditions).</li>
            <li><b>Algorithms:</b> Cutting-plane methods and support vector machines (SVMs) rely explicitly on finding these separators.</li>
          </ul>
          <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/separation-failure.png"
                    alt="Failure of separation for non-convex sets"
                    style="max-width: 60%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 1.3:</i> <b>Cautionary Tale:</b> If the sets are not convex (like the C-shape), a separating hyperplane may not exist. This is why convexity is often required for strong duality.</figcaption>
          </figure>
        </div>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Explorer: Separating Hyperplanes</h3>
          <p><b>Find Hyperplanes that Separate Convex Sets:</b> This widget makes the Separating Hyperplane Theorem tangible:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Draw two sets:</b> Click to define vertices of two convex polygons.</li>
            <li><b>Drag to move:</b> Move the sets around and watch the separating hyperplane update in real-time.</li>
            <li><b>Auto-compute separation:</b> The tool uses the closest-point algorithm (constructive proof logic) to find the optimal separator.</li>
            <li><b>Collision:</b> See how the separator vanishes when the sets overlap.</li>
          </ul>
          <div id="widget-separating-hyperplane" style="width: 100%; height: 450px; position: relative;"></div>
        </div>
      </section>


      <section class="section-card" id="section-2">
        <h2>2. Cones, Proper Cones, and Dual Cones</h2>

        <h3>2.1 Cones and Convex Cones</h3>

        <p>A set $K \subseteq \mathbb{R}^n$ is a <a href="#" class="definition-link">cone</a> if it is closed under non-negative scaling:</p>
        $$ x \in K, \ \alpha \ge 0 \implies \alpha x \in K $$

        <p>A <a href="#" class="definition-link">convex cone</a> is a cone that is also a convex set. Equivalently, it is closed under non-negative linear combinations:</p>
        $$ x, y \in K, \ \alpha, \beta \ge 0 \implies \alpha x + \beta y \in K $$

        <div class="example">
            <h4>Examples of Convex Cones</h4>
            <ul>
                <li><b>Non-negative orthant:</b> $\mathbb{R}^n_+ = \{x \in \mathbb{R}^n \mid x_i \ge 0\}$</li>
                <li><b>Second-order cone (Lorentz cone):</b> $\mathcal{Q}^{n+1} = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\|_2 \le t\}$</li>
                <li><b>PSD Cone:</b> $\mathbb{S}^n_+ = \{X \in \mathbb{S}^n \mid X \succeq 0\}$</li>
            </ul>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/second-order-cone.png"
                    alt="3D visualization of the second-order cone (ice cream cone)"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.1:</i> The Second-Order Cone in $\mathbb{R}^3$ (ice-cream cone) is defined by $\|x\|_2 \le t$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/hyperbolic-cone.png"
                    alt="3D visualization of a hyperbolic cone"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.2:</i> A Hyperbolic Cone. Cones are not limited to straight lines; they can have curved boundaries as long as they are closed under scaling.</figcaption>
             </figure>
        </div>

        <h3>2.2 Proper Cones</h3>

        <p>A <a href="#" class="definition-link">proper cone</a> is a convex cone $K$ that satisfies three additional properties:</p>
        <ol>
          <li><b>Closed:</b> $K$ contains its boundary.</li>
          <li><b>Pointed:</b> $K$ contains no lines ($K \cap -K = \{0\}$).</li>
          <li><b>Solid:</b> $K$ has a non-empty interior.</li>
        </ol>

        <p>Proper cones are geometrically "sharp" (pointed) and "full-dimensional" (solid). They are used to define generalized inequalities.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/cone-zoo.png"
                  alt="Examples of proper and improper cones"
                  style="max-width: 90%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 2.3:</i> The "Cone Zoo". Left: A proper cone (closed, pointed, solid). Center: A wedge (not pointed, contains a line). Right: A flat slice (not solid, empty interior).</figcaption>
        </figure>

        <h3>2.3 Generalized Inequalities</h3>

        <p>A proper cone $K$ defines a partial ordering $\preceq_K$ on $\mathbb{R}^n$:</p>
        $$
        x \preceq_K y \iff y - x \in K
        $$
        <p>Strict inequality is defined using the interior of the cone:</p>
        $$
        x \prec_K y \iff y - x \in \text{int}(K)
        $$

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/generalized-inequality-cone.png"
                    alt="Visualizing generalized inequality"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.4:</i> Visualizing $x \preceq_K y$. The point $x$ must lie in the "shadow" of $y$ cast by the cone $-K$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/matrix-inequality-cone.png"
                    alt="Matrix inequality ordering"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.5:</i> Partial ordering in the PSD cone. $A \preceq B$ means $B-A$ is in the PSD cone.</figcaption>
             </figure>
        </div>

        <div class="insight">
             <h4>Minimum vs. Minimal</h4>
             <p>Because the ordering is partial, we distinguish between a <b>minimum</b> element (smaller than everyone, e.g., the origin in $\mathbb{R}^n_+$) and a <b>minimal</b> element (nothing is smaller than it, but it might not compare to everyone).</p>
             <figure style="text-align: center; margin: 24px 0;">
                  <img src="assets/minimum-vs-minimal.png"
                       alt="Minimum vs minimal elements"
                       style="max-width: 60%; height: auto; border-radius: 8px;" />
                  <figcaption><i>Figure 2.6:</i> Left: Minimum element (unique). Right: Minimal elements (red boundary). In vector optimization (Pareto optimality), we seek minimal elements.</figcaption>
             </figure>
        </div>

        <h3>2.4 The Dual Cone</h3>

        <p>The <a href="#" class="definition-link">dual cone</a> of a cone $K$ is the set of all vectors making a non-obtuse angle with every vector in $K$:</p>
        $$
        K^* = \{y \in \mathbb{R}^n \mid y^\top x \ge 0 \ \forall x \in K\}
        $$
        <p>The dual cone $K^*$ is always a closed convex cone, regardless of whether $K$ is convex or closed.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/dual-cone-geometry.png"
                  alt="Geometry of primal and dual cones"
                  style="max-width: 50%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 2.7:</i> The dual cone $K^*$ (red) consists of vectors that make an angle $\le 90^\circ$ with every vector in $K$ (blue).</figcaption>
        </figure>

        <div class="theorem-box">
            <h4>Important Dualities</h4>
            <ul>
                <li>$\mathbb{R}^n_+$ is <b>self-dual</b>: $(\mathbb{R}^n_+)^* = \mathbb{R}^n_+$</li>
                <li>$\mathbb{S}^n_+$ is <b>self-dual</b>: $(\mathbb{S}^n_+)^* = \mathbb{S}^n_+$ (under trace inner product). This property is crucial for the symmetry of primal and dual <b>Semidefinite Programs</b> (<a href="../09-duality/index.html">Lecture 09</a>).</li>
                <li>$\mathcal{Q}^{n+1}$ is <b>self-dual</b>: $(\mathcal{Q}^{n+1})^* = \mathcal{Q}^{n+1}$</li>
                <li>$(L_p \text{ norm cone})^* = L_q \text{ norm cone}$ where $1/p + 1/q = 1$.</li>
            </ul>
        </div>

        <div class="proof-box">
          <h4>Proof: Self-Duality of the PSD Cone</h4>
          <p>We want to show that $(\mathbb{S}^n_+)^* = \mathbb{S}^n_+$ under the trace inner product $\langle A, B \rangle = \mathrm{tr}(AB)$.</p>

          <div class="proof-step">
            <strong>Part 1: $\mathbb{S}^n_+ \subseteq (\mathbb{S}^n_+)^*$ (Primal implies Dual)</strong>
            <p>Assume $A \in \mathbb{S}^n_+$. We must show that for any $B \in \mathbb{S}^n_+$, $\mathrm{tr}(AB) \ge 0$.</p>
            <ul>
              <li>Since $A$ is PSD, it has a "square root" decomposition $A = L L^\top$ (e.g., Cholesky or spectral).</li>
              <li>Then $\mathrm{tr}(AB) = \mathrm{tr}(L L^\top B) = \mathrm{tr}(L^\top B L)$ by the cyclic property.</li>
              <li>Let $M = L^\top B L$. Notice that for any vector $x$, $x^\top M x = x^\top L^\top B L x = (Lx)^\top B (Lx)$.</li>
              <li>Since $B \succeq 0$, $(Lx)^\top B (Lx) \ge 0$ for any vector $Lx$. Thus $M$ is PSD.</li>
              <li>The trace of a PSD matrix is the sum of its eigenvalues (which are non-negative), so $\mathrm{tr}(M) \ge 0$.</li>
            </ul>
            <p>Thus $\mathrm{tr}(AB) \ge 0$, so $A \in (\mathbb{S}^n_+)^*$.</p>
          </div>

          <div class="proof-step">
            <strong>Part 2: $(\mathbb{S}^n_+)^* \subseteq \mathbb{S}^n_+$ (Dual implies Primal)</strong>
            <p>Assume $Y \in (\mathbb{S}^n_+)^*$. By definition, this means $\mathrm{tr}(XY) \ge 0$ for <i>all</i> test matrices $X \in \mathbb{S}^n_+$.</p>
            <ul>
              <li>We choose a specific family of test matrices. For any arbitrary vector $v \in \mathbb{R}^n$, let $X = vv^\top$.</li>
              <li>Check if $X$ is PSD: $z^\top X z = z^\top v v^\top z = (v^\top z)^2 \ge 0$. Yes, it is.</li>
              <li>Apply the dual condition: $\mathrm{tr}(XY) = \mathrm{tr}(vv^\top Y) = \mathrm{tr}(v^\top Y v) = v^\top Y v$.</li>
              <li>The condition $\mathrm{tr}(XY) \ge 0$ implies $v^\top Y v \ge 0$.</li>
            </ul>
            <p>Since $v^\top Y v \ge 0$ holds for <i>all</i> vectors $v$, $Y$ satisfies the definition of a PSD matrix. Thus $Y \in \mathbb{S}^n_+$.</p>
          </div>

          <div class="proof-step">
            <strong>Conclusion:</strong> Since both inclusions hold, $(\mathbb{S}^n_+)^* = \mathbb{S}^n_+$.
          </div>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/self-dual-cones.png"
                    alt="The three major self-dual cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.8:</i> The Big Three self-dual cones: Nonnegative Orthant, Second-Order Cone, and PSD Cone.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/dual-norm-cones.png"
                    alt="Dual relationship between L1 and L-infinity cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 2.9:</i> Duality of Norm Cones: The dual of the $L_1$ cone is the $L_\infty$ cone.</figcaption>
             </figure>
        </div>
      </section>

      <section class="section-card" id="section-3">
      <h2>3. Review & Cheat Sheet</h2>

      <h3>Quick Reference Glossary</h3>
        <ul style="column-count: 2; column-gap: 2rem;">
          <li><b>Cone:</b> Set closed under positive scaling ($\theta x \in C$ for $\theta \ge 0$).</li>
          <li><b>Convex cone:</b> Cone that is also convex. Closed under addition.</li>
          <li><b>Proper cone:</b> Convex, closed, pointed (no lines), solid (nonempty interior).</li>
          <li><b>Dual cone ($K^*$):</b> $\{y \mid y^\top x \ge 0 \ \forall x \in K\}$.</li>
          <li><b>Generalized inequality:</b> $x \preceq_K y$ iff $y - x \in K$.</li>
          <li><b>Separating hyperplane:</b> Exists for any two disjoint convex sets.</li>
          <li><b>Strict separation:</b> Possible if sets are disjoint, closed, and one is compact.</li>
          <li><b>Supporting hyperplane:</b> Touches boundary of set, set lies on one side.</li>
          <li><b>Support function ($S_C(y)$):</b> $\sup_{x \in C} y^\top x$. Defines supporting hyperplanes.</li>
          <li><b>Self-dual cones:</b> Orthant $\mathbb{R}^n_+$, SOC $\mathcal{Q}$, PSD cone $\mathbb{S}^n_+$.</li>
        </ul>
    </section>

    <section class="section-card" id="section-4">
      <h2><i data-feather="edit-3"></i> 4. Exercises</h2>

<div class="problem">
  <h3>P4.1 â€” Separation by Projection</h3>
  <p>Let $C$ be a nonempty closed convex set and $y \notin C$. Prove that the vector $a = y - \Pi_C(y)$ (where $\Pi_C$ denotes projection onto $C$) defines a strictly separating hyperplane between $y$ and $C$.</p>

      <div class="recap-box">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Constructive Separation Proof:</b> The Separating Hyperplane Theorem for a closed convex set $C$ and an external point $y$ can be proven constructively using the projection theorem.</li>
            <li><b>The Normal Vector:</b> The vector $a = y - p$ is normal to the separating hyperplane.</li>
        </ul>
      </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
              <strong>Step 1: Projection characterization.</strong> By the projection theorem (Lecture 00-01), for all $x \in C$:
              $$
              (y - p)^\top (x - p) \le 0
              $$
              where $p = \Pi_C(y)$. Expanding with $a = y - p$:
              $$
              a^\top x - a^\top p \le 0 \quad \implies \quad a^\top x \le a^\top p
              $$
            </div>

            <div class="proof-step">
              <strong>Step 2: Strict inequality at $y$.</strong> Since $p \neq y$ (because $y \notin C$), we have $a = y - p \neq 0$, so $\|a\|_2 > 0$. Then:
              $$
              a^\top y = a^\top p + a^\top (y - p) = a^\top p + \|a\|_2^2 > a^\top p
              $$
            </div>

            <div class="proof-step">
              <strong>Conclusion:</strong> Combining both inequalities: $a^\top x \le a^\top p < a^\top y$ for all $x \in C$.
            </div>
  </div>
</div>

<div class="problem">
  <h3>P4.2 â€” Dual of a Subspace</h3>
  <p>Let $V \subseteq \mathbb{R}^n$ be a linear subspace. Prove that its dual cone is the orthogonal complement $V^\perp$.</p>

      <div class="recap-box">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Subspace Duality:</b> For a subspace, $y^\top x \ge 0$ implies $y^\top x = 0$ because both $x$ and $-x$ are in $V$.</li>
            <li><b>Geometric Intuition:</b> A subspace is a "flat" cone. If you widen a cone until it becomes a plane, its dual cone narrows until it becomes the normal line (orthogonal complement).</li>
        </ul>
      </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
              <strong>($\subseteq$):</strong> If $y \in V^\perp$, then $y^\top x = 0 \ge 0$ for all $x \in V$. So $y \in V^*$.
    </div>
    <div class="proof-step">
              <strong>($\supseteq$):</strong> Suppose $y \in V^*$, so $y^\top x \ge 0$ for all $x \in V$. Since $V$ is a subspace, $-x \in V$. Thus $y^\top (-x) \ge 0 \implies y^\top x \le 0$.
              Combining $\ge 0$ and $\le 0$ gives $y^\top x = 0$. Thus $y \in V^\perp$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.3 â€” Self-Duality of Second-Order Cone</h3>
  <p>Prove that the second-order cone $\mathcal{Q} = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\|_2 \le t\}$ is self-dual: $\mathcal{Q}^* = \mathcal{Q}$.</p>

      <div class="recap-box">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Cauchy-Schwarz:</b> The inequality $u^\top v \ge -\|u\|\|v\|$ is central to proving this inclusion.</li>
        </ul>
      </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>Let $u=(x,t)$ and $v=(y,s)$.</p>
    <div class="proof-step">
      <strong>($\subseteq$):</strong> Let $v \in \mathcal{Q}$. For any $u \in \mathcal{Q}$, we have $\|x\| \le t$ and $\|y\| \le s$.
      Using Cauchy-Schwarz $x^\top y \ge -\|x\|\|y\|$:
      $$ u^\top v = x^\top y + ts \ge -\|x\|\|y\| + ts \ge -ts + ts = 0 $$
      Thus $u^\top v \ge 0$ for all $u \in \mathcal{Q}$, so $v \in \mathcal{Q}^*$.
    </div>
    <div class="proof-step">
      <strong>($\supseteq$):</strong> Let $v \in \mathcal{Q}^*$.
      First, take $u=(0,1) \in \mathcal{Q}$. Then $u^\top v = s \ge 0$.
      Next, if $y \ne 0$, take $u = (-y/\|y\|, 1)$. Since $\|-y/\|y\|\| = 1 \le 1$, $u \in \mathcal{Q}$.
      The condition $u^\top v \ge 0$ implies:
      $$ - \frac{y^\top y}{\|y\|} + s \ge 0 \implies -\|y\| + s \ge 0 \implies \|y\| \le s $$
      (If $y=0$, then $\|y\| \le s$ since $s \ge 0$).
      Thus $v \in \mathcal{Q}$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.4 â€” Dual Cone Identities</h3>
  <p>For closed convex cones $K_1, K_2$, prove $(K_1 + K_2)^* = K_1^* \cap K_2^*$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Duality of Operations:</b> Dual of sum is intersection.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>($\subseteq$):</strong>
      $y \in (K_1 + K_2)^*$ iff $y^\top (x_1+x_2) \ge 0$ for all $x_1 \in K_1, x_2 \in K_2$.
      Choosing $x_2=0$, $y^\top x_1 \ge 0 \implies y \in K_1^*$.
      Choosing $x_1=0$, $y^\top x_2 \ge 0 \implies y \in K_2^*$.
      Thus $y \in K_1^* \cap K_2^*$.
    </div>
    <div class="proof-step">
      <strong>($\supseteq$):</strong>
      Let $y \in K_1^* \cap K_2^*$. For any element $z \in K_1 + K_2$, we can write $z = x_1 + x_2$ with $x_1 \in K_1, x_2 \in K_2$.
      Then $y^\top z = y^\top x_1 + y^\top x_2$.
      Since $y \in K_1^*$, $y^\top x_1 \ge 0$. Since $y \in K_2^*$, $y^\top x_2 \ge 0$.
      Therefore $y^\top z \ge 0$ for all $z \in K_1 + K_2$, so $y \in (K_1 + K_2)^*$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.5 â€” Generalized Inequality Properties</h3>
  <p>Let $K$ be a proper cone. Prove $\preceq_K$ is antisymmetric: $x \preceq_K y \land y \preceq_K x \implies x=y$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Pointedness:</b> $K \cap -K = \{0\}$ is the key property ensuring antisymmetry.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      $x \preceq_K y \implies y-x \in K$.
      $y \preceq_K x \implies x-y \in K \implies -(y-x) \in K$.
      So $y-x \in K \cap -K$. Since $K$ is proper (pointed), $K \cap -K = \{0\}$.
      Thus $y-x=0 \implies x=y$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.6 â€” Norm Cone (Epigraph of Norm)</h3>
  <p>Show that the set $C = \{(x,t) \mid \|x\| \le t\}$ is a convex cone.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Epigraphs of Convex Functions:</b> The set is the epigraph of the convex function $f(x)=\|x\|$.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <b>Cone:</b> If $\|x\| \le t$, then $\|\alpha x\| = \alpha \|x\| \le \alpha t$. So $\alpha(x,t) \in C$ for $\alpha \ge 0$.
    </div>
    <div class="proof-step">
      <b>Convex:</b> If $(x,t), (y,s) \in C$, then $\|x+y\| \le \|x\|+\|y\| \le t+s$. So $(x+y, t+s) \in C$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.7 â€” Support Function Determines Set</h3>
  <p>Prove that if $C, D$ are closed convex sets and $S_C(y) = S_D(y)$ for all $y$, then $C=D$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>A closed convex set is uniquely determined by its support function because it is the intersection of all its supporting halfspaces.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      A closed convex set is the intersection of its supporting halfspaces: $C = \bigcap_y \{x \mid y^\top x \le S_C(y)\}$.
      If $S_C = S_D$, the intersections are identical, so $C=D$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.8 â€” Converse Supporting Hyperplane Theorem</h3>
  <p>Prove that if a closed set $C$ with nonempty interior has a supporting hyperplane at every boundary point, $C$ is convex.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>This theorem (Tietze-Nakajima) shows that "local convexity" at every boundary point (existence of support) implies global convexity for connected sets with interior.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      Assume $C$ is not convex. Then there exists a point in the convex hull $D = \mathrm{conv}(C)$ that is not in $C$.
      Consider a line segment connecting an interior point of $C$ to this point. It must cross the boundary of $C$ at some $x^*$.
      The supporting hyperplane at $x^*$ must separate $C$ from the rest of the segment.
      However, the endpoints of the segment are in $D$ (convex hull). Separation implies $D$ lies on one side, which contradicts the segment crossing the plane.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.9 â€” Cones in $\mathbb{R}^2$</h3>
  <p>Describe all closed convex cones in $\mathbb{R}^2$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>In 2D, convex cones are simply wedges radiating from the origin. The dual cone relationship is purely geometric: if the primal cone has angle $\phi$, the dual cone has angle $\pi - \phi$.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>They are wedges defined by an angular interval $[\alpha, \beta]$ with width $\le \pi$. The dual cone is the wedge rotated by $90^\circ$ (roughly) with width $\pi - (\beta-\alpha)$.</p>
  </div>
</div>

<div class="problem">
  <h3>P4.10 â€” Properties of Dual Cones</h3>
  <p>Prove that if $\mathrm{int}(K) \neq \emptyset$, then $K^*$ is pointed.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>There is a duality between "solidness" and "pointedness". A fat cone (solid) forces its dual to be sharp (pointed). A flat cone (subspace) allows its dual to be wide (subspace).</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      If $y \in K^* \cap -K^*$, then $y^\top x = 0$ for all $x \in K$.
      Since $K$ has interior, it contains a basis of $\mathbb{R}^n$.
      A vector orthogonal to a basis must be the zero vector. Thus $y=0$, so $K^*$ is pointed.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.11 â€” Dual Cone of Generated Cone</h3>
  <p>Let $K = \{Ax \mid x \ge 0\}$. Show $K^* = \{y \mid A^\top y \ge 0\}$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>This is the dual of the finitely generated cone (polyhedral cone). It corresponds to the Farkas Lemma: $y$ is in the dual cone if it makes a non-negative angle with all generators (columns of $A$).</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      $y \in K^* \iff y^\top (Ax) \ge 0 \ \forall x \ge 0 \iff (A^\top y)^\top x \ge 0 \ \forall x \ge 0$.
      This is true iff $A^\top y \ge 0$ (component-wise).
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.12 â€” The Monotone Nonnegative Cone</h3>
  <p>Find the dual of $K = \{x \in \mathbb{R}^n \mid x_1 \ge x_2 \ge \dots \ge 0\}$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>The dual of the cone of monotonic sequences is the cone of sequences with non-negative partial sums. This duality is often used in isotonic regression.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      Using summation by parts (Abel's lemma), the condition $\sum x_i y_i \ge 0$ for all monotone $x$ requires the partial sums of $y$ to be non-negative.
      $K^* = \{y \mid \sum_{i=1}^k y_i \ge 0, k=1\dots n\}$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.13 â€” The Lexicographic Cone</h3>
  <p>Let $K_{lex} = \{0\} \cup \{x \mid \text{first nonzero of } x > 0\}$. Find $K_{lex}^*$.</p>

  <div class="recap-box">
    <h4>Recap</h4>
    <p>The lexicographic cone is not closed (it misses the boundary where the first coordinate is zero but the second is positive). Its dual is extremely thin (a single ray), illustrating that $K^{**} \neq K$ for non-closed cones.</p>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      The cone is "almost" a halfspace but includes boundaries delicately.
      Any vector $y$ with a non-zero component at index $k > 1$ can form a negative dot product with some $x \in K_{lex}$ (by dominating the first component with a large value at $k$).
      Thus $y$ must be zero everywhere except index 1. $y_1$ must be non-negative.
      $K_{lex}^* = \{ \alpha e_1 \mid \alpha \ge 0 \}$ (The ray along the first axis).
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.14 â€” Dual of Intersection</h3>
  <p>Let $K_1, K_2$ be closed convex cones. Prove that $(K_1 \cap K_2)^* = \mathrm{cl}(K_1^* + K_2^*)$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Duality Symmetry:</b> Since $K^{**} = K$ for closed convex cones, properties of the primal operations map to dual operations. Intersection in primal corresponds to sum in dual (with closure).</li>
        <li><b>Closure is Crucial:</b> The sum of two closed cones is not always closed. The closure operation is necessary for the equality to hold.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Use P4.4.</strong> From Problem 4.4, we know that for closed convex cones $A, B$, $(A + B)^* = A^* \cap B^*$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Apply to Duals.</strong> Let $A = K_1^*$ and $B = K_2^*$. Then $(K_1^* + K_2^*)^* = K_1^{**} \cap K_2^{**}$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Biconjugate.</strong> Since $K_i$ are closed convex cones, $K_i^{**} = K_i$. Thus $(K_1^* + K_2^*)^* = K_1 \cap K_2$.
    </div>
    <div class="proof-step">
      <strong>Step 4: Take Dual again.</strong> Taking the dual of both sides: $(K_1^* + K_2^*)^{**} = (K_1 \cap K_2)^*$.
      The biconjugate of a cone is its closure (if it's convex). Thus $\mathrm{cl}(K_1^* + K_2^*) = (K_1 \cap K_2)^*$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P4.15 â€” Euclidean Distance Matrices (EDM)</h3>
  <p>A matrix $D \in \mathbb{S}^n$ is a Euclidean Distance Matrix if there exist points $x_1, \dots, x_n$ such that $D_{ij} = \|x_i - x_j\|_2^2$. Show that the set of all EDMs is a convex cone.</p>
  <div class="recap-box">
    <h4>Recap</h4>
    <p>EDMs are linear images of the PSD cone. Since linear maps preserve convexity and conical structure, the set of EDMs inherits the cone property from $\mathbb{S}^n_+$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Expand definition.</strong>
      $D_{ij} = \|x_i - x_j\|^2 = \|x_i\|^2 + \|x_j\|^2 - 2x_i^\top x_j$.
      Let $G$ be the Gram matrix where $G_{ij} = x_i^\top x_j$. Then $G \succeq 0$.
      Let $v$ be the vector where $v_i = G_{ii} = \|x_i\|^2$.
      We can write $D = v\mathbf{1}^\top + \mathbf{1}v^\top - 2G$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Identify Linear Structure.</strong>
      The mapping $\mathcal{L}(G) = \text{diag}(G)\mathbf{1}^\top + \mathbf{1}\text{diag}(G)^\top - 2G$ is a linear map from $\mathbb{S}^n$ to $\mathbb{S}^n$.
      The set of EDMs is the image of the PSD cone $\mathbb{S}^n_+$ under this linear map $\mathcal{L}$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Convexity.</strong>
      Since $\mathbb{S}^n_+$ is a convex cone and linear maps preserve convexity and conical structure, the set of EDMs is a convex cone.
    </div>
  </div>
</div>

</div>

    </section>

    <section class="section-card" id="section-5">
      <h2>5. Readings & Resources</h2>
      <ul class="link-list">
        <li><strong>Required Reading:</strong> Boyd & Vandenberghe, Chapter 2 (Convex Sets, specifically Cones and Dual Cones).</li>
        <li><strong>Supplementary:</strong> Rockafellar, <em>Convex Analysis</em>, Sections 11 (Separation Theorems) and 14 (Cones).</li>
        <li><strong>Interactive:</strong> Use the <a href="#widget-separating-hyperplane">Separating Hyperplane Explorer</a> to test intuition.</li>
      </ul>
    </section>

    </article>

    <footer class="site-footer">
      <div class="container">
        <p>Â© <span id="year"></a> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- Widget Loaders -->
  <script type="module">
    import { initSeparatingHyperplane } from './widgets/js/separating-hyperplane.js';
    initSeparatingHyperplane('widget-separating-hyperplane');
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
