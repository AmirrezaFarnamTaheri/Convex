<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>02. Convex Sets â€” Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../01-introduction/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../03-convex-functions/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>02. The Geometry of Feasibility: Convex Sets</h1>
      <div class="lecture-meta">
        <span>Date: 2025-10-28</a>
        <span>Duration: 90 min</a>
        <span>Tags: sets, geometry, foundational, theory</a>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the geometric foundations of convex optimization through the study of convex sets. We define convexity for sets, examine canonical examples such as hyperplanes, polyhedra, and cones, and establish operations that preserve convexity. The lecture concludes with the Separating and Supporting Hyperplane Theorems, which form the geometric basis for duality theory and optimality conditions.</p>
        <p><strong>Prerequisites:</strong> Linear algebra (<a href="../00-linear-algebra-primer/index.html">Lecture 00</a>)â€”particularly projections, subspaces, and inner productsâ€”and the definition of a convex problem (<a href="../01-introduction/index.html">Lecture 01</a>).</p>
        <p><strong>Forward Connections:</strong> Feasible sets from LP and QP formulations are shown to be convex. The hyperplane separation theorems provide the geometric foundation for Lagrangian duality (Lecture 05) and KKT conditions. Cone duality underpins conic programming (SOCP, SDP).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <ul>
        <li><b>Define and Interpret Convexity:</b> Provide formal definitions of affine sets, convex sets, convex combinations, and convex hulls with geometric intuition.</li>
        <li><b>Identify Key Convex Sets:</b> Recognize and work with hyperplanes, halfspaces, norm balls, ellipsoids, polyhedra, second-order cones, and the PSD cone.</li>
        <li><b>Understand Convexity-Preserving Operations:</b> Use intersection, affine mappings, and perspective operations to construct complex convex sets from simple building blocks.</li>
        <li><b>Prove and Apply Hyperplane Theorems:</b> State and prove the Separating and Supporting Hyperplane Theorems, understanding their role in duality and optimality.</li>
        <li><b>Work with Cones and Duality:</b> Define cones, proper cones, and dual cones. Prove self-duality of key cones and apply generalized inequalities.</li>
        <li><b>Use Topological Concepts:</b> Apply closure, interior, boundary, and relative interior to analyze constraint qualifications and algorithm convergence.</li>
      </ul>
    </section>



    <article>
      <section class="section-card" id="section-1">
        <h2>1. Affine and Convex Sets: Definitions and Basic Properties</h2>

        <p>The geometry of optimization is built on understanding how points combine. Two fundamental operations define the landscape:</p>

        <h3>1.1 Affine Combinations and Affine Sets</h3>

        <p>An <a href="#" class="definition-link">affine combination</a> of points $x_1, \ldots, x_k$ is a weighted sum where the weights sum to one:</p>
        $$
        \sum_{i=1}^k \theta_i x_i \quad \text{where} \quad \sum_{i=1}^k \theta_i = 1
        $$
        <p>Unlike linear combinations, affine combinations do not require the origin to be included. Weights can be negativeâ€”there's no nonnegativity requirement. Affine combinations describe lines, planes, and hyperplanes.</p>

        <div class="theorem-box">
          <h4>Definition (Affine Set)</h4>
          <p>A set $C$ is <a href="#" class="definition-link">affine</a> if it contains all affine combinations of its points. Equivalently, the <b>infinite line</b> passing through any two points in $C$ lies entirely in $C$.</p>
          $$ x_1, x_2 \in C, \ \theta \in \mathbb{R} \implies \theta x_1 + (1-\theta)x_2 \in C $$
        </div>

        <h4>Affine Sets as Translated Subspaces</h4>
        <p>Geometrically, every affine set is just a linear subspace that has been shifted (translated) away from the origin.</p>

        <div class="theorem-box">
          <h4>Theorem: Affine Set $\iff$ Translated Subspace</h4>
          <p>A set $C \subseteq \mathbb{R}^n$ is affine if and only if it can be written as:</p>
          $$
          C = x_0 + V = \{x_0 + v \mid v \in V\}
          $$
          <p>where $x_0$ is any specific point in $C$, and $V$ is a linear subspace of $\mathbb{R}^n$.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <div class="proof-step">
              <strong>($\Leftarrow$):</strong> Suppose $C = x_0 + V$. Let $x_1, x_2 \in C$. Then $x_1 = x_0 + v_1$ and $x_2 = x_0 + v_2$ for some $v_1, v_2 \in V$.
              For any $\theta \in \mathbb{R}$:
              $$
              \theta x_1 + (1-\theta)x_2 = \theta(x_0 + v_1) + (1-\theta)(x_0 + v_2)
              = x_0 + [\theta v_1 + (1-\theta)v_2]
              $$
              Since $V$ is a subspace, it is closed under linear combinations, so the bracketed term is in $V$. Thus the combination is in $x_0 + V = C$.
            </div>
            <div class="proof-step">
              <strong>($\Rightarrow$):</strong> Suppose $C$ is affine. Pick any $x_0 \in C$ and define $V = C - x_0 = \{x - x_0 \mid x \in C\}$. We show $V$ is a subspace.
              <ul>
                <li>$0 \in V$ since $x_0 \in C$.</li>
                <li>Let $v_1, v_2 \in V$ and $\alpha, \beta \in \mathbb{R}$. We want $\alpha v_1 + \beta v_2 \in V$. This follows from the affine property of $C$ (specifically, closure under affine sums leads to closure of difference vectors under linear combinations).</li>
              </ul>
              Thus $C = x_0 + V$.
            </div>
          </div>
        </div>

        <figure style="text-align: center;">
          <img src="assets/affine-subspace.png"
               alt="An affine set C shown as a red plane parallel to a blue subspace V passing through the origin"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.0:</i> An affine set $C$ (red) is a subspace $V$ (blue) translated by a vector $x_0$. Note that $V$ passes through the origin, while $C$ does not necessarily.</figcaption>
        </figure>

        <div class="example">
          <h4>Examples of Affine Sets</h4>
          <ul>
            <li><b>Solution set of linear equations:</b> $C = \{x \mid Ax = b\}$. If $x_0$ is a particular solution ($Ax_0 = b$), then $C = x_0 + \mathcal{N}(A)$, where the nullspace $\mathcal{N}(A)$ is the associated subspace.</li>
            <li><b>$\mathbb{R}^n$ itself:</b> The entire space is trivially affine ($V = \mathbb{R}^n, x_0 = 0$).</li>
            <li><b>Single point $\{x_0\}$:</b> Affine ($V = \{0\}$).</li>
          </ul>
        </div>

        <h3>1.2 Convex Combinations and Convex Sets</h3>

        <p>A <a href="#" class="definition-link">convex combination</a> is an affine combination with the additional constraint that all weights are nonnegative:</p>
        $$
        \sum_{i=1}^k \theta_i x_i \quad \text{where} \quad \theta_i \ge 0, \ \sum_{i=1}^k \theta_i = 1
        $$
        <p>This describes "filled-in" shapes like line segments, triangles, and convex polytopes.</p>

        <div class="theorem-box">
          <h4>Definition (Convex Set)</h4>
          <p>A set $C \subseteq \mathbb{R}^n$ is <a href="#" class="definition-link" data-term="convex function">convex</a> if for any two points $x, y \in C$ and any $\theta \in [0,1]$:</p>
          $$
          \theta x + (1-\theta)y \in C
          $$
          <p><b>Geometric meaning:</b> The line segment connecting any two points in the set lies entirely within the setâ€”no "dents" or "holes."</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-vs-nonconvex.png"
               alt="Visual definition of convex and non-convex sets"
               style="max-width: 100%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.1:</i> In a convex set (right), the line segment between any two points lies entirely within the set. In a non-convex set (left), some line segments (red) cross outside the set boundaries.</figcaption>
        </figure>

        <h3>1.3 Convex Hull</h3>

        <p>The <a href="#" class="definition-link">convex hull</a> of a set $S$, denoted $\mathrm{conv}(S)$, is the set of all convex combinations of points in $S$:</p>
        $$
        \mathrm{conv}(S) = \left\{\sum_{i=1}^k \theta_i x_i \ \bigg| \ x_i \in S, \ \theta_i \ge 0, \ \sum_{i=1}^k \theta_i = 1, \ k \in \mathbb{N}\right\}
        $$
        <p>It is the smallest convex set containing $S$â€”analogous to stretching a rubber band around all the points.</p>

        <div class="theorem-box">
          <h4>Theorem (CarathÃ©odory's Theorem)</h4>
          <p>If $S \subseteq \mathbb{R}^n$, then every point in $\mathrm{conv}(S)$ can be written as a convex combination of at most $n+1$ points from $S$.</p>
          <p><b>Implication:</b> To describe any point in the convex hull, we never need more than $n+1$ points, regardless of how large $S$ is!</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-hull.png"
               alt="Illustration of a convex hull"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.2:</i> The convex hull of a set of points (black dots) acts like a rubber band (blue polygon) snapped tight around them.</figcaption>
        </figure>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
            <figure style="text-align: center; flex: 1;">
              <img src="assets/convex-hull-nonconvex.png"
                   alt="Convex hull of a crescent shape"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 1.3:</i> The convex hull of a non-convex set (dark grey crescent) fills in the "gaps" (light blue), creating the smallest convex superset.</figcaption>
            </figure>
            <figure style="text-align: center; flex: 1;">
              <img src="assets/caratheodory.png"
                   alt="Caratheodory's theorem visualization"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 1.4:</i> CarathÃ©odory's Theorem: Any point $x$ in the hull of many points (black) can be formed by a convex combination of just $n+1$ of them (red triangle in $\mathbb{R}^2$).</figcaption>
            </figure>
        </div>

        <div class="insight">
          <h4>Visualizing Sublevel Sets</h4>
          <p>Convex sets are intimately linked to convex functions. The <a href="#" class="definition-link">indicator function</a> of a set $C$, $\delta_C(x) = 0$ if $x \in C$ and $\infty$ otherwise, is a convex function if and only if $C$ is convex. Furthermore, the sublevel sets of any convex function are convex sets.</p>
          <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/indicator-function.png"
                  alt="3D plot of an indicator function"
                  style="max-width: 60%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 1.5:</i> The sublevel set of a convex function (like the indicator function shown here) corresponds to the convex set itself.</figcaption>
          </figure>
        </div>

        <h3>1.4 Key Properties</h3>

        <ul>
          <li>Every affine set is convex (but not vice versa).</li>
          <li>The intersection of any collection of convex sets is convex (proven in Section 3).</li>
          <li>The union of convex sets is generally <b>not</b> convex.</li>
        </ul>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Tool: Convex Set Checker</h3>
          <p><b>Test Convexity Interactively:</b> Use the drawing tools below to create shapes and verify their convexity. Any "dent" will be flagged as a violation of the line segment property.</p>
          <!-- Note: The standalone drawing widget has been merged into the lab below for a unified experience. -->
        </div>
      </section>


      <section class="section-card" id="section-2">
        <h2>2. Canonical Convex Sets: Building Blocks</h2>

        <p>These fundamental convex sets appear repeatedly in optimization formulations. Recognizing them is essential for problem classification.</p>

        <h3>2.1 Hyperplanes and Halfspaces</h3>

        <p>A <a href="#" class="definition-link">hyperplane</a> is a set of the form:</p>
        $$
        H = \{x \in \mathbb{R}^n \mid a^\top x = b\}
        $$
        <p>where $a \in \mathbb{R}^n \setminus \{0\}$ and $b \in \mathbb{R}$. The vector $a$ is the <b>normal vector</b> (perpendicular to the hyperplane).</p>

        <div class="theorem-box">
          <h4>Geometric Interpretation</h4>
          <p>A hyperplane is an affine set of dimension $n-1$. It can be viewed as:</p>
          <ul>
            <li>The solution set of a single linear equation.</li>
            <li>A linear subspace ($a^\top x = 0$) translated by some vector $x_0$ (where $a^\top x_0 = b$).</li>
          </ul>
        </div>

        <p>A <a href="#" class="definition-link">halfspace</a> is a set of the form:</p>
        $$
        H^- = \{x \in \mathbb{R}^n \mid a^\top x \le b\}
        $$
        <p>This is the region on one side of the hyperplane. The complement halfspace is $H^+ = \{x \mid a^\top x \ge b\}$.</p>

        <div class="proof-box">
          <h4>Proof: Hyperplanes and Halfspaces are Convex</h4>

          <div class="proof-step">
            <strong>Hyperplane:</strong> Take $x_1, x_2 \in H$ and $\theta \in [0,1]$. Then:
            $$
            a^\top(\theta x_1 + (1-\theta)x_2) = \theta a^\top x_1 + (1-\theta)a^\top x_2 = \theta b + (1-\theta)b = b
            $$
            So the entire segment lies in $H$.
          </div>

          <div class="proof-step">
            <strong>Halfspace:</strong> Take $x_1, x_2 \in H^-$ (so $a^\top x_i \le b$) and $\theta \in [0,1]$. Then:
            $$
            a^\top(\theta x_1 + (1-\theta)x_2) = \theta a^\top x_1 + (1-\theta)a^\top x_2 \le \theta b + (1-\theta)b = b
            $$
            So the segment lies in $H^-$.
          </div>

          <div class="proof-step">
            <strong>Alternate View (Preimage):</strong> Define the linear function $f(x) = a^\top x$. Then $H^- = f^{-1}((-\infty, b])$. Since $(-\infty, b]$ is a convex interval in $\mathbb{R}$ and preimages of convex sets under affine maps are convex, $H^-$ is convex.
          </div>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/hyperplane-halfspace.png"
               alt="A 3D visualization of a hyperplane dividing space into two halfspaces"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.1:</i> A hyperplane (transparent plane) divides $\mathbb{R}^3$ into two halfspaces. The normal vector $a$ determines the orientation.</figcaption>
        </figure>

        <h3>2.2 Norm Balls and Ellipsoids</h3>

        <p>A <a href="#" class="definition-link" data-term="norm ball">norm ball</a> centered at $x_c$ with radius $r$ is:</p>
        $$
        B(x_c, r) = \{x \in \mathbb{R}^n \mid \|x - x_c\| \le r\}
        $$
        <p>where $\|\cdot\|$ is any norm. All norm balls are convex (by the triangle inequality).</p>

        <div class="theorem-box">
          <h4>Proof: Norm Balls are Convex</h4>
          <p>Let $x, y \in B(x_c, r)$ and $\theta \in [0,1]$. Then $\|x - x_c\| \le r$ and $\|y - x_c\| \le r$.</p>
          $$
          \begin{aligned}
          \|(\theta x + (1-\theta)y) - x_c\| &= \|\theta(x - x_c) + (1-\theta)(y - x_c)\| \\
          &\le \theta\|x - x_c\| + (1-\theta)\|y - x_c\| \\
          &\le \theta r + (1-\theta)r = r
          \end{aligned}
          $$
          <p>Thus the convex combination is in the ball.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="../../topics/00-linear-algebra-primer/assets/norm-balls.png"
               alt="Comparison of unit balls for L1, L2, and L-infinity norms"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.2:</i> Unit balls for different norms in $\mathbb{R}^2$: $L_1$ (diamond), $L_2$ (circle), and $L_\infty$ (square). All are convex sets.</figcaption>
        </figure>

        <p>An <a href="#" class="definition-link">ellipsoid</a> is a generalized Euclidean ball, defined as:</p>
        $$
        \mathcal{E} = \{x \in \mathbb{R}^n \mid (x - x_c)^\top P^{-1} (x - x_c) \le 1\}
        $$
        <p>where $P \in \mathbb{S}^n_{++}$ (symmetric positive definite). $P$ determines the shape and orientation.</p>

        <div class="insight">
          <h4>Geometric Interpretation via Eigendecomposition</h4>
          <p>Let $P = Q \Lambda Q^\top$ be the eigendecomposition of $P$, where $\Lambda = \text{diag}(\lambda_1, \dots, \lambda_n)$. The semi-axes of the ellipsoid are aligned with the eigenvectors $q_i$ (columns of $Q$) and have lengths $\sqrt{\lambda_i}$.</p>
          <p>Alternatively, an ellipsoid is the image of the unit Euclidean ball under an affine mapping: $\mathcal{E} = f(B(0,1))$ where $f(u) = P^{1/2}u + x_c$. Since affine maps preserve convexity, ellipsoids are convex.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/ellipsoid-axes.png"
               alt="Anatomy of an ellipsoid showing principal axes aligned with eigenvectors"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.3:</i> An ellipsoid is defined by a PSD matrix $P$. Its principal axes align with the eigenvectors of $P$, and their lengths are the square roots of the eigenvalues.</figcaption>
        </figure>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Explorer: Ellipsoid Geometry</h3>
          <p><b>See How PSD Matrices Define Ellipsoids:</b> An ellipsoid is defined by $\{x \mid (x-x_c)^\top P^{-1} (x-x_c) \le 1\}$ where $P \succ 0$. This tool lets you:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Adjust matrix P:</b> Modify the PSD matrix entries and watch the ellipsoid reshape in real-time</li>
            <li><b>Visualize eigenvectors:</b> The principal axes align with eigenvectors of $P$</li>
            <li><b>Observe eigenvalue effects:</b> Axis lengths are proportional to $\sqrt{\lambda_i}$ where $\lambda_i$ are eigenvalues</li>
          </ul>
          <div id="widget-ellipsoid-explorer" style="width: 100%; height: 400px; position: relative;"></div>
        </div>

        <h3>2.3 Polyhedra</h3>

        <p>A <a href="#" class="definition-link">polyhedron</a> is the solution set of finitely many linear inequalities and equalities:</p>
        $$
        \mathcal{P} = \{x \in \mathbb{R}^n \mid Ax \le b, \ Cx = d\}
        $$
        <p>Geometrically, a polyhedron is the intersection of a finite number of halfspaces and hyperplanes.</p>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/polyhedron-construction.png"
               alt="A polyhedron formed by the intersection of multiple halfspaces"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.4:</i> A polyhedron (central solid region) is formed by intersecting multiple halfspaces. Each face corresponds to one linear inequality constraint.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Convexity of Polyhedra</h4>
          <p>Since halfspaces and hyperplanes are convex sets, and the intersection of any collection of convex sets is convex (see Section 3), a polyhedron is convex.</p>
        </div>

        <p>A <a href="#" class="definition-link">polytope</a> is a bounded polyhedron. Equivalently, it is the convex hull of a finite set of points.</p>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Visualizer: Polyhedron Builder</h3>
          <p><b>Build Feasible Regions from Constraints:</b> A polyhedron is the intersection of finitely many halfspaces. This tool brings LP feasible sets to life:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Add constraints one at a time:</b> Drag to define linear inequalities $a^\top x \le b$</li>
            <li><b>Visualize normals:</b> See the normal vector $a$ pointing <i>out</i> of the feasible region</li>
            <li><b>Watch the intersection:</b> As you add constraints, see how the feasible region is carved out of the plane</li>
          </ul>
          <div id="widget-polyhedron-visualizer" style="width: 100%; height: 520px; position: relative;"></div>
        </div>

        <h3>2.4 The Positive Semidefinite (PSD) Cone</h3>

        <p>The set of symmetric positive semidefinite matrices is a central object in modern convex optimization, forming the domain for <b>Semidefinite Programming (SDP)</b> (<a href="../04-convex-opt-problems/index.html">Lecture 04</a>). Its properties rely on the eigenvalue characterizations from <a href="../00-linear-algebra-primer/index.html">Lecture 00</a>.</p>
        $$
        \mathbb{S}^n_+ = \{X \in \mathbb{S}^n \mid X \succeq 0\}
        $$
        <p>where $X \succeq 0$ means $z^\top X z \ge 0$ for all vectors $z \in \mathbb{R}^n$.</p>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/psd-cone-3d.png"
               alt="Visualization of the 2x2 PSD cone in 3D space"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.5:</i> The cone of $2 \times 2$ PSD matrices visualized in 3D space (axes are the matrix entries $x, y, z$). It is a convex cone with a specific "ice-cream" like shape but with a flat boundary structure.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof: The PSD Cone is Convex</h4>
          <p>We need to show that if $A, B \in \mathbb{S}^n_+$ and $\theta \in [0,1]$, then $\theta A + (1-\theta)B \in \mathbb{S}^n_+$.</p>
          <div class="proof-step">
            <strong>Definition Check:</strong> Let $z \in \mathbb{R}^n$ be any vector.
            $$
            z^\top (\theta A + (1-\theta)B) z = \theta (z^\top A z) + (1-\theta) (z^\top B z)
            $$
          </div>
          <div class="proof-step">
            <strong>Sign Analysis:</strong> Since $A, B \succeq 0$, we know $z^\top A z \ge 0$ and $z^\top B z \ge 0$. Since $\theta \in [0,1]$, both coefficients are non-negative.
          </div>
          <div class="proof-step">
            <strong>Conclusion:</strong> The sum is non-negative, so $z^\top (\theta A + (1-\theta)B) z \ge 0$ for all $z$. Thus the combination is PSD.
          </div>
        </div>

        <div class="example">
            <h4>Spectrahedra: The Shape of SDP</h4>
            <p>The intersection of the PSD cone with an affine subspace is called a <a href="#" class="definition-link">spectrahedron</a>. These are the feasible sets for Semidefinite Programs (SDPs). Unlike polyhedra, they have smooth, curved boundaries.</p>
            <figure style="text-align: center; margin: 24px 0;">
              <img src="assets/spectrahedron.png"
                   alt="A spectrahedron (feasible set of an LMI)"
                   style="max-width: 50%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 2.6:</i> A spectrahedron looks like a "puffy" polygon. Its faces are flat where the affine space cuts the cone's boundary, but its edges and corners can be smooth curves.</figcaption>
            </figure>
        </div>
      </section>


      <section class="section-card" id="section-3">
        <h2>3. Operations that Preserve Convexity</h2>

        <p>We can prove that a complex set is convex by building it from simpler convex sets using operations that preserve convexity. This is the "calculus" of convex sets.</p>


        <h3>3.1 Intersection</h3>

        <div class="theorem-box">
          <h4>Theorem (Intersection Preserves Convexity)</h4>
          <p>The intersection of any collection (finite or infinite) of convex sets is convex.</p>
          $$ C = \bigcap_{i \in I} C_i $$
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-intersection.png"
               alt="Venn diagram showing the intersection of two convex sets is convex"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 3.1:</i> The intersection of two convex sets (blue and yellow) is the green region. Note that while the union is not necessarily convex, the intersection always is.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof</h4>
          <div class="proof-step">
            Let $x, y \in C$. By definition, $x \in C_i$ and $y \in C_i$ for all $i \in I$.
          </div>
          <div class="proof-step">
            Since each $C_i$ is convex, $\theta x + (1-\theta)y \in C_i$ for all $i \in I$.
          </div>
          <div class="proof-step">
            Therefore, $\theta x + (1-\theta)y \in \bigcap_{i \in I} C_i = C$.
          </div>
        </div>

        <div class="example">
          <h4>Advanced Example: Trigonometric Polynomials</h4>
          <p>Consider the set of coefficients $x \in \mathbb{R}^m$ such that the trigonometric polynomial $p_x(t) = \sum_{k=1}^m x_k \cos(kt)$ is bounded by 1 on an interval:</p>
          $$
          S = \{x \in \mathbb{R}^m \mid |p_x(t)| \le 1 \text{ for all } |t| \le \pi/3\}
          $$
          <p>This set can be written as an infinite intersection of halfspaces:</p>
          $$
          S = \bigcap_{|t| \le \pi/3} \{x \mid -1 \le c(t)^\top x \le 1\}
          $$
          <p>where $c(t) = (\cos(t), \dots, \cos(mt))$. Since each constraint defines a convex "slab" (intersection of two halfspaces), the infinite intersection $S$ is convex.</p>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
            <figure style="text-align: center; flex: 1;">
              <img src="assets/trig-poly-intersection.png"
                   alt="Plot of the convex set of bounded trigonometric polynomials"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 3.2:</i> The set $S$ defined by infinite constraints.</figcaption>
            </figure>
            <figure style="text-align: center; flex: 1;">
              <img src="assets/gonzo-shape.png"
                   alt="Visualizing the intersection of infinite halfspaces"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 3.3:</i> The smooth convex "safe zone" formed by tangent hyperplanes.</figcaption>
            </figure>
        </div>
<h3>3.2 Affine Functions Preserve Convexity</h3>

        <p>Let $f : \mathbb{R}^n \to \mathbb{R}^m$ be an affine function, $f(x) = Ax + b$.</p>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/affine-image-projection.png"
                    alt="Projection of a polyhedron onto 2D space"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.4:</i> The image of a convex set (polyhedron) under an affine map (projection) is convex.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/affine-preimage-cone.png"
                    alt="Slice of a cone by a plane"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.5:</i> The preimage of a convex cone (intersection with a plane) is a convex set (an ellipse).</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Theorem (Affine Image and Preimage)</h4>
          <ul>
            <li><b>Image:</b> If $C \subseteq \mathbb{R}^n$ is convex, then $f(C) = \{Ax + b \mid x \in C\} \subseteq \mathbb{R}^m$ is convex.</li>
            <li><b>Preimage (Inverse Image):</b> If $D \subseteq \mathbb{R}^m$ is convex, then $f^{-1}(D) = \{x \in \mathbb{R}^n \mid Ax + b \in D\}$ is convex.</li>
          </ul>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>

          <div class="proof-step">
            <strong>Image:</strong> Take $y_1, y_2 \in f(C)$, so $y_1 = Ax_1 + b$ and $y_2 = Ax_2 + b$ for some $x_1, x_2 \in C$. For $\theta \in [0,1]$:
            $$
            \theta y_1 + (1-\theta)y_2 = \theta(Ax_1 + b) + (1-\theta)(Ax_2 + b) = A(\theta x_1 + (1-\theta)x_2) + b
            $$
            Since $C$ is convex, $\theta x_1 + (1-\theta)x_2 \in C$, so $\theta y_1 + (1-\theta)y_2 \in f(C)$.
          </div>

          <div class="proof-step">
            <strong>Preimage:</strong> Take $x_1, x_2 \in f^{-1}(D)$, so $Ax_1 + b \in D$ and $Ax_2 + b \in D$. For $\theta \in [0,1]$:
            $$
            A(\theta x_1 + (1-\theta)x_2) + b = \theta(Ax_1 + b) + (1-\theta)(Ax_2 + b)
            $$
            Since $D$ is convex, the right side is in $D$, so $\theta x_1 + (1-\theta)x_2 \in f^{-1}(D)$.
          </div>
        </div>

        <div class="example">
          <h4>Application: Ellipsoids are Convex</h4>
          <p>An ellipsoid $\mathcal{E} = \{x \mid (x - x_c)^\top P^{-1} (x - x_c) \le 1\}$ where $P \succ 0$ can be written as:</p>
          $$
          \mathcal{E} = \{x \mid \|P^{-1/2}(x - x_c)\|_2 \le 1\}
          $$
          <p>This is the preimage of the Euclidean ball $\{z \mid \|z\|_2 \le 1\}$ (convex) under the affine map $f(x) = P^{-1/2}(x - x_c)$. Since preimages preserve convexity, $\mathcal{E}$ is convex.</p>
          <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/image-vs-preimage-ball.png"
                    alt="Comparison of image vs preimage of a ball"
                    style="max-width: 60%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.6:</i> The image of a ball is an ellipsoid (left). The preimage of a ball (slab) is also convex (right).</figcaption>
          </figure>
        </div>

        <div class="insight">
            <h4>Counterexample: Non-Affine Maps</h4>
            <p>Convexity is fragile. Non-affine maps, such as $f(x) = 1/x$ or $f(x) = x^2$, do not generally preserve convexity of sets.</p>
            <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/division-counterexample.png"
                    alt="Division function mapping a convex set to non-convex"
                    style="max-width: 50%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.7:</i> The "division" map $f(x,y) = x/y$ can tear a convex square into two disjoint (non-convex) pieces.</figcaption>
            </figure>
        </div>

        <h3>3.3 Perspective and Linear-Fractional Functions</h3>

        <p>The <b>perspective function</b> $P : \mathbb{R}^{n+1} \to \mathbb{R}^n$ is defined by:</p>
        $$
        P(x, t) = x/t, \quad \mathrm{dom}\, P = \{(x, t) \mid t > 0\}
        $$
        <p>Geometrically, this corresponds to a pinhole camera projection: points $(x,t)$ are projected onto the plane $t=1$ via lines through the origin.</p>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/pinhole-camera.png"
                    alt="Geometric intuition of perspective projection"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.8:</i> The perspective map $P(x,t) = x/t$ projects 3D points onto the $t=1$ plane. The image of a convex object (ellipsoid) is a convex shadow.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/perspective-domain.png"
                    alt="Domain of the perspective map"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.9:</i> The domain is restricted to $t > 0$. As $t \to 0$, the projected point shoots to infinity.</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>The perspective function preserves convexity: if $C \subseteq \mathbb{R}^{n+1}$ is convex, then $P(C)$ is convex.</p>
        </div>

        <p>A <a href="#" class="definition-link">linear-fractional function</a> is a composition of perspective with an affine function:</p>
        $$
        f(x) = \frac{Ax + b}{c^\top x + d}
        $$
        <p>Since it is composed of operations that preserve convexity (Affine $\to$ Perspective), linear-fractional functions also preserve convexity.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/composition-maps.png"
                  alt="Block diagram of function composition"
                  style="max-width: 60%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 3.10:</i> Linear-fractional functions are built by composing an affine map $g(x)$ with the perspective map $P$.</figcaption>
        </figure>

        <div class="example">
             <h4>Visualizing Projective Geometry</h4>
             <p>Linear-fractional maps can distort space significantly, turning parallel lines into converging ones (like train tracks on a horizon), yet they strictly preserve the convexity of sets.</p>
             <figure style="text-align: center; margin: 24px 0;">
                  <img src="assets/warping-grid.png"
                       alt="Grid warped by a linear-fractional map"
                       style="max-width: 60%; height: auto; border-radius: 8px;" />
                  <figcaption><i>Figure 3.11:</i> A regular grid (left) is warped by a linear-fractional transformation (right). Squares become "conic" quadrilaterals, but they remain convex sets.</figcaption>
             </figure>
        </div>

        <h3>3.4 Minkowski Sum</h3>
        <p>The <a href="#" class="definition-link">Minkowski sum</a> of two sets $C, D \subseteq \mathbb{R}^n$ is the set of all vector sums:</p>
        $$ C + D = \{x + y \mid x \in C, y \in D\} $$

        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>If $C$ and $D$ are convex, then $C+D$ is convex.</p>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>
          <p>Let $u, v \in C+D$. Then $u = c_1 + d_1$ and $v = c_2 + d_2$ for some $c_i \in C, d_i \in D$.
          For any $\theta \in [0,1]$:</p>
          $$
          \theta u + (1-\theta)v = \theta(c_1 + d_1) + (1-\theta)(c_2 + d_2)
          = [\theta c_1 + (1-\theta)c_2] + [\theta d_1 + (1-\theta)d_2]
          $$
          <p>Since $C$ is convex, the first bracket is in $C$. Since $D$ is convex, the second is in $D$. Thus the sum is in $C+D$.</p>
        </div>

        <h3>3.5 Cartesian Product</h3>
        <p>The product of convex sets $C \subseteq \mathbb{R}^n$ and $D \subseteq \mathbb{R}^m$ is convex in $\mathbb{R}^{n+m}$:</p>
        $$ C \times D = \{(x, y) \mid x \in C, y \in D\} $$
        <p>This follows because component-wise convex combinations preserve membership in $C$ and $D$ respectively.</p>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Laboratory: Convex Geometry</h3>
          <p><b>Draw, Combine, and Verify:</b> This unified workspace lets you experiment with convex sets and operations. It combines drawing capabilities with set algebra:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Draw Custom Sets:</b> Use the pen tool to draw polygons. Double-click to close.</li>
            <li><b>Add Primitives:</b> Quickly add standard convex sets like circles and squares.</li>
            <li><b>Apply Operations:</b> Select multiple sets (Shift+Click) and apply operations like <b>Intersection</b>, <b>Convex Hull</b>, or <b>Minkowski Sum</b>.</li>
            <li><b>Verify Convexity:</b> The lab automatically labels sets as Convex (C) or Non-Convex (NC).</li>
          </ul>
          <p><i>Key Concept:</i> Notice how the intersection of any two sets (even non-convex ones) doesn't guarantee convexity, but the intersection of <i>convex</i> sets is always convex!</p>
          <div id="widget-convex-geometry-lab" style="width: 100%; position: relative;"></div>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. Separating and Supporting Hyperplane Theorems</h2>

        <p>These theorems are the geometric backbone of duality theory, optimality conditions, and many algorithms in convex optimization.</p>

        <h3>4.1 The Separating Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Separating Hyperplane)</h4>
          <p>Let $C, D \subseteq \mathbb{R}^n$ be nonempty, disjoint, convex sets. Then there exists a hyperplane that separates them: there exist $a \in \mathbb{R}^n \setminus \{0\}$ and $b \in \mathbb{R}$ such that:</p>
          $$
          a^\top x \le b \quad \forall x \in C, \qquad a^\top y \ge b \quad \forall y \in D
          $$
          <p>If additionally one of $C$ or $D$ is compact, or if $\mathrm{dist}(C, D) > 0$, then we can achieve <b>strict separation</b> (with $<$ and $>$ instead of $\le$ and $\ge$).</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/separating-hyperplane-strict.png"
               alt="Illustration of the Separating Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 4.1:</i> A hyperplane separating two disjoint convex sets $C$ and $D$. For closed sets, we can construct the separator using the projection of 0 onto their difference set $C-D$.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof (Constructive via Projection)</h4>

          <div class="proof-step">
            <strong>Step 1: Form the difference set.</strong> Define $S = C - D = \{c - d \mid c \in C, d \in D\}$. Since $C$ and $D$ are convex, $S$ is convex. Since $C \cap D = \emptyset$, we have $0 \notin S$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Project zero onto $S$.</strong> Let $p$ be the unique projection of $0$ onto $\mathrm{cl}(S)$ (the closure). This exists and is unique because closed convex sets have unique projections. Since $0 \notin S$, we have $p \neq 0$.
          </div>

          <div class="proof-step">
            <strong>Step 3: Use projection characterization.</strong> For any $z \in S$, the projection property (from <a href="../00-linear-algebra-primer/index.html">Lecture 00</a>) gives:
            $$
            p^\top z \ge p^\top p = \|p\|_2^2 > 0
            $$
            Writing $z = c - d$ for arbitrary $c \in C, d \in D$:
            $$
            p^\top c - p^\top d \ge \|p\|_2^2 > 0 \quad \implies \quad p^\top c \ge p^\top d + \|p\|_2^2
            $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Define the separating hyperplane.</strong> Set $a = p$ and choose:
            $$
            b = \frac{1}{2}\left(\inf_{c \in C} a^\top c + \sup_{d \in D} a^\top d\right)
            $$
            Then $a^\top c \ge b \ge a^\top d$ for all $c \in C, d \in D$, achieving separation.
          </div>

          <div class="proof-step">
            <strong>Step 5: Strict separation.</strong> If $\mathrm{dist}(C, D) = \delta > 0$ or one set is compact, we can choose $b$ strictly between the supremum and infimum to get strict inequalities.
          </div>
        </div>

        <h3>4.2 The Supporting Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Supporting Hyperplane)</h4>
          <p>Let $C \subseteq \mathbb{R}^n$ be a nonempty, closed, convex set, and let $x_0 \in \partial C$ (the boundary of $C$). Then there exists a <b>supporting hyperplane</b> to $C$ at $x_0$: there exists $a \in \mathbb{R}^n \setminus \{0\}$ such that:</p>
          $$
          a^\top x \le a^\top x_0 \quad \forall x \in C
          $$
          <p>The hyperplane $\{x \mid a^\top x = a^\top x_0\}$ "supports" $C$ at $x_0$â€”it touches $C$ at $x_0$ and $C$ lies entirely on one side.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/supporting-hyperplane-tangent.png"
               alt="Illustration of the Supporting Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 4.2:</i> A supporting hyperplane to a convex set at a boundary point. It "kisses" the set without cutting into it.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof (via Projection)</h4>

          <div class="proof-step">
            <strong>Step 1: Take an exterior point.</strong> Since $x_0 \in \partial C$ (boundary), there exists a sequence $\{y_k\} \subset \mathbb{R}^n \setminus C$ with $y_k \to x_0$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Project each $y_k$ onto $C$.</strong> Let $p_k = \Pi_C(y_k)$ be the projection. By the projection characterization:
            $$
            (y_k - p_k)^\top (x - p_k) \le 0 \quad \forall x \in C
            $$
          </div>

          <div class="proof-step">
            <strong>Step 3: Pass to the limit.</strong> As $k \to \infty$, we have $p_k \to x_0$ (since $y_k \to x_0$ and projections are continuous). Normalize $a_k = (y_k - p_k) / \|y_k - p_k\|_2$ and extract a convergent subsequence $a_k \to a$ with $\|a\|_2 = 1$. Taking limits:
            $$
            a^\top (x - x_0) \le 0 \quad \forall x \in C
            $$
            Rearranging: $a^\top x \le a^\top x_0$ for all $x \in C$.
          </div>
        </div>

        <div class="insight">
          <h4>ðŸ”‘ Why These Theorems Matter</h4>
          <ul>
            <li><b>Duality:</b> The separating hyperplane theorem is the geometric foundation of <b>Lagrangian duality</b> (<a href="../05-duality/index.html">Lecture 05</a>)</li>
            <li><b>Optimality:</b> The supporting hyperplane theorem leads to first-order optimality conditions (KKT conditions)</li>
            <li><b>Algorithms:</b> Cutting-plane methods and bundle methods rely on separating hyperplanes</li>
            <li><b>Subgradients:</b> Supporting hyperplanes define subgradients for non-smooth convex functions</li>
          </ul>
          <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/separation-failure.png"
                    alt="Failure of separation for non-convex sets"
                    style="max-width: 60%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 4.3:</i> <b>Cautionary Tale:</b> If the sets are not convex (like the C-shape), a separating hyperplane may not exist. This is why convexity is required for strong duality.</figcaption>
          </figure>
        </div>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Explorer: Separating Hyperplanes</h3>
          <p><b>Find Hyperplanes that Separate Convex Sets:</b> This widget makes the Separating Hyperplane Theorem tangible:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Draw two sets:</b> Click to define vertices of two convex polygons</li>
            <li><b>Drag to move:</b> Move the sets around and watch the separating hyperplane update in real-time</li>
            <li><b>Auto-compute separation:</b> The tool uses the closest-point algorithm (constructive proof logic) to find the optimal separator</li>
            <li><b>Observe the boundary case:</b> See what happens when the sets touch (strict separation becomes non-strict)</li>
            <li><b>Violate separation:</b> If you make the sets overlap, the tool detects the collision and shows no hyperplane exists</li>
          </ul>
          <p><i>Connection to optimization:</i> This is exactly what happens in SVM classificationâ€”finding the maximum-margin separating hyperplane between two classes of data points!</p>
          <div id="widget-separating-hyperplane" style="width: 100%; height: 450px; position: relative;"></div>
        </div>
      </section>


      <section class="section-card" id="section-5">
        <h2>5. Cones, Proper Cones, and Dual Cones</h2>

        <h3>5.1 Cones and Convex Cones</h3>

        <p>A set $K \subseteq \mathbb{R}^n$ is a <a href="#" class="definition-link">cone</a> if it is closed under non-negative scaling:</p>
        $$ x \in K, \ \alpha \ge 0 \implies \alpha x \in K $$

        <p>A <a href="#" class="definition-link">convex cone</a> is a cone that is also a convex set. Equivalently, it is closed under non-negative linear combinations:</p>
        $$ x, y \in K, \ \alpha, \beta \ge 0 \implies \alpha x + \beta y \in K $$

        <div class="example">
            <h4>Examples of Convex Cones</h4>
            <ul>
                <li><b>Non-negative orthant:</b> $\mathbb{R}^n_+ = \{x \in \mathbb{R}^n \mid x_i \ge 0\}$</li>
                <li><b>Second-order cone (Lorentz cone):</b> $\mathcal{Q}^{n+1} = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\|_2 \le t\}$</li>
                <li><b>Norm Cone (Epigraph of a Norm):</b> For any norm $\|\cdot\|$, the set $C = \{(x, t) \mid \|x\| \le t\}$ is a convex cone.
                  <br><i>Proof:</i> If $(x, t) \in C$, then $\|\alpha x\| = \alpha \|x\| \le \alpha t$, so $\alpha(x, t) \in C$. If $\|x\| \le t$ and $\|y\| \le s$, then $\|x+y\| \le \|x\| + \|y\| \le t + s$, so $(x+y, t+s) \in C$. This generalizes the Second-Order Cone.
                </li>
                <li><b>PSD Cone:</b> $\mathbb{S}^n_+ = \{X \in \mathbb{S}^n \mid X \succeq 0\}$</li>
            </ul>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/second-order-cone.png"
                    alt="3D visualization of the second-order cone (ice cream cone)"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.1:</i> The Second-Order Cone in $\mathbb{R}^3$ (ice-cream cone) is defined by $\|x\|_2 \le t$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/hyperbolic-cone.png"
                    alt="3D visualization of a hyperbolic cone"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.2:</i> A Hyperbolic Cone (generalized version). The cross-sections are ellipses that grow as you move up the axis.</figcaption>
             </figure>
        </div>

        <h3>5.2 Proper Cones</h3>

        <p>A <a href="#" class="definition-link">proper cone</a> is a convex cone $K$ that satisfies three additional properties:</p>
        <ol>
          <li><b>Closed:</b> $K$ contains its boundary.</li>
          <li><b>Pointed:</b> $K$ contains no lines ($K \cap -K = \{0\}$).</li>
          <li><b>Solid:</b> $K$ has a non-empty interior.</li>
        </ol>

        <p>Proper cones are geometrically "sharp" (pointed) and "full-dimensional" (solid). They are used to define generalized inequalities.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/cone-zoo.png"
                  alt="Examples of proper and improper cones"
                  style="max-width: 90%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 5.3:</i> The "Cone Zoo". Left: A proper cone (closed, pointed, solid). Center: A wedge (not pointed, contains a line). Right: A flat slice (not solid, empty interior).</figcaption>
        </figure>

        <div class="example">
            <h4>Example: Nonnegative Polynomials</h4>
            <p>The set of polynomials of degree $n$ that are non-negative on an interval $[0,1]$ forms a proper convex cone in the space of coefficients.</p>
            <figure style="text-align: center; margin: 24px 0;">
                 <img src="assets/nonnegative-poly-cone.png"
                      alt="Cone of nonnegative polynomials"
                      style="max-width: 50%; height: auto; border-radius: 8px;" />
                 <figcaption><i>Figure 5.4:</i> Visualizing the cone of polynomials $P(t)$ such that $P(t) \ge 0$ for $t \in [0,1]$. The boundary corresponds to polynomials with roots in the interval.</figcaption>
            </figure>
        </div>

        <h3>5.3 Generalized Inequalities</h3>

        <p>A proper cone $K$ defines a partial ordering $\preceq_K$ on $\mathbb{R}^n$:</p>
        $$
        x \preceq_K y \iff y - x \in K
        $$
        <p>Strict inequality is defined using the interior of the cone:</p>
        $$
        x \prec_K y \iff y - x \in \text{int}(K)
        $$

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/generalized-inequality-cone.png"
                    alt="Visualizing generalized inequality"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.5:</i> Visualizing $x \preceq_K y$. The point $x$ must lie in the "shadow" of $y$ cast by the cone $-K$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/matrix-inequality-cone.png"
                    alt="Matrix inequality ordering"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.6:</i> Partial ordering in the PSD cone. $A \preceq B$ means $B-A$ is in the PSD cone.</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Properties of Generalized Inequalities</h4>
          <ul>
            <li><b>Reflexive:</b> $x \preceq_K x$</li>
            <li><b>Antisymmetric:</b> $x \preceq_K y \text{ and } y \preceq_K x \implies x = y$</li>
            <li><b>Transitive:</b> $x \preceq_K y \text{ and } y \preceq_K z \implies x \preceq_K z$</li>
            <li><b>Additivity:</b> $x \preceq_K y \implies x + u \preceq_K y + u$</li>
          </ul>
        </div>

        <div class="insight">
             <h4>Minimum vs. Minimal</h4>
             <p>Because the ordering is partial, we distinguish between a <b>minimum</b> element (smaller than everyone, e.g., the origin in $\mathbb{R}^n_+$) and a <b>minimal</b> element (nothing is smaller than it, but it might not compare to everyone).</p>
             <figure style="text-align: center; margin: 24px 0;">
                  <img src="assets/minimum-vs-minimal.png"
                       alt="Minimum vs minimal elements"
                       style="max-width: 60%; height: auto; border-radius: 8px;" />
                  <figcaption><i>Figure 5.7:</i> Left: Minimum element (unique). Right: Minimal elements (red boundary). In vector optimization (Pareto optimality), we seek minimal elements.</figcaption>
             </figure>
        </div>

        <h3>5.4 The Dual Cone</h3>

        <p>The <a href="#" class="definition-link">dual cone</a> of a cone $K$ is the set of all vectors making a non-obtuse angle with every vector in $K$:</p>
        $$
        K^* = \{y \in \mathbb{R}^n \mid y^\top x \ge 0 \ \forall x \in K\}
        $$
        <p>The dual cone $K^*$ is always a closed convex cone, regardless of whether $K$ is convex or closed.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/dual-cone-geometry.png"
                  alt="Geometry of primal and dual cones"
                  style="max-width: 50%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 5.8:</i> The dual cone $K^*$ (red) consists of vectors that make an angle $\le 90^\circ$ with every vector in $K$ (blue).</figcaption>
        </figure>

        <div class="theorem-box">
            <h4>Important Dualities</h4>
            <ul>
                <li>$\mathbb{R}^n_+$ is <b>self-dual</b>: $(\mathbb{R}^n_+)^* = \mathbb{R}^n_+$</li>
                <li>$\mathbb{S}^n_+$ is <b>self-dual</b>: $(\mathbb{S}^n_+)^* = \mathbb{S}^n_+$ (under trace inner product)</li>
                <li>$\mathcal{Q}^{n+1}$ is <b>self-dual</b>: $(\mathcal{Q}^{n+1})^* = \mathcal{Q}^{n+1}$</li>
                <li>$(L_p \text{ norm cone})^* = L_q \text{ norm cone}$ where $1/p + 1/q = 1$.</li>
            </ul>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/self-dual-cones.png"
                    alt="The three major self-dual cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.9:</i> The Big Three self-dual cones: Nonnegative Orthant, Second-Order Cone, and PSD Cone.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/dual-norm-cones.png"
                    alt="Dual relationship between L1 and L-infinity cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.10:</i> Duality of Norm Cones: The dual of the $L_1$ cone is the $L_\infty$ cone.</figcaption>
             </figure>
        </div>
      </section>


      <section class="section-card" id="section-6">
        <h2>6. Topological Toolkit: Closure, Interior, Relative Interior</h2>

        <p>To work precisely with convex sets and optimality conditions, we need clear notions of "inside," "edge," and "outside."</p>

        <h3>6.1 Basic Topological Definitions</h3>

        <p>Let $C \subseteq \mathbb{R}^n$ be any set.</p>

        <ul>
          <li><b>Closure</b> $\mathrm{cl}(C)$: The set of all limits of convergent sequences in $C$. It's the smallest closed set containing $C$.</li>
          <li><b>Interior</b> $\mathrm{int}(C)$: Points with some open ball fully contained in $C$. Intuitively, "strictly inside" $C$.</li>
          <li><b>Boundary</b> $\partial C = \mathrm{cl}(C) \setminus \mathrm{int}(C)$: The "edge" of $C$.</li>
          <li><b>Affine hull</b> $\mathrm{aff}(C)$: The smallest affine set containing $C$.</li>
          <li><b>Relative interior</b> $\mathrm{ri}(C)$: The interior of $C$ <i>relative to</i> $\mathrm{aff}(C)$. Points strictly inside when viewed in the affine hull.</li>
        </ul>

        <div class="example">
          <h4>Example 1: Line Segment in $\mathbb{R}^2$</h4>
          <p>Consider $C = \{(t, 0) \mid 0 \le t \le 1\}$ (a line segment on the $x$-axis).</p>
          <ul>
            <li>$\mathrm{int}(C) = \emptyset$ (no open ball in $\mathbb{R}^2$ fits inside a line)</li>
            <li>$\mathrm{aff}(C) = \{(t, 0) \mid t \in \mathbb{R}\}$ (the entire $x$-axis)</li>
            <li>$\mathrm{ri}(C) = \{(t, 0) \mid 0 < t < 1\}$ (interior relative to the $x$-axis)</li>
          </ul>
        </div>

        <div class="example">
          <h4>Example 1b: A Flat Disk in 3D</h4>
          <p>Consider a flat circular disk floating in 3D space: $C = \{(x, y, 0) \mid x^2 + y^2 \le 1\}$.</p>
          <ul>
            <li><b>Interior:</b> Empty ($\emptyset$). A 3D ball has volume, but this disk is flat, so no 3D ball fits inside it.</li>
            <li><b>Affine Hull:</b> The $xy$-plane ($z=0$).</li>
            <li><b>Relative Interior:</b> The disk without its boundary circle: $\{(x, y, 0) \mid x^2 + y^2 < 1\}$. Viewed "relative" to the plane it lives in, it has an interior!</li>
          </ul>
        </div>

        <div class="example">
          <h4>Example 2: Standard Simplex</h4>
          <p>$\Delta^n = \{x \in \mathbb{R}^n \mid x \ge 0, \mathbf{1}^\top x = 1\}$.</p>
          <ul>
            <li>$\mathrm{int}(\Delta^n) = \emptyset$ (lies in a hyperplane)</li>
            <li>$\mathrm{aff}(\Delta^n) = \{x \mid \mathbf{1}^\top x = 1\}$ (the hyperplane)</li>
            <li>$\mathrm{ri}(\Delta^n) = \{x > 0 \mid \mathbf{1}^\top x = 1\}$ (all coordinates strictly positive)</li>
          </ul>
        </div>

        <h3>6.2 Key Properties for Convex Sets</h3>

        <div class="theorem-box">
          <h4>Facts About Convex Sets</h4>
          <ol>
            <li><b>Closure is Convex:</b> $\mathrm{cl}(C)$ is convex.
              <br><i>Proof:</i> Let $a, b \in \mathrm{cl}(C)$. Then there exist sequences $a_k \to a, b_k \to b$ with $a_k, b_k \in C$. For any $\theta$, the sequence $z_k = \theta a_k + (1-\theta)b_k$ lies in $C$ (by convexity) and converges to $\theta a + (1-\theta)b$. Thus the limit is in $\mathrm{cl}(C)$.
            </li>
            <li>$\mathrm{int}(C)$ (if nonempty) and $\mathrm{ri}(C)$ are convex.</li>
            <li>If $C$ is convex with nonempty interior, then $\mathrm{cl}(C) = \mathrm{cl}(\mathrm{int}(C))$ and $\mathrm{int}(C) = \mathrm{int}(\mathrm{cl}(C))$.</li>
            <li><b>Relative interior of intersection:</b> If $\mathrm{ri}(C) \cap \mathrm{ri}(D) \neq \emptyset$, then:
              $$
              \mathrm{ri}(C \cap D) = \mathrm{ri}(C) \cap \mathrm{ri}(D)
              $$
            </li>
            <li><b>Affine functions:</b> If $f(x) = Ax + b$, then $f(\mathrm{ri}(C)) = \mathrm{ri}(f(C))$ for convex $C$.</li>
          </ol>
        </div>

        <h3>6.3 Why Relative Interior Matters</h3>

        <p>Relative interior is crucial for:</p>
        <ul>
          <li><b>Constraint qualifications:</b> Slater's condition for strong duality (Lecture 05) requires a point in $\mathrm{ri}(\mathrm{dom}(f_0))$</li>
          <li><b>Optimality conditions:</b> KKT conditions require regularity at boundary points</li>
          <li><b>Interior-point methods:</b> Algorithms that approach optimality from the relative interior</li>
        </ul>
      </section>

      <!-- SECTION 7: EXERCISES -->
      <section class="section-card" id="section-7">
        <h2><i data-feather="edit-3"></i> 7. Exercises</h2>

        <p>These problems consolidate all exercises from throughout the lecture and add additional practice.</p>

        <div class="problem">
          <h3>P2.1 â€” Convexity of Distance Set</h3>
          <p>Show that the set of points closer to a given point $x_0$ than to another point $y_0$, defined as:</p>
          $$
          C = \{x \in \mathbb{R}^n \mid \|x - x_0\|_2 \le \|x - y_0\|_2\}
          $$
          <p>is a convex set.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Geometric Bisector:</b> The set of points closer to $x_0$ than $y_0$ is the halfspace defined by the perpendicular bisector of the segment $[x_0, y_0]$. Since halfspaces are convex, this set is convex.</li>
            <li><b>Algebraic Verification:</b> Expanding $\|x - x_0\|^2 \le \|x - y_0\|^2$ always cancels the quadratic term $x^\top x$, leaving a linear inequality.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Square both sides.</strong> Since both sides are non-negative, squaring preserves the inequality:
              $$
              \|x - x_0\|_2^2 \le \|x - y_0\|_2^2
              $$
            </div>

            <div class="proof-step">
              <strong>Step 2: Expand.</strong>
              $$
              (x - x_0)^\top (x - x_0) \le (x - y_0)^\top (x - y_0)
              $$
              $$
              x^\top x - 2x_0^\top x + x_0^\top x_0 \le x^\top x - 2y_0^\top x + y_0^\top y_0
              $$
            </div>

            <div class="proof-step">
              <strong>Step 3: Simplify.</strong> The $x^\top x$ terms cancel:
              $$
              -2x_0^\top x + \|x_0\|_2^2 \le -2y_0^\top x + \|y_0\|_2^2
              $$
              $$
              2(y_0 - x_0)^\top x \le \|y_0\|_2^2 - \|x_0\|_2^2
              $$
            </div>

            <div class="proof-step">
              <strong>Step 4: Recognize as halfspace.</strong> This is a linear inequality $a^\top x \le b$ where $a = 2(y_0 - x_0)$ and $b = \|y_0\|_2^2 - \|x_0\|_2^2$. A halfspace is convex, therefore $C$ is convex.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.2 â€” Dual of a Subspace</h3>
          <p>Let $V \subseteq \mathbb{R}^n$ be a linear subspace. Prove that its dual cone is the orthogonal complement:</p>
          $$
          V^* = V^\perp = \{y \in \mathbb{R}^n \mid y^\top x = 0 \ \forall x \in V\}
          $$


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Subspace Duality:</b> For a linear subspace $V$, the dual cone $V^*$ coincides with the orthogonal complement $V^\perp$. This is because a subspace contains both $x$ and $-x$, forcing the angle condition $y^\top x \ge 0$ to become the orthogonality condition $y^\top x = 0$.</li>
            <li><b>Geometric Intuition:</b> A subspace is "flat" and extends infinitely in both directions. The only vectors that can make a non-obtuse angle with <i>every</i> vector in this flat plane are those strictly perpendicular to it (the normal vectors).</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Recall definition.</strong> $V^* = \{y \mid y^\top x \ge 0 \ \forall x \in V\}$.
            </div>

            <div class="proof-step">
              <strong>Step 2: Show $V^\perp \subseteq V^*$.</strong> If $y \in V^\perp$, then $y^\top x = 0$ for all $x \in V$. Since $0 \ge 0$, we have $y \in V^*$.
            </div>

            <div class="proof-step">
              <strong>Step 3: Show $V^* \subseteq V^\perp$.</strong> Suppose $y \in V^*$, so $y^\top x \ge 0$ for all $x \in V$. Since $V$ is a subspace, if $x \in V$, then $-x \in V$ as well. Therefore:
              $$
              y^\top (-x) \ge 0 \quad \implies \quad y^\top x \le 0
              $$
              The only way for both $y^\top x \ge 0$ and $y^\top x \le 0$ to hold is if $y^\top x = 0$ for all $x \in V$. Thus $y \in V^\perp$.
            </div>

            <div class="proof-step">
              <strong>Conclusion:</strong> $V^* = V^\perp$.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.3 â€” Convexity of Quadratic Sublevel Set</h3>
          <p>Show that the set:</p>
          $$
          C = \{x \in \mathbb{R}^n \mid x^\top Q x + c^\top x + d \le 0\}
          $$
          <p>is convex when $Q \in \mathbb{S}^n_+$ (positive semidefinite).</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Sublevel Sets of Convex Functions:</b> A fundamental property of convex functions is that their sublevel sets $\{x \mid f(x) \le lpha\}$ are always convex sets (though the converse is not true).</li>
            <li><b>Hessian Condition:</b> For a quadratic $f(x) = x^\top Q x + c^\top x + d$, convexity is determined solely by $Q \succeq 0$.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Identify as sublevel set.</strong> Define $f(x) = x^\top Q x + c^\top x + d$. The Hessian is $\nabla^2 f(x) = 2Q \succeq 0$ (PSD), so $f$ is convex.
            </div>

            <div class="proof-step">
              <strong>Step 2: Setup convexity proof.</strong> Take $x, y \in C$ and $\theta \in [0,1]$. This means $f(x) \le 0$ and $f(y) \le 0$.
            </div>

            <div class="proof-step">
              <strong>Step 3: Apply convexity of $f$.</strong>
              $$
              f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta)f(y) \le \theta \cdot 0 + (1-\theta) \cdot 0 = 0
              $$
              Therefore, $\theta x + (1-\theta)y \in C$.
            </div>

            <div class="proof-step">
              <strong>Conclusion:</strong> $C$ is convex (sublevel sets of convex functions are convex).
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.4 â€” Relative Interior of the Simplex</h3>
          <p>Let $\Delta^n = \{x \in \mathbb{R}^n \mid x \ge 0, \mathbf{1}^\top x = 1\}$ be the standard simplex. Show that:</p>
          $$
          \mathrm{ri}(\Delta^n) = \{x \in \mathbb{R}^n \mid x > 0, \mathbf{1}^\top x = 1\}
          $$


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Relative Interior Definition:</b> The relative interior $\mathrm{ri}(C)$ consists of points that are in the "interior" of $C$ when viewed within its affine hull. It excludes "edges" that lie on the relative boundary.</li>
            <li><b>Simplex Geometry:</b> The standard simplex $\Delta^n$ lives in the affine hyperplane $\sum x_i = 1$. Its topological interior is empty (it has no volume in $\mathbb{R}^n$), but its relative interior is the set of strictly positive probability distributions ($x > 0$).</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Identify affine hull.</strong> $\mathrm{aff}(\Delta^n) = \{x \in \mathbb{R}^n \mid \mathbf{1}^\top x = 1\}$ (the hyperplane, without requiring $x \ge 0$).
            </div>

            <div class="proof-step">
              <strong>Step 2: Interior relative to affine hull.</strong> A point $x \in \Delta^n$ is in $\mathrm{ri}(\Delta^n)$ if there exists $\varepsilon > 0$ such that the ball $B(x, \varepsilon) \cap \mathrm{aff}(\Delta^n)$ is contained in $\Delta^n$.
            </div>

            <div class="proof-step">
              <strong>Step 3: Necessity ($\Rightarrow$).</strong> If $x_i = 0$ for some $i$, then any ball around $x$ in the hyperplane contains points with $x_i < 0$, which violates $\Delta^n \subseteq \{x \ge 0\}$. Thus, all coordinates must be strictly positive.
            </div>

            <div class="proof-step">
              <strong>Step 4: Sufficiency ($\Leftarrow$).</strong> If $x > 0$ with $\mathbf{1}^\top x = 1$, let $\varepsilon = \min_i x_i > 0$. For any $y \in B(x, \varepsilon/2) \cap \mathrm{aff}(\Delta^n)$:
              $$
              y_i \ge x_i - \|y - x\|_\infty \ge x_i - \varepsilon/2 > 0
              $$
              Thus $y \in \Delta^n$, so $x \in \mathrm{ri}(\Delta^n)$.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.5 â€” Separation by Projection</h3>
          <p>Let $C$ be a nonempty closed convex set and $y \notin C$. Prove that the vector $a = y - \Pi_C(y)$ (where $\Pi_C$ denotes projection onto $C$) defines a strictly separating hyperplane:</p>
          $$
          a^\top x \le a^\top p < a^\top y \quad \forall x \in C
          $$
          <p>where $p = \Pi_C(y)$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Constructive Separation Proof:</b> The Separating Hyperplane Theorem for a closed convex set $C$ and an external point $y$ can be proven constructively using the projection theorem. The closest point $p = \Pi_C(y)$ serves as the anchor.</li>
            <li><b>The Normal Vector:</b> The vector $a = y - p$ is normal to the separating hyperplane. The hyperplane passes through $p$ and is perpendicular to the line segment connecting $y$ and its projection, placing $C$ entirely on one side.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Projection characterization.</strong> By the projection theorem (Lecture 00), for all $x \in C$:
              $$
              (y - p)^\top (x - p) \le 0
              $$
              Expanding with $a = y - p$:
              $$
              a^\top x - a^\top p \le 0 \quad \implies \quad a^\top x \le a^\top p
              $$
            </div>

            <div class="proof-step">
              <strong>Step 2: Strict inequality at $y$.</strong> Since $p \neq y$ (because $y \notin C$), we have $a = y - p \neq 0$, so $\|a\|_2 > 0$. Then:
              $$
              a^\top y = a^\top p + a^\top (y - p) = a^\top p + \|a\|_2^2 > a^\top p
              $$
            </div>

            <div class="proof-step">
              <strong>Conclusion:</strong> Combining both inequalities: $a^\top x \le a^\top p < a^\top y$ for all $x \in C$, giving strict separation.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.6 â€” Self-Duality of Second-Order Cone</h3>
          <p>Prove that the second-order cone $\mathcal{Q} = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\|_2 \le t\}$ is self-dual: $\mathcal{Q}^* = \mathcal{Q}$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Self-Duality of the Lorentz Cone:</b> The Second-Order Cone (or Ice-Cream Cone) $\mathcal{Q}$ is self-dual, meaning $\mathcal{Q}^* = \mathcal{Q}$. This property is shared by the non-negative orthant and the PSD cone, making it a symmetric cone.</li>
            <li><b>Proof Logic:</b> The proof relies on the Cauchy-Schwarz inequality $u^\top v \ge -\|u\|\|v\|$ to show $\mathcal{Q} \subseteq \mathcal{Q}^*$, and a specific counter-example construction to show the reverse inclusion.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>
            <p>We prove both inclusions.</p>

            <div class="proof-step">
              <strong>($\subseteq$): $\mathcal{Q} \subseteq \mathcal{Q}^*$.</strong> Let $(y, s) \in \mathcal{Q}$, so $\|y\|_2 \le s$. For any $(x, t) \in \mathcal{Q}$ (so $\|x\|_2 \le t$):
              $$
              y^\top x + st \ge -|y^\top x| + st \ge -\|y\|_2 \|x\|_2 + st \ge -st + st = 0
              $$
              (using Cauchy-Schwarz and the cone constraints). Thus $(y, s) \in \mathcal{Q}^*$.
            </div>

            <div class="proof-step">
              <strong>($\supseteq$): $\mathcal{Q}^* \subseteq \mathcal{Q}$.</strong> Let $(y, s) \in \mathcal{Q}^*$. We must show $\|y\|_2 \le s$.
              Assume for contradiction that $\|y\|_2 > s$.
              <ul>
                <li><b>Case 1:</b> If $s < 0$, take $(x, t) = (0, 1) \in \mathcal{Q}$. Then $y^\top x + st = s < 0$, contradicting $(y, s) \in \mathcal{Q}^*$.</li>
                <li><b>Case 2:</b> If $s \ge 0$ but $\|y\|_2 > s$, take $(x, t) = (-y/\|y\|_2, 1) \in \mathcal{Q}$ (since $\|x\|_2 = 1 = t$). Then:
                  $$
                  y^\top x + st = y^\top(-y/\|y\|_2) + s = -\|y\|_2 + s < 0
                  $$
                  contradicting $(y, s) \in \mathcal{Q}^*$.
                </li>
              </ul>
              Therefore, $\|y\|_2 \le s$, so $(y, s) \in \mathcal{Q}$.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.7 â€” Dual Cone Identities</h3>
          <p>For closed convex cones $K_1, K_2 \subseteq \mathbb{R}^n$, prove:</p>
          $$
          (K_1 + K_2)^* = K_1^* \cap K_2^*
          $$


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Duality of Operations:</b> There is a deep duality between addition and intersection for convex cones: $(K_1 + K_2)^* = K_1^* \cap K_2^*$. Taking the dual swaps "sum" with "intersection".</li>
            <li><b>Constraint Logic:</b> A vector is in the dual of the sum if it has a non-negative dot product with <i>all</i> sums. This is a stricter requirement than being in the dual of just one, hence the intersection.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>($\supseteq$):</strong> Let $y \in K_1^* \cap K_2^*$. For any $x \in K_1 + K_2$, we can write $x = x_1 + x_2$ where $x_1 \in K_1, x_2 \in K_2$. Then:
              $$
              y^\top x = y^\top(x_1 + x_2) = y^\top x_1 + y^\top x_2 \ge 0 + 0 = 0
              $$
              (since $y \in K_1^*$ and $y \in K_2^*$). Thus $y \in (K_1 + K_2)^*$.
            </div>

            <div class="proof-step">
              <strong>($\subseteq$):</strong> Let $y \in (K_1 + K_2)^*$. Then $y^\top(x_1 + x_2) \ge 0$ for all $x_1 \in K_1, x_2 \in K_2$. Taking $x_2 = 0$:
              $$
              y^\top x_1 \ge 0 \quad \forall x_1 \in K_1 \quad \implies \quad y \in K_1^*
              $$
              Similarly, taking $x_1 = 0$ gives $y \in K_2^*$. Thus $y \in K_1^* \cap K_2^*$.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.8 â€” Generalized Inequality Properties</h3>
          <p>Let $K$ be a proper cone defining a generalized inequality $\preceq_K$. Prove that $\preceq_K$ is:</p>
          <ol type="a">
            <li>Reflexive: $x \preceq_K x$</li>
            <li>Antisymmetric: $x \preceq_K y$ and $y \preceq_K x \implies x = y$</li>
            <li>Transitive: $x \preceq_K y \preceq_K z \implies x \preceq_K z$</li>
          </ol>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Cone-Induced Partial Orders:</b> Any proper cone $K$ defines a generalized inequality $\preceq_K$ that behaves like the standard scalar inequality.</li>
            <li><b>Role of Pointedness:</b> The "pointed" property (cone contains no lines) is strictly required for the antisymmetry property ($x \preceq y \land y \preceq x \implies x=y$). Without it, we would only have a preorder, not a partial order.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>(a) Reflexive:</strong> $x \preceq_K x$ means $x - x = 0 \in K$. Since every cone contains the origin, this is true.
            </div>

            <div class="proof-step">
              <strong>(b) Antisymmetric:</strong> If $x \preceq_K y$ and $y \preceq_K x$, then $y - x \in K$ and $x - y \in K$. Thus $(y - x) \in K \cap (-K)$. By pointedness (property of proper cones), $K \cap (-K) = \{0\}$, so $y - x = 0$, i.e., $x = y$.
            </div>

            <div class="proof-step">
              <strong>(c) Transitive:</strong> If $x \preceq_K y$ and $y \preceq_K z$, then $y - x \in K$ and $z - y \in K$. Since $K$ is a convex cone (closed under addition):
              $$
              (z - y) + (y - x) = z - x \in K
              $$
              Thus $x \preceq_K z$.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.9 â€” Voronoi Regions</h3>
          <p>Let $x_1, \ldots, x_k \in \mathbb{R}^n$ be a set of points. The Voronoi region associated with $x_i$ is defined as the set of points in $\mathbb{R}^n$ that are closer to $x_i$ than to any other point $x_j$:
          $$ V_i = \{x \in \mathbb{R}^n \mid \|x - x_i\|_2 \le \|x - x_j\|_2 \ \forall j \neq i\} $$
          Prove that $V_i$ is a polyhedron (and thus a convex set).</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Voronoi Regions as Polyhedra:</b> The region of space closest to a seed point $x_i$ is defined by the intersection of halfspaces. Each halfspace is bounded by the perpendicular bisector between $x_i$ and a neighbor $x_j$.</li>
            <li><b>Convexity via Intersection:</b> Since halfspaces are convex sets, and the intersection of any collection of convex sets is convex, the resulting Voronoi region (a polyhedron) is necessarily convex.</li>
        </ul>
      </div>

<div class="solution">
            <h4>Solution</h4>

            <div class="proof-step">
              <strong>Step 1: Analyze pairwise condition.</strong> The condition $\|x - x_i\|_2 \le \|x - x_j\|_2$ is equivalent to $\|x - x_i\|_2^2 \le \|x - x_j\|_2^2$ because both sides are nonnegative.
              Expanding the squared norms:
              $$ \|x - x_i\|_2^2 = (x - x_i)^\top (x - x_i) = x^\top x - 2x_i^\top x + x_i^\top x_i $$
              $$ \|x - x_j\|_2^2 = (x - x_j)^\top (x - x_j) = x^\top x - 2x_j^\top x + x_j^\top x_j $$
              Substituting these into the inequality:
              $$ x^\top x - 2x_i^\top x + x_i^\top x_i \le x^\top x - 2x_j^\top x + x_j^\top x_j $$
            </div>

            <div class="proof-step">
              <strong>Step 2: Simplify to linear inequality.</strong> The quadratic terms $x^\top x$ cancel out from both sides:
              $$ -2x_i^\top x + \|x_i\|_2^2 \le -2x_j^\top x + \|x_j\|_2^2 $$
              Rearranging terms to put $x$ on the left side:
              $$ 2x_j^\top x - 2x_i^\top x \le \|x_j\|_2^2 - \|x_i\|_2^2 $$
              $$ 2(x_j - x_i)^\top x \le \|x_j\|_2^2 - \|x_i\|_2^2 $$
              This is a linear inequality of the form $a_{ij}^\top x \le b_{ij}$ where $a_{ij} = 2(x_j - x_i)$ and $b_{ij} = \|x_j\|_2^2 - \|x_i\|_2^2$. Geometrically, this defines a halfspace bounded by the perpendicular bisector of the segment connecting $x_i$ and $x_j$.
            </div>

            <div class="proof-step">
              <strong>Step 3: Intersection of halfspaces.</strong> The Voronoi region $V_i$ is the set of points that satisfy this linear inequality for all $j \neq i$:
              $$ V_i = \bigcap_{j \neq i} \{x \mid 2(x_j - x_i)^\top x \le \|x_j\|_2^2 - \|x_i\|_2^2\} $$
              Since each set in the intersection is a halfspace, $V_i$ is an intersection of $k-1$ halfspaces.
            </div>

            <div class="proof-step">
              <strong>Conclusion:</strong> By definition, the intersection of finitely many halfspaces is a polyhedron. Since every polyhedron is a convex set, the Voronoi region $V_i$ is a convex set.
            </div>
          </div>
        </div>

        <div class="problem">
          <h3>P2.10 â€” Convexity of Norm Cone</h3>
          <p>Let $S = \{(x,t) \in \mathbb{R}^n \times \mathbb{R} \mid \|x\| \le t\}$. Show that $S$ is convex.</p>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Epigraphs of Convex Functions:</b> The set $S$ is the epigraph of the norm function $f(x) = \|x\|$. Since the epigraph of a function is a convex set if and only if the function is convex, the convexity of $S$ follows directly from the convexity of norms.</li>
                <li><b>Triangle Inequality as Convexity:</b> The core reason norms are convex is the triangle inequality $\|x+y\| \le \|x\| + \|y\|$, which geometrically ensures that the "bowl" of the norm function never dips downwards.</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>
            <p><b>Method 1: Direct Proof via Triangle Inequality</b></p>
            <div class="proof-step">
              <strong>Step 1: Unpack membership.</strong> Let $(x_1, t_1) \in S$ and $(x_2, t_2) \in S$. This means $\|x_1\| \le t_1$ and $\|x_2\| \le t_2$. Note that $t_1, t_2 \ge 0$.
            </div>
            <div class="proof-step">
              <strong>Step 2: Convex combination.</strong> Let $\lambda \in [0,1]$. We examine the point $(\lambda x_1 + (1-\lambda)x_2, \lambda t_1 + (1-\lambda)t_2)$.
            </div>
            <div class="proof-step">
              <strong>Step 3: Apply inequalities.</strong>
              $$ \|\lambda x_1 + (1-\lambda)x_2\| \le \lambda \|x_1\| + (1-\lambda) \|x_2\| $$
              (by triangle inequality and homogeneity).
              $$ \le \lambda t_1 + (1-\lambda) t_2 $$
              (by membership in $S$).
            </div>
            <div class="proof-step">
              <strong>Conclusion:</strong> The convex combination satisfies the condition $\|x\| \le t$, so $S$ is convex.
            </div>

            <p><b>Method 2: Epigraph of Convex Function (Geometric View)</b></p>
            <div class="proof-step">
              Define the function $f(x) = \|x\|$. Since every norm satisfies the triangle inequality ($f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda)f(y)$), it is a convex function.
              The set $S$ is exactly the <b>epigraph</b> of this function:
              $$ S = \mathrm{epi}(f) := \{(x,t) \in \mathbb{R}^n \times \mathbb{R} \mid t \ge f(x)\} $$
              A fundamental property in convex analysis is that a function is convex if and only if its epigraph is a convex set. Thus, convexity of the norm implies convexity of $S$.
              <br><i>Intuition:</i> Think of this as the "ice cream cone" shape in $\mathbb{R}^3$ (for $x \in \mathbb{R}^2$), which is the region "above" the graph of the cone function.
            </div>
          </div>
        </div>
        <div class="problem">
          <h3>P2.11 â€” Convex Hull of Finite Points</h3>
          <p>Given points $x_1, \dots, x_k \in \mathbb{R}^n$, show that the set of all convex combinations:
          $$ C = \left\{ \sum_{i=1}^k \theta_i x_i \ \middle|\ \theta_i \ge 0, \sum \theta_i = 1 \right\} $$
          is convex.</p>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Convex Hull as Intersection:</b> The convex hull can be rigorously defined as the intersection of <i>all</i> convex sets containing the points. Since intersections preserve convexity, the hull is automatically convex.</li>
                <li><b>Constructive View:</b> Alternatively, the set of all convex combinations is convex because a "convex combination of convex combinations" can be flattened into a single convex combination of the original points.</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>
            <div class="proof-step">
              <strong>Step 1: Pick two points.</strong> Let $u, v \in C$.
              $$ u = \sum \alpha_i x_i, \quad v = \sum \beta_i x_i $$
              where $\sum \alpha_i = 1, \alpha \ge 0$ and $\sum \beta_i = 1, \beta \ge 0$.
            </div>
            <div class="proof-step">
              <strong>Step 2: Combine them.</strong> Let $\lambda \in [0,1]$.
              $$ \lambda u + (1-\lambda)v = \lambda \sum \alpha_i x_i + (1-\lambda) \sum \beta_i x_i = \sum (\lambda \alpha_i + (1-\lambda)\beta_i) x_i $$
            </div>
            <div class="proof-step">
              <strong>Step 3: Verify weights.</strong> Let $\gamma_i = \lambda \alpha_i + (1-\lambda)\beta_i$.
              <ul>
                <li>Non-negativity: Since $\lambda, \alpha, \beta \ge 0$, $\gamma_i \ge 0$.</li>
                <li>Sum to 1: $\sum \gamma_i = \lambda \sum \alpha_i + (1-\lambda) \sum \beta_i = \lambda(1) + (1-\lambda)(1) = 1$.</li>
              </ul>
            </div>
            <div class="proof-step">
              <strong>Conclusion:</strong> The combined point is a valid convex combination of $\{x_i\}$, so it lies in $C$.
            </div>

            <div class="proof-step">
              <strong>Alternative Proof: Intersection of Convex Sets.</strong>
              Define $\mathrm{conv}(S) = \bigcap \{D \mid S \subseteq D, D \text{ is convex}\}$.
              The intersection of any collection of convex sets is convex (see Section 3.1).
              Thus, this intersection is convex by construction.
              (One can show this definition is equivalent to the set of convex combinations, but this perspective makes convexity immediate.)
            </div>
          </div>
        </div>
        <div class="problem">
          <h3>P2.12 â€” Minkowski Sum of Sets</h3>
          <p>The Minkowski sum is $X + Y = \{x+y \mid x \in X, y \in Y\}$.</p>
          <ol type="a">
            <li>Show that if $X, Y$ are convex, $X+Y$ is convex.</li>
            <li>Give an example where $X$ is not convex but $X+Y$ is convex.</li>
          </ol>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Linear Maps:</b> $X+Y$ is the image of $X \times Y$ under the linear map $f(x,y)=x+y$. Linear maps preserve convexity.</li>
                <li><b>convex + non-convex = convex?:</b> Surprisingly, adding a "large enough" convex set to a non-convex set can result in a convex set (e.g., $\mathbb{Z} + [0,1] = \mathbb{R}$). The sum operation "fills in the gaps".</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>

            <p><b>(a) Convexity Proof</b></p>
            <div class="proof-step">
              Let $u, v \in X+Y$. Then $u = x_1+y_1$ and $v = x_2+y_2$ with $x_i \in X, y_i \in Y$.
              For $\lambda \in [0,1]$:
              $$ \lambda u + (1-\lambda)v = \lambda(x_1+y_1) + (1-\lambda)(x_2+y_2) = (\lambda x_1 + (1-\lambda)x_2) + (\lambda y_1 + (1-\lambda)y_2) $$
              By convexity of $X$ and $Y$, the terms in parentheses are in $X$ and $Y$ respectively. Thus the sum is in $X+Y$.
            </div>

            <div class="proof-step">
              <strong>Alternative Proof: Image under Linear Map.</strong>
              Consider the Cartesian product $X \times Y \subseteq \mathbb{R}^{2n}$, which is convex (Problem 2.15).
              Define the linear map $f: \mathbb{R}^{2n} \to \mathbb{R}^n$ by $f(x,y) = x+y$.
              The Minkowski sum is exactly the image of the product set under this map: $X+Y = f(X \times Y)$.
              Since linear maps preserve convexity, $X+Y$ is convex.
            </div>

            <p><b>(b) Counter-intuitive Example</b></p>
            <div class="proof-step">
              Let $X = \mathbb{Z}$ (integers, clearly not convex) and $Y = [0, 1]$.
              $$ X + Y = \{k + t \mid k \in \mathbb{Z}, t \in [0,1]\} = \bigcup_{k \in \mathbb{Z}} [k, k+1] = \mathbb{R} $$
              Since $\mathbb{R}$ is convex, $X+Y$ is convex even though $X$ is not.
            </div>
          </div>
        </div>
        <div class="problem">
          <h3>P2.13 â€” Convexity of Thickened Sets</h3>
          <p>Let $C \subseteq \mathbb{R}^n$ be a closed convex set. Define the thickened set $C_\varepsilon = \{y \mid \mathrm{dist}(y, C) \le \varepsilon\}$. Show that $C_\varepsilon$ is convex.</p>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Minkowski Sum Interpretation:</b> The thickened set $C_arepsilon$ is exactly the Minkowski sum of the original set $C$ and the ball of radius $arepsilon$, i.e., $C_arepsilon = C + B(0, arepsilon)$.</li>
                <li><b>Convexity Preservation:</b> Since $C$ is convex and the ball $B(0, \varepsilon)$ is convex, their Minkowski sum must be convex. This provides a clean, geometric proof without needing to analyze the distance function directly.</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>
            <p><b>Method 1: Minkowski Sum</b></p>
            <div class="proof-step">
              <strong>Step 1: Show Equality.</strong> Let $\overline{B}_\varepsilon(0) = \{z \mid \|z\| \le \varepsilon\}$. We claim $C_\varepsilon = C + \overline{B}_\varepsilon(0)$.
              <ul>
                <li><b>($\subseteq$):</b> Take $y \in C_\varepsilon$. By definition, $d(y, C) = \inf_{x \in C} \|y-x\| \le \varepsilon$. Since $C$ is closed and the norm is continuous, the infimum is attained by a projection $x^\star \in C$. Thus $\|y - x^\star\| \le \varepsilon$. Let $z = y - x^\star$. Then $z \in \overline{B}_\varepsilon(0)$ and $y = x^\star + z \in C + \overline{B}_\varepsilon(0)$.</li>
                <li><b>($\supseteq$):</b> Take $y \in C + \overline{B}_\varepsilon(0)$. Then $y = x + z$ for some $x \in C$ and $\|z\| \le \varepsilon$. The distance to $C$ satisfies $d(y, C) \le \|y - x\| = \|z\| \le \varepsilon$. Thus $y \in C_\varepsilon$.</li>
              </ul>
            </div>
            <div class="proof-step">
              <strong>Step 2: Use Convexity.</strong>
              We know that $C$ is convex (by assumption) and the ball $\overline{B}_\varepsilon(0)$ is convex (norm ball).
              By Problem 2.12, the Minkowski sum of two convex sets is convex.
              Thus $C_\varepsilon = C + \overline{B}_\varepsilon(0)$ is convex.
            </div>

            <div class="proof-step">
              <strong>Method 2: Convexity of Distance Function.</strong>
              Let $f(y) = \mathrm{dist}(y, C)$.
              $$ f(\lambda y_1 + (1-\lambda)y_2) = \inf_{x \in C} \|\lambda y_1 + (1-\lambda)y_2 - x\| $$
              Let $x = \lambda x_1 + (1-\lambda)x_2$ for any $x_1, x_2 \in C$.
              $$ \le \|\lambda(y_1-x_1) + (1-\lambda)(y_2-x_2)\| \le \lambda \|y_1-x_1\| + (1-\lambda)\|y_2-x_2\| $$
              Taking infimum over $x_1, x_2$ yields $f(\lambda y_1 + (1-\lambda)y_2) \le \lambda f(y_1) + (1-\lambda)f(y_2)$.
              Thus $f$ is convex, and its sublevel set $C_\varepsilon$ is convex.
            </div>
          </div>
        </div>
        <div class="problem">
          <h3>P2.14 â€” Closure of a Convex Set</h3>
          <p>Show that if $C$ is convex, its closure $\mathrm{cl}(C)$ is convex.</p>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Sequences:</b> Limit points preserve non-strict inequalities like $\theta x + (1-\theta)y \in \dots$</li>
                <li><b>Intuition:</b> You cannot "bend" the boundary of a convex shape inwards (making it non-convex) without affecting the interior points. The limit points simply "seal" the convex shape.</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>
            <div class="proof-step">
              Let $a, b \in \mathrm{cl}(C)$. By definition, there exist sequences $\{x_k\} \subset C$ such that $x_k \to a$ and $\{y_k\} \subset C$ such that $y_k \to b$.
            </div>
            <div class="proof-step">
              Let $\lambda \in [0,1]$. Since $C$ is convex:
              $$ z_k := \lambda x_k + (1-\lambda)y_k \in C \quad \forall k $$
            </div>
            <div class="proof-step">
              By continuity of vector addition and scalar multiplication:
              $$ \lim_{k \to \infty} z_k = \lambda a + (1-\lambda)b $$
            </div>
            <div class="proof-step">
              Thus, $\lambda a + (1-\lambda)b$ is the limit of a sequence in $C$, so it belongs to $\mathrm{cl}(C)$.
            </div>

            <div class="proof-step">
              <strong>Alternative Proof: Open Balls.</strong>
              Let $a, b \in \mathrm{cl}(C)$ and $\lambda \in [0,1]$. Define $c = \lambda a + (1-\lambda)b$.
              To prove $c \in \mathrm{cl}(C)$, we must show that every open ball around $c$ intersects $C$.
              Let $B(c, r)$ be an arbitrary ball of radius $r > 0$.
              Since $a, b \in \mathrm{cl}(C)$, any neighborhood of them hits $C$. Specifically:
              <ul>
                <li>There exists $x \in C \cap B(a, r)$. (So $\|x - a\| < r$)</li>
                <li>There exists $y \in C \cap B(b, r)$. (So $\|y - b\| < r$)</li>
              </ul>
              By convexity of $C$, the point $z := \lambda x + (1-\lambda)y$ is in $C$.
              Now check the distance from $z$ to $c$:
              $$ \|z - c\| = \|\lambda(x-a) + (1-\lambda)(y-b)\| \le \lambda\|x-a\| + (1-\lambda)\|y-b\| < \lambda r + (1-\lambda)r = r $$
              Thus $\|z - c\| < r$, meaning $z \in B(c, r)$.
              We found a point $z \in C \cap B(c, r)$, so every ball around $c$ intersects $C$. Thus $c \in \mathrm{cl}(C)$.
            </div>
          </div>
        </div>
        <div class="problem">
          <h3>P2.15 â€” Product of Convex Sets</h3>
          <p>Let $X \subseteq \mathbb{R}^n, Y \subseteq \mathbb{R}^m$.</p>
          <ol type="a">
            <li>Show that if $X, Y$ are convex, then $X \times Y$ is convex in $\mathbb{R}^{n+m}$.</li>
            <li>If $X$ is not convex (and $Y$ nonempty), can $X \times Y$ be convex?</li>
          </ol>

          <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
            <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
            <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
                <li><b>Convexity of Products:</b> The Cartesian product $X \times Y$ essentially stacks the convexity conditions. A line segment in the product space projects to line segments in $X$ and $Y$. If the components are convex, the product is convex.</li>
                <li><b>Necessity of Factors:</b> Unlike the Minkowski sum, for a Cartesian product to be convex, <i>both</i> factors must be convex (assuming they are non-empty). A hole in either factor creates a hole in the product "cylinder".</li>
            </ul>
          </div>

          <div class="solution-box">
            <h4>Solution</h4>
            <p><b>(a) Convexity of Product</b></p>
            <div class="proof-step">
              Let $u_1 = (x_1, y_1), u_2 = (x_2, y_2) \in X \times Y$.
              $$ \lambda u_1 + (1-\lambda)u_2 = (\lambda x_1 + (1-\lambda)x_2, \lambda y_1 + (1-\lambda)y_2) $$
              Since $X$ is convex, the first component is in $X$. Since $Y$ is convex, the second is in $Y$. Thus the pair is in $X \times Y$.
            </div>

            <div class="proof-step">
              <strong>Alternative Proof: Preimage of Linear Maps.</strong>
              Let $P_X(x,y) = x$ and $P_Y(x,y) = y$ be the projection maps (linear).
              Then $X \times Y = P_X^{-1}(X) \cap P_Y^{-1}(Y)$.
              Since $X$ and $Y$ are convex, their preimages under linear maps are convex.
              The intersection of these two convex preimages is convex.
            </div>

            <p><b>(b) Non-convex Factor</b></p>
            <div class="proof-step">
              <b>No.</b> Unlike the Minkowski sum (where sum of non-convex sets can be convex), the Cartesian product <i>requires</i> both factors to be convex.
              <br><i>Proof:</i> Assume $X \times Y$ is convex and $Y$ is nonempty (contains $y_0$). We show $X$ must be convex.
              Take any $x_1, x_2 \in X$. Then $(x_1, y_0), (x_2, y_0) \in X \times Y$.
              By convexity of the product, for any $\lambda \in [0,1]$:
              $$ \lambda(x_1, y_0) + (1-\lambda)(x_2, y_0) = (\lambda x_1 + (1-\lambda)x_2, y_0) \in X \times Y $$
              This implies the first component $\lambda x_1 + (1-\lambda)x_2$ is in $X$. Thus $X$ is convex.
              (Similarly for $Y$).
            </div>
          </div>
        </div>
</section>

      <!-- SECTION 8: SUMMARY -->
      <section class="section-card" id="summary">
        <h2>8. Summary</h2>
        <p><strong>Overview:</strong> This lecture presents the geometric foundations of convex optimization through the study of convex sets. We define convexity for sets, examine canonical examples such as hyperplanes, polyhedra, and cones, and establish operations that preserve convexity. The lecture concludes with the Separating and Supporting Hyperplane Theorems, which form the geometric basis for duality theory and optimality conditions.</p>
      </section>

      <!-- SECTION 9: GLOSSARY -->
      <section class="section-card" id="section-9">
        <h2>9. Quick Reference Glossary</h2>

        <p>Essential terms from this lecture for quick lookup:</p>

        <ul style="column-count: 2; column-gap: 2rem;">
          <li><b>Affine combination:</b> $\sum_i \theta_i x_i$ with $\sum_i \theta_i = 1$</li>
          <li><b>Affine set:</b> Contains all affine combinations of its points</li>
          <li><b>Boundary ($\partial C$):</b> $\mathrm{cl}(C) \setminus \mathrm{int}(C)$</li>
          <li><b>Closure ($\mathrm{cl}(C)$):</b> All limit points of sequences in $C$</li>
          <li><b>Cone:</b> $x \in K, \theta \ge 0 \implies \theta x \in K$</li>
          <li><b>Conic combination:</b> $\sum_i \theta_i x_i$ with $\theta_i \ge 0$</li>
          <li><b>Convex combination:</b> $\sum_i \theta_i x_i$ with $\theta_i \ge 0, \sum_i \theta_i = 1$</li>
          <li><b>Convex cone:</b> Cone that is also convex</li>
          <li><b>Convex hull ($\mathrm{conv}(S)$):</b> All convex combinations of points in $S$</li>
          <li><b>Convex set:</b> Contains all line segments between its points</li>
          <li><b>Dual cone ($K^*$):</b> $\{y \mid y^\top x \ge 0 \ \forall x \in K\}$</li>
          <li><b>Ellipsoid:</b> $\{x \mid (x-x_c)^\top P^{-1}(x-x_c) \le 1\}$</li>
          <li><b>Generalized inequality:</b> $x \preceq_K y$ iff $y - x \in K$</li>
          <li><b>Halfspace:</b> $\{x \mid a^\top x \le b\}$</li>
          <li><b>Hyperplane:</b> $\{x \mid a^\top x = b\}$</li>
          <li><b>Interior ($\mathrm{int}(C)$):</b> Points with open ball fully in $C$</li>
          <li><b>Norm ball:</b> $\{x \mid \|x - x_c\| \le r\}$</li>
          <li><b>Polyhedron:</b> $\{x \mid Ax \le b, Cx = d\}$</li>
          <li><b>Polytope:</b> Bounded polyhedron</li>
          <li><b>Proper cone:</b> Convex, closed, pointed, solid</li>
          <li><b>PSD cone ($\mathbb{S}^n_+$):</b> $\{X \succeq 0\}$</li>
          <li><b>Relative interior ($\mathrm{ri}(C)$):</b> Interior relative to $\mathrm{aff}(C)$</li>
          <li><b>Second-order cone ($\mathcal{Q}$):</b> $\{(x,t) \mid \|x\|_2 \le t\}$</li>
          <li><b>Separating hyperplane:</b> Divides two disjoint convex sets</li>
          <li><b>Simplex ($\Delta^n$):</b> $\{x \ge 0 \mid \mathbf{1}^\top x = 1\}$</li>
          <li><b>Supporting hyperplane:</b> Touches boundary, set on one side</li>
        </ul>
      </section>

    </article>

    <footer class="site-footer">
      <div class="container">
        <p>Â© <span id="year"></a> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- Widget Loaders -->
  <script type="module">
    import { initEllipsoidExplorer } from './widgets/js/ellipsoid-explorer.js';
    initEllipsoidExplorer('widget-ellipsoid-explorer');
  </script>
  <script type="module">
    import { initPolyhedronVisualizer } from './widgets/js/polyhedron-visualizer.js';
    initPolyhedronVisualizer('widget-polyhedron-visualizer');
  </script>
  <script type="module">
    import { initConvexGeometryLab } from './widgets/js/convex-geometry-lab.js';
    initConvexGeometryLab('widget-convex-geometry-lab');
  </script>
  <script type="module">
    import { initSeparatingHyperplane } from './widgets/js/separating-hyperplane.js';
    initSeparatingHyperplane('widget-separating-hyperplane');
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
