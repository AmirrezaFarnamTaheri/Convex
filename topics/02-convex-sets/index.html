<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>02. Convex Sets â€” Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../01-introduction/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../03-convex-functions/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>02. The Geometry of Feasibility: Convex Sets</h1>
      <div class="lecture-meta">
        <span>Date: 2025-10-28</a>
        <span>Duration: 90 min</a>
        <span>Tags: sets, geometry, foundational, theory</a>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the geometric foundations of convex optimization through the study of convex sets. We define convexity for sets, examine canonical examples such as hyperplanes, polyhedra, and cones, and establish operations that preserve convexity. The lecture concludes with the Separating and Supporting Hyperplane Theorems, which form the geometric basis for duality theory and optimality conditions.</p>
        <p><strong>Prerequisites:</strong> Linear algebra (<a href="../00-linear-algebra-primer/index.html">Lecture 00</a>)â€”particularly projections, subspaces, and inner productsâ€”and the definition of a convex problem (<a href="../01-introduction/index.html">Lecture 01</a>).</p>
        <p><strong>Forward Connections:</strong> Feasible sets from LP and QP formulations are shown to be convex. The hyperplane separation theorems provide the geometric foundation for Lagrangian duality (Lecture 05) and KKT conditions. Cone duality underpins conic programming (SOCP, SDP).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <ul>
        <li><b>Define and Interpret Convexity:</b> Provide formal definitions of affine sets, convex sets, convex combinations, and convex hulls with geometric intuition.</li>
        <li><b>Identify Key Convex Sets:</b> Recognize and work with hyperplanes, halfspaces, norm balls, ellipsoids, polyhedra, second-order cones, and the PSD cone.</li>
        <li><b>Understand Convexity-Preserving Operations:</b> Use intersection, affine mappings, and perspective operations to construct complex convex sets from simple building blocks.</li>
        <li><b>Prove and Apply Hyperplane Theorems:</b> State and prove the Separating and Supporting Hyperplane Theorems, understanding their role in duality and optimality.</li>
        <li><b>Work with Cones and Duality:</b> Define cones, proper cones, and dual cones. Prove self-duality of key cones and apply generalized inequalities.</li>
        <li><b>Use Topological Concepts:</b> Apply closure, interior, boundary, and relative interior to analyze constraint qualifications and algorithm convergence.</li>
      </ul>
    </section>



    <article>
      <section class="section-card" id="section-1">
        <h2>1. Affine and Convex Sets: Definitions and Basic Properties</h2>

        <p>The geometry of optimization is built on understanding how points combine. Two fundamental operations define the landscape:</p>

        <h3>1.1 Affine Combinations and Affine Sets</h3>

        <p>An <a href="#" class="definition-link">affine combination</a> is a linear combination of points where the coefficients sum to exactly one. Geometrically, this operation generates lines, planes, and hyperplanes passing through the given points, without reference to the origin.</p>
        $$
        \sum_{i=1}^k \theta_i x_i \quad \text{where} \quad \sum_{i=1}^k \theta_i = 1
        $$
        <p>The coefficients $\theta_i$ may be negative, allowing the combination to extend beyond the region spanned by the points (e.g., the infinite line passing through two points, not just the segment between them).</p>

        <div class="theorem-box">
          <h4>Definition (Affine Set)</h4>
          <p>A set $C$ is <a href="#" class="definition-link">affine</a> if it contains all affine combinations of its points. Equivalently, the <b>infinite line</b> passing through any two points in $C$ lies entirely in $C$.</p>
          $$ x_1, x_2 \in C, \ \theta \in \mathbb{R} \implies \theta x_1 + (1-\theta)x_2 \in C $$
        </div>

        <h4>Affine Sets as Translated Subspaces</h4>
        <p>Geometrically, every affine set is just a linear subspace that has been shifted (translated) away from the origin.</p>

        <div class="theorem-box">
          <h4>Theorem: Affine Set $\iff$ Translated Subspace</h4>
          <p>A set $C \subseteq \mathbb{R}^n$ is affine if and only if it can be written as:</p>
          $$
          C = x_0 + V = \{x_0 + v \mid v \in V\}
          $$
          <p>where $x_0$ is any specific point in $C$, and $V$ is a linear subspace of $\mathbb{R}^n$.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <div class="proof-step">
              <strong>($\Leftarrow$):</strong> Suppose $C = x_0 + V$. Let $x_1, x_2 \in C$. Then $x_1 = x_0 + v_1$ and $x_2 = x_0 + v_2$ for some $v_1, v_2 \in V$.
              For any $\theta \in \mathbb{R}$:
              $$
              \theta x_1 + (1-\theta)x_2 = \theta(x_0 + v_1) + (1-\theta)(x_0 + v_2)
              = x_0 + [\theta v_1 + (1-\theta)v_2]
              $$
              Since $V$ is a subspace, it is closed under linear combinations, so the bracketed term is in $V$. Thus the combination is in $x_0 + V = C$.
            </div>
            <div class="proof-step">
              <strong>($\Rightarrow$):</strong> Suppose $C$ is affine. Pick any $x_0 \in C$ and define $V = C - x_0 = \{x - x_0 \mid x \in C\}$. We show $V$ is a subspace.
              <ul>
                <li>$0 \in V$ since $x_0 \in C$.</li>
                <li>Let $v_1, v_2 \in V$ and $\alpha, \beta \in \mathbb{R}$. We want $\alpha v_1 + \beta v_2 \in V$. This follows from the affine property of $C$ (specifically, closure under affine sums leads to closure of difference vectors under linear combinations).</li>
              </ul>
              Thus $C = x_0 + V$.
            </div>
          </div>
        </div>

        <figure style="text-align: center;">
          <img src="assets/affine-subspace.png"
               alt="An affine set C shown as a red plane parallel to a blue subspace V passing through the origin"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.0:</i> An affine set $C$ (red) is a subspace $V$ (blue) translated by a vector $x_0$. Note that $V$ passes through the origin, while $C$ does not necessarily.</figcaption>
        </figure>

        <div class="example">
          <h4>Examples of Affine Sets</h4>
          <ul>
            <li><b>Solution set of linear equations:</b> $C = \{x \mid Ax = b\}$. If $x_0$ is a particular solution ($Ax_0 = b$), then $C = x_0 + \mathcal{N}(A)$, where the nullspace $\mathcal{N}(A)$ is the associated subspace.</li>
            <li><b>$\mathbb{R}^n$ itself:</b> The entire space is trivially affine ($V = \mathbb{R}^n, x_0 = 0$).</li>
            <li><b>Single point $\{x_0\}$:</b> Affine ($V = \{0\}$).</li>
          </ul>
        </div>

        <h3>1.2 Convex Combinations and Convex Sets</h3>

        <p>A <a href="#" class="definition-link">convex combination</a> is an affine combination with the additional constraint that all weights are nonnegative:</p>
        $$
        \sum_{i=1}^k \theta_i x_i \quad \text{where} \quad \theta_i \ge 0, \ \sum_{i=1}^k \theta_i = 1
        $$
        <p>This describes "filled-in" shapes like line segments, triangles, and convex polytopes.</p>

        <div class="theorem-box">
          <h4>Definition (Convex Set)</h4>
          <p>A set $C \subseteq \mathbb{R}^n$ is <a href="#" class="definition-link" data-term="convex function">convex</a> if for any two points $x, y \in C$ and any $\theta \in [0,1]$:</p>
          $$
          \theta x + (1-\theta)y \in C
          $$
          <p><b>Geometric meaning:</b> The line segment connecting any two points in the set lies entirely within the setâ€”no "dents" or "holes."</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-vs-nonconvex.png"
               alt="Visual definition of convex and non-convex sets"
               style="max-width: 100%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.1:</i> In a convex set (right), the line segment between any two points lies entirely within the set. In a non-convex set (left), some line segments (red) cross outside the set boundaries.</figcaption>
        </figure>

        <h3>1.3 Convex Hull</h3>

        <p>The <a href="#" class="definition-link">convex hull</a> of a set $S$ is the smallest convex set that contains $S$. Intuitively, it is the shape formed by "shrink-wrapping" the set $S$ or stretching a rubber band around it. Mathematically, it is the set of all possible convex combinations of points in $S$:</p>
        $$
        \mathrm{conv}(S) = \left\{\sum_{i=1}^k \theta_i x_i \ \bigg| \ x_i \in S, \ \theta_i \ge 0, \ \sum_{i=1}^k \theta_i = 1, \ k \in \mathbb{N}\right\}
        $$

        <div class="theorem-box">
          <h4>Theorem (CarathÃ©odory's Theorem)</h4>
          <p>If $S \subseteq \mathbb{R}^n$, then every point in $\mathrm{conv}(S)$ can be written as a convex combination of at most $n+1$ points from $S$.</p>
          <p><b>Implication:</b> To describe any point in the convex hull, we never need more than $n+1$ points, regardless of how large $S$ is!</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-hull.png"
               alt="Illustration of a convex hull"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 1.2:</i> The convex hull of a set of points (black dots) acts like a rubber band (blue polygon) snapped tight around them.</figcaption>
        </figure>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
            <figure style="text-align: center; flex: 1;">
              <img src="assets/convex-hull-nonconvex.png"
                   alt="Convex hull of a crescent shape"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 1.3:</i> The convex hull of a non-convex set (dark grey crescent) fills in the "gaps" (light blue), creating the smallest convex superset.</figcaption>
            </figure>
            <figure style="text-align: center; flex: 1;">
              <img src="assets/caratheodory.png"
                   alt="Caratheodory's theorem visualization"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 1.4:</i> CarathÃ©odory's Theorem: Any point $x$ in the hull of many points (black) can be formed by a convex combination of just $n+1$ of them (red triangle in $\mathbb{R}^2$).</figcaption>
            </figure>
        </div>

        <h3>1.4 Sets Defined by Functions</h3>

        <p>A powerful way to generate convex sets is to derive them from convex functions (<a href="../03-convex-functions/index.html">Lecture 03</a>). Two primary objects bridge the gap between sets and functions: sublevel sets and epigraphs.</p>

        <h4>(a) Sublevel Sets</h4>
        <p>The $\alpha$-<a href="#" class="definition-link">sublevel set</a> of a function $f : \mathbb{R}^n \to \mathbb{R}$ is the set of all points where the function value is below a threshold $\alpha$:</p>
        $$
        C_\alpha = \{x \in \mathrm{dom} f \mid f(x) \le \alpha\}
        $$
        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>If $f$ is a convex function, then its sublevel set $C_\alpha$ is a convex set for any $\alpha \in \mathbb{R}$.</p>
          <p><i>Proof:</i> Let $x, y \in C_\alpha$ and $\theta \in [0,1]$. Then $f(x) \le \alpha$ and $f(y) \le \alpha$. By convexity, $f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta)f(y) \le \theta \alpha + (1-\theta)\alpha = \alpha$. Thus the combination is in $C_\alpha$.</p>
          <p><i>Note:</i> The converse is false. Functions whose sublevel sets are convex but who are not themselves convex are called <b>quasiconvex</b>.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/indicator-function.png"
                  alt="3D plot of an indicator function"
                  style="max-width: 60%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 1.5:</i> The sublevel set of a convex function corresponds to a convex set. For example, the unit ball is the 1-sublevel set of the norm function $f(x) = \|x\|$.</figcaption>
        </figure>

        <h4>(b) Epigraphs</h4>
        <p>The <a href="#" class="definition-link">epigraph</a> of a function $f$ is the set of points lying on or above its graph in $\mathbb{R}^{n+1}$:</p>
        $$
        \mathrm{epi}(f) = \{(x, t) \in \mathbb{R}^{n+1} \mid x \in \mathrm{dom} f, \ f(x) \le t\}
        $$
        <p>This object is the "Rosetta Stone" connecting the algebra of functions to the geometry of sets.</p>

        <div class="theorem-box">
          <h4>Fundamental Bridge Theorem</h4>
          <p>A function $f$ is <b>convex</b> if and only if its <b>epigraph</b> $\mathrm{epi}(f)$ is a <b>convex set</b>.</p>
          <p>This equivalence allows us to translate analytic properties of functions into geometric properties of sets. For example, the fact that the pointwise maximum of convex functions is convex follows immediately from the fact that the intersection of convex sets (their epigraphs) is convex.</p>
        </div>

        <h3>1.5 Key Properties</h3>

        <ul>
          <li>Every affine set is convex (but not vice versa).</li>
          <li>The intersection of any collection of convex sets is convex (proven in Section 3).</li>
          <li>The union of convex sets is generally <b>not</b> convex.</li>
        </ul>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Tool: Convex Set Checker</h3>
          <p><b>Test Convexity Interactively:</b> Use the drawing tools below to create shapes and verify their convexity. Any "dent" will be flagged as a violation of the line segment property.</p>
          <!-- Note: The standalone drawing widget has been merged into the lab below for a unified experience. -->
        </div>
      </section>


      <section class="section-card" id="section-2">
        <h2>2. Canonical Convex Sets: Building Blocks</h2>

        <p>These fundamental convex sets appear repeatedly in optimization formulations. Recognizing them is essential for problem classification.</p>

        <h3>2.1 Hyperplanes and Halfspaces</h3>

        <p>A <a href="#" class="definition-link">hyperplane</a> is a set of the form:</p>
        $$
        H = \{x \in \mathbb{R}^n \mid a^\top x = b\}
        $$
        <p>where $a \in \mathbb{R}^n \setminus \{0\}$ and $b \in \mathbb{R}$. The vector $a$ is the <b>normal vector</b> (perpendicular to the hyperplane).</p>

        <div class="theorem-box">
          <h4>Geometric Interpretation</h4>
          <p>A hyperplane is an affine set of dimension $n-1$. It can be viewed as:</p>
          <ul>
            <li>The solution set of a single linear equation.</li>
            <li>A linear subspace ($a^\top x = 0$) translated by some vector $x_0$ (where $a^\top x_0 = b$).</li>
          </ul>
        </div>

        <p>A <a href="#" class="definition-link">halfspace</a> is a set of the form:</p>
        $$
        H^- = \{x \in \mathbb{R}^n \mid a^\top x \le b\}
        $$
        <p>This is the region on one side of the hyperplane. The complement halfspace is $H^+ = \{x \mid a^\top x \ge b\}$.</p>

        <div class="proof-box">
          <h4>Proof: Hyperplanes and Halfspaces are Convex</h4>

          <div class="proof-step">
            <strong>Hyperplane:</strong> Take $x_1, x_2 \in H$ and $\theta \in [0,1]$. Then:
            $$
            a^\top(\theta x_1 + (1-\theta)x_2) = \theta a^\top x_1 + (1-\theta)a^\top x_2 = \theta b + (1-\theta)b = b
            $$
            So the entire segment lies in $H$.
          </div>

          <div class="proof-step">
            <strong>Halfspace:</strong> Take $x_1, x_2 \in H^-$ (so $a^\top x_i \le b$) and $\theta \in [0,1]$. Then:
            $$
            a^\top(\theta x_1 + (1-\theta)x_2) = \theta a^\top x_1 + (1-\theta)a^\top x_2 \le \theta b + (1-\theta)b = b
            $$
            So the segment lies in $H^-$.
          </div>

          <div class="proof-step">
            <strong>Alternate View (Preimage):</strong> Define the linear function $f(x) = a^\top x$. Then $H^- = f^{-1}((-\infty, b])$. Since $(-\infty, b]$ is a convex interval in $\mathbb{R}$ and preimages of convex sets under affine maps are convex, $H^-$ is convex.
          </div>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/hyperplane-halfspace.png"
               alt="A 3D visualization of a hyperplane dividing space into two halfspaces"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.1:</i> A hyperplane (transparent plane) divides $\mathbb{R}^3$ into two halfspaces. The normal vector $a$ determines the orientation.</figcaption>
        </figure>

        <h3>2.2 Norm Balls and Ellipsoids</h3>

        <p>A <a href="#" class="definition-link" data-term="norm ball">norm ball</a> centered at $x_c$ with radius $r$ is:</p>
        $$
        B(x_c, r) = \{x \in \mathbb{R}^n \mid \|x - x_c\| \le r\}
        $$
        <p>where $\|\cdot\|$ is any norm. All norm balls are convex (by the triangle inequality).</p>

        <div class="theorem-box">
          <h4>Proof: Norm Balls are Convex</h4>
          <p>Let $x, y \in B(x_c, r)$ and $\theta \in [0,1]$. Then $\|x - x_c\| \le r$ and $\|y - x_c\| \le r$.</p>
          $$
          \begin{aligned}
          \|(\theta x + (1-\theta)y) - x_c\| &= \|\theta(x - x_c) + (1-\theta)(y - x_c)\| \\
          &\le \theta\|x - x_c\| + (1-\theta)\|y - x_c\| \\
          &\le \theta r + (1-\theta)r = r
          \end{aligned}
          $$
          <p>Thus the convex combination is in the ball.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="../../topics/00-linear-algebra-primer/assets/norm-balls.png"
               alt="Comparison of unit balls for L1, L2, and L-infinity norms"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.2:</i> Unit balls for different norms in $\mathbb{R}^2$: $L_1$ (diamond), $L_2$ (circle), and $L_\infty$ (square). All are convex sets.</figcaption>
        </figure>

        <p>An <a href="#" class="definition-link">ellipsoid</a> is a generalized Euclidean ball, defined as:</p>
        $$
        \mathcal{E} = \{x \in \mathbb{R}^n \mid (x - x_c)^\top P^{-1} (x - x_c) \le 1\}
        $$
        <p>where $P \in \mathbb{S}^n_{++}$ (symmetric positive definite). $P$ determines the shape and orientation.</p>

        <div class="insight">
          <h4>Geometric Interpretation via Eigendecomposition</h4>
          <p>Let $P = Q \Lambda Q^\top$ be the eigendecomposition of $P$, where $\Lambda = \text{diag}(\lambda_1, \dots, \lambda_n)$. The semi-axes of the ellipsoid are aligned with the eigenvectors $q_i$ (columns of $Q$) and have lengths $\sqrt{\lambda_i}$.</p>
          <p>Alternatively, an ellipsoid is the image of the unit Euclidean ball under an affine mapping: $\mathcal{E} = f(B(0,1))$ where $f(u) = P^{1/2}u + x_c$. Since affine maps preserve convexity, ellipsoids are convex.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/ellipsoid-axes.png"
               alt="Anatomy of an ellipsoid showing principal axes aligned with eigenvectors"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.3:</i> An ellipsoid is defined by a PSD matrix $P$. Its principal axes align with the eigenvectors of $P$, and their lengths are the square roots of the eigenvalues.</figcaption>
        </figure>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Explorer: Ellipsoid Geometry</h3>
          <p><b>See How PSD Matrices Define Ellipsoids:</b> An ellipsoid is defined by $\{x \mid (x-x_c)^\top P^{-1} (x-x_c) \le 1\}$ where $P \succ 0$. This tool lets you:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Adjust matrix P:</b> Modify the PSD matrix entries and watch the ellipsoid reshape in real-time</li>
            <li><b>Visualize eigenvectors:</b> The principal axes align with eigenvectors of $P$</li>
            <li><b>Observe eigenvalue effects:</b> Axis lengths are proportional to $\sqrt{\lambda_i}$ where $\lambda_i$ are eigenvalues</li>
          </ul>
          <div id="widget-ellipsoid-explorer" style="width: 100%; height: 400px; position: relative;"></div>
        </div>

        <h3>2.3 Polyhedra</h3>

        <p>A <a href="#" class="definition-link">polyhedron</a> is the solution set of finitely many linear inequalities and equalities:</p>
        $$
        \mathcal{P} = \{x \in \mathbb{R}^n \mid Ax \le b, \ Cx = d\}
        $$
        <p>Geometrically, a polyhedron is the intersection of a finite number of halfspaces and hyperplanes.</p>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/polyhedron-construction.png"
               alt="A polyhedron formed by the intersection of multiple halfspaces"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.4:</i> A polyhedron (central solid region) is formed by intersecting multiple halfspaces. Each face corresponds to one linear inequality constraint.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Convexity of Polyhedra</h4>
          <p>Since halfspaces and hyperplanes are convex sets, and the intersection of any collection of convex sets is convex (see Section 3), a polyhedron is convex.</p>
        </div>

        <p>A <a href="#" class="definition-link">polytope</a> is a bounded polyhedron. Equivalently, it is the convex hull of a finite set of points.</p>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Visualizer: Polyhedron Builder</h3>
          <p><b>Build Feasible Regions from Constraints:</b> A polyhedron is the intersection of finitely many halfspaces. This tool brings LP feasible sets to life:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Add constraints one at a time:</b> Drag to define linear inequalities $a^\top x \le b$</li>
            <li><b>Visualize normals:</b> See the normal vector $a$ pointing <i>out</i> of the feasible region</li>
            <li><b>Watch the intersection:</b> As you add constraints, see how the feasible region is carved out of the plane</li>
          </ul>
          <div id="widget-polyhedron-visualizer" style="width: 100%; height: 520px; position: relative;"></div>
        </div>

        <h3>2.4 The Positive Semidefinite (PSD) Cone</h3>

        <p>The set of symmetric positive semidefinite matrices is a central object in modern convex optimization, forming the domain for <b>Semidefinite Programming (SDP)</b> (<a href="../04-convex-opt-problems/index.html">Lecture 04</a>). Its properties rely on the eigenvalue characterizations from <a href="../00-linear-algebra-primer/index.html">Lecture 00</a>.</p>
        $$
        \mathbb{S}^n_+ = \{X \in \mathbb{S}^n \mid X \succeq 0\}
        $$
        <p>where $X \succeq 0$ means $z^\top X z \ge 0$ for all vectors $z \in \mathbb{R}^n$.</p>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/psd-cone-3d.png"
               alt="Visualization of the 2x2 PSD cone in 3D space"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 2.5:</i> The cone of $2 \times 2$ PSD matrices visualized in 3D space (axes are the matrix entries $x, y, z$). It is a convex cone with a specific "ice-cream" like shape but with a flat boundary structure.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof: The PSD Cone is Convex</h4>
          <p>We need to show that if $A, B \in \mathbb{S}^n_+$ and $\theta \in [0,1]$, then $\theta A + (1-\theta)B \in \mathbb{S}^n_+$.</p>
          <div class="proof-step">
            <strong>Definition Check:</strong> Let $z \in \mathbb{R}^n$ be any vector.
            $$
            z^\top (\theta A + (1-\theta)B) z = \theta (z^\top A z) + (1-\theta) (z^\top B z)
            $$
          </div>
          <div class="proof-step">
            <strong>Sign Analysis:</strong> Since $A, B \succeq 0$, we know $z^\top A z \ge 0$ and $z^\top B z \ge 0$. Since $\theta \in [0,1]$, both coefficients are non-negative.
          </div>
          <div class="proof-step">
            <strong>Conclusion:</strong> The sum is non-negative, so $z^\top (\theta A + (1-\theta)B) z \ge 0$ for all $z$. Thus the combination is PSD.
          </div>
        </div>

        <div class="example">
            <h4>Spectrahedra: The Shape of SDP</h4>
            <p>The intersection of the PSD cone with an affine subspace is called a <a href="#" class="definition-link">spectrahedron</a>. These are the feasible sets for Semidefinite Programs (SDPs). Unlike polyhedra, they have smooth, curved boundaries.</p>
            <figure style="text-align: center; margin: 24px 0;">
              <img src="assets/spectrahedron.png"
                   alt="A spectrahedron (feasible set of an LMI)"
                   style="max-width: 50%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 2.6:</i> A spectrahedron looks like a "puffy" polygon. Its faces are flat where the affine space cuts the cone's boundary, but its edges and corners can be smooth curves.</figcaption>
            </figure>
        </div>
      </section>


      <section class="section-card" id="section-3">
        <h2>3. Operations that Preserve Convexity</h2>

        <p>We can prove that a complex set is convex by building it from simpler convex sets using operations that preserve convexity. This is the "calculus" of convex sets.</p>


        <h3>3.1 Intersection</h3>

        <div class="theorem-box">
          <h4>Theorem (Intersection Preserves Convexity)</h4>
          <p>The intersection of any collection (finite or infinite) of convex sets is convex.</p>
          $$ C = \bigcap_{i \in I} C_i $$
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/convex-intersection.png"
               alt="Venn diagram showing the intersection of two convex sets is convex"
               style="max-width: 60%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 3.1:</i> The intersection of two convex sets (blue and yellow) is the green region. Note that while the union is not necessarily convex, the intersection always is.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof</h4>
          <div class="proof-step">
            Let $x, y \in C$. By definition, $x \in C_i$ and $y \in C_i$ for all $i \in I$.
          </div>
          <div class="proof-step">
            Since each $C_i$ is convex, $\theta x + (1-\theta)y \in C_i$ for all $i \in I$.
          </div>
          <div class="proof-step">
            Therefore, $\theta x + (1-\theta)y \in \bigcap_{i \in I} C_i = C$.
          </div>
        </div>

        <div class="example">
          <h4>Advanced Example: Trigonometric Polynomials</h4>
          <p>Consider the set of coefficients $x \in \mathbb{R}^m$ such that the trigonometric polynomial $p_x(t) = \sum_{k=1}^m x_k \cos(kt)$ is bounded by 1 on an interval:</p>
          $$
          S = \{x \in \mathbb{R}^m \mid |p_x(t)| \le 1 \text{ for all } |t| \le \pi/3\}
          $$
          <p>This set can be written as an infinite intersection of halfspaces:</p>
          $$
          S = \bigcap_{|t| \le \pi/3} \{x \mid -1 \le c(t)^\top x \le 1\}
          $$
          <p>where $c(t) = (\cos(t), \dots, \cos(mt))$. Since each constraint defines a convex "slab" (intersection of two halfspaces), the infinite intersection $S$ is convex.</p>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
            <figure style="text-align: center; flex: 1;">
              <img src="assets/trig-poly-intersection.png"
                   alt="Plot of the convex set of bounded trigonometric polynomials"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 3.2:</i> The set $S$ defined by infinite constraints.</figcaption>
            </figure>
            <figure style="text-align: center; flex: 1;">
              <img src="assets/gonzo-shape.png"
                   alt="Visualizing the intersection of infinite halfspaces"
                   style="width: 100%; height: auto; border-radius: 8px;" />
              <figcaption><i>Figure 3.3:</i> The smooth convex "safe zone" formed by tangent hyperplanes.</figcaption>
            </figure>
        </div>
<h3>3.2 Affine Functions Preserve Convexity</h3>

        <p>Let $f : \mathbb{R}^n \to \mathbb{R}^m$ be an affine function, $f(x) = Ax + b$.</p>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/affine-image-projection.png"
                    alt="Projection of a polyhedron onto 2D space"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.4:</i> The image of a convex set (polyhedron) under an affine map (projection) is convex.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/affine-preimage-cone.png"
                    alt="Slice of a cone by a plane"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.5:</i> The preimage of a convex cone (intersection with a plane) is a convex set (an ellipse).</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Theorem (Affine Image and Preimage)</h4>
          <ul>
            <li><b>Image:</b> If $C \subseteq \mathbb{R}^n$ is convex, then $f(C) = \{Ax + b \mid x \in C\} \subseteq \mathbb{R}^m$ is convex.</li>
            <li><b>Preimage (Inverse Image):</b> If $D \subseteq \mathbb{R}^m$ is convex, then $f^{-1}(D) = \{x \in \mathbb{R}^n \mid Ax + b \in D\}$ is convex.</li>
          </ul>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>

          <div class="proof-step">
            <strong>Image:</strong> Take $y_1, y_2 \in f(C)$, so $y_1 = Ax_1 + b$ and $y_2 = Ax_2 + b$ for some $x_1, x_2 \in C$. For $\theta \in [0,1]$:
            $$
            \theta y_1 + (1-\theta)y_2 = \theta(Ax_1 + b) + (1-\theta)(Ax_2 + b) = A(\theta x_1 + (1-\theta)x_2) + b
            $$
            Since $C$ is convex, $\theta x_1 + (1-\theta)x_2 \in C$, so $\theta y_1 + (1-\theta)y_2 \in f(C)$.
          </div>

          <div class="proof-step">
            <strong>Preimage:</strong> Take $x_1, x_2 \in f^{-1}(D)$, so $Ax_1 + b \in D$ and $Ax_2 + b \in D$. For $\theta \in [0,1]$:
            $$
            A(\theta x_1 + (1-\theta)x_2) + b = \theta(Ax_1 + b) + (1-\theta)(Ax_2 + b)
            $$
            Since $D$ is convex, the right side is in $D$, so $\theta x_1 + (1-\theta)x_2 \in f^{-1}(D)$.
          </div>
        </div>

        <div class="example">
          <h4>Application: Ellipsoids are Convex</h4>
          <p>An ellipsoid $\mathcal{E} = \{x \mid (x - x_c)^\top P^{-1} (x - x_c) \le 1\}$ where $P \succ 0$ can be written as:</p>
          $$
          \mathcal{E} = \{x \mid \|P^{-1/2}(x - x_c)\|_2 \le 1\}
          $$
          <p>This is the preimage of the Euclidean ball $\{z \mid \|z\|_2 \le 1\}$ (convex) under the affine map $f(x) = P^{-1/2}(x - x_c)$. Since preimages preserve convexity, $\mathcal{E}$ is convex.</p>
          <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/image-vs-preimage-ball.png"
                    alt="Comparison of image vs preimage of a ball"
                    style="max-width: 60%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.6:</i> The image of a ball is an ellipsoid (left). The preimage of a ball (slab) is also convex (right).</figcaption>
          </figure>
        </div>

        <div class="insight">
            <h4>Counterexample: Non-Affine Maps</h4>
            <p>Convexity is fragile. Non-affine maps, such as $f(x) = 1/x$ or $f(x) = x^2$, do not generally preserve convexity of sets.</p>
            <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/division-counterexample.png"
                    alt="Division function mapping a convex set to non-convex"
                    style="max-width: 50%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.7:</i> The "division" map $f(x,y) = x/y$ can tear a convex square into two disjoint (non-convex) pieces.</figcaption>
            </figure>
        </div>

        <h3>3.3 Perspective and Linear-Fractional Functions</h3>

        <p>The <b>perspective function</b> $P : \mathbb{R}^{n+1} \to \mathbb{R}^n$ is defined by:</p>
        $$
        P(x, t) = x/t, \quad \mathrm{dom}\, P = \{(x, t) \mid t > 0\}
        $$
        <p>Geometrically, this corresponds to a pinhole camera projection: points $(x,t)$ are projected onto the plane $t=1$ via lines through the origin.</p>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/pinhole-camera.png"
                    alt="Geometric intuition of perspective projection"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.8:</i> The perspective map $P(x,t) = x/t$ projects 3D points onto the $t=1$ plane. The image of a convex object (ellipsoid) is a convex shadow.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/perspective-domain.png"
                    alt="Domain of the perspective map"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 3.9:</i> The domain is restricted to $t > 0$. As $t \to 0$, the projected point shoots to infinity.</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>The perspective function preserves convexity: if $C \subseteq \mathbb{R}^{n+1}$ is convex, then $P(C)$ is convex.</p>
        </div>

        <p>A <a href="#" class="definition-link">linear-fractional function</a> is a composition of perspective with an affine function:</p>
        $$
        f(x) = \frac{Ax + b}{c^\top x + d}
        $$
        <p>Since it is composed of operations that preserve convexity (Affine $\to$ Perspective), linear-fractional functions also preserve convexity.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/composition-maps.png"
                  alt="Block diagram of function composition"
                  style="max-width: 60%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 3.10:</i> Linear-fractional functions are built by composing an affine map $g(x)$ with the perspective map $P$.</figcaption>
        </figure>

        <div class="example">
             <h4>Visualizing Projective Geometry</h4>
             <p>Linear-fractional maps can distort space significantly, turning parallel lines into converging ones (like train tracks on a horizon), yet they strictly preserve the convexity of sets.</p>
             <figure style="text-align: center; margin: 24px 0;">
                  <img src="assets/warping-grid.png"
                       alt="Grid warped by a linear-fractional map"
                       style="max-width: 60%; height: auto; border-radius: 8px;" />
                  <figcaption><i>Figure 3.11:</i> A regular grid (left) is warped by a linear-fractional transformation (right). Squares become "conic" quadrilaterals, but they remain convex sets.</figcaption>
             </figure>
        </div>

        <h3>3.4 Minkowski Sum</h3>
        <p>The <a href="#" class="definition-link">Minkowski sum</a> of two sets $C, D \subseteq \mathbb{R}^n$ is the set of all vector sums:</p>
        $$ C + D = \{x + y \mid x \in C, y \in D\} $$

        <div class="theorem-box">
          <h4>Theorem</h4>
          <p>If $C$ and $D$ are convex, then $C+D$ is convex.</p>
        </div>

        <div class="proof-box">
          <h4>Proof</h4>
          <p>Let $u, v \in C+D$. Then $u = c_1 + d_1$ and $v = c_2 + d_2$ for some $c_i \in C, d_i \in D$.
          For any $\theta \in [0,1]$:</p>
          $$
          \theta u + (1-\theta)v = \theta(c_1 + d_1) + (1-\theta)(c_2 + d_2)
          = [\theta c_1 + (1-\theta)c_2] + [\theta d_1 + (1-\theta)d_2]
          $$
          <p>Since $C$ is convex, the first bracket is in $C$. Since $D$ is convex, the second is in $D$. Thus the sum is in $C+D$.</p>
        </div>

        <h3>3.5 Cartesian Product</h3>
        <p>The product of convex sets $C \subseteq \mathbb{R}^n$ and $D \subseteq \mathbb{R}^m$ is convex in $\mathbb{R}^{n+m}$:</p>
        $$ C \times D = \{(x, y) \mid x \in C, y \in D\} $$
        <p>This follows because component-wise convex combinations preserve membership in $C$ and $D$ respectively.</p>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Laboratory: Convex Geometry</h3>
          <p><b>Draw, Combine, and Verify:</b> This unified workspace lets you experiment with convex sets and operations. It combines drawing capabilities with set algebra:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Draw Custom Sets:</b> Use the pen tool to draw polygons. Double-click to close.</li>
            <li><b>Add Primitives:</b> Quickly add standard convex sets like circles and squares.</li>
            <li><b>Apply Operations:</b> Select multiple sets (Shift+Click) and apply operations like <b>Intersection</b>, <b>Convex Hull</b>, or <b>Minkowski Sum</b>.</li>
            <li><b>Verify Convexity:</b> The lab automatically labels sets as Convex (C) or Non-Convex (NC).</li>
          </ul>
          <p><i>Key Concept:</i> Notice how the intersection of any two sets (even non-convex ones) doesn't guarantee convexity, but the intersection of <i>convex</i> sets is always convex!</p>
          <div id="widget-convex-geometry-lab" style="width: 100%; position: relative;"></div>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. Separating and Supporting Hyperplane Theorems</h2>

        <p>These theorems are the geometric backbone of duality theory, optimality conditions, and many algorithms in convex optimization.</p>

        <h3>4.1 The Separating Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Separating Hyperplane)</h4>
          <p>Let $C, D \subseteq \mathbb{R}^n$ be nonempty, disjoint, convex sets. Then there exists a hyperplane that separates them: there exist $a \in \mathbb{R}^n \setminus \{0\}$ and $b \in \mathbb{R}$ such that:</p>
          $$
          a^\top x \le b \quad \forall x \in C, \qquad a^\top y \ge b \quad \forall y \in D
          $$
          <p>If additionally one of $C$ or $D$ is compact, or if $\mathrm{dist}(C, D) > 0$, then we can achieve <b>strict separation</b> (with $<$ and $>$ instead of $\le$ and $\ge$).</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/separating-hyperplane-strict.png"
               alt="Illustration of the Separating Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 4.1:</i> A hyperplane separating two disjoint convex sets $C$ and $D$. For closed sets, we can construct the separator using the projection of 0 onto their difference set $C-D$.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof (Constructive via Projection)</h4>

          <div class="proof-step">
            <strong>Step 1: Form the Difference Set.</strong> Define the Minkowski difference $S = C - D = \{c - d \mid c \in C, d \in D\}$.
            <br>Since $C$ and $D$ are convex, their difference $S$ is also convex.
            <br>Since $C \cap D = \emptyset$, the origin $0$ is <b>not</b> in $S$. (If $0 = c-d$, then $c=d \in C \cap D$).
          </div>

          <div class="proof-step">
            <strong>Step 2: Project Zero onto the Closure.</strong> Let $\bar{S} = \mathrm{cl}(S)$. Since $S$ is convex, $\bar{S}$ is closed and convex.
            <br>Let $p = \Pi_{\bar{S}}(0)$ be the projection of the origin onto $\bar{S}$.
            <br>If $0 \notin \bar{S}$, then $p \neq 0$. (The case where $0 \in \partial S$ requires a limiting argument using supporting hyperplanes, but we assume strict separation possible for geometric intuition).
          </div>

          <div class="proof-step">
            <strong>Step 3: Characterize Projection.</strong> By the projection theorem, for any $z \in \bar{S}$:
            $$ (z - p)^\top (0 - p) \le 0 \implies (z - p)^\top (-p) \le 0 \implies z^\top p \ge p^\top p = \|p\|_2^2 > 0 $$
            Since every $z \in S$ is of the form $c - d$:
            $$ (c - d)^\top p \ge \|p\|_2^2 \implies p^\top c \ge p^\top d + \|p\|_2^2 $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Define the Hyperplane.</strong> Set the normal vector $a = p$. Define the scalar $b$ halfway between the boundaries:
            $$ b = \sup_{d \in D} a^\top d + \frac{1}{2}\|p\|_2^2 $$
            Then for all $c \in C, d \in D$:
            $$ a^\top c \ge a^\top d + \|p\|_2^2 > b > a^\top d $$
            Thus, the hyperplane $\{x \mid a^\top x = b\}$ strictly separates $C$ and $D$.
          </div>
        </div>

        <h3>4.2 The Supporting Hyperplane Theorem</h3>

        <div class="theorem-box">
          <h4>Theorem (Supporting Hyperplane)</h4>
          <p>Let $C \subseteq \mathbb{R}^n$ be a nonempty, closed, convex set, and let $x_0 \in \partial C$ (the boundary of $C$). Then there exists a <b>supporting hyperplane</b> to $C$ at $x_0$: there exists $a \in \mathbb{R}^n \setminus \{0\}$ such that:</p>
          $$
          a^\top x \le a^\top x_0 \quad \forall x \in C
          $$
          <p>The hyperplane $\{x \mid a^\top x = a^\top x_0\}$ "supports" $C$ at $x_0$â€”it touches $C$ at $x_0$ and $C$ lies entirely on one side.</p>
        </div>

        <figure style="text-align: center; margin: 24px 0;">
          <img src="assets/supporting-hyperplane-tangent.png"
               alt="Illustration of the Supporting Hyperplane Theorem"
               style="max-width: 80%; height: auto; border-radius: 8px;" />
          <figcaption><i>Figure 4.2:</i> A supporting hyperplane to a convex set at a boundary point. It "kisses" the set without cutting into it.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Proof (via Projection)</h4>

          <div class="proof-step">
            <strong>Step 1: Take an exterior point.</strong> Since $x_0 \in \partial C$ (boundary), there exists a sequence $\{y_k\} \subset \mathbb{R}^n \setminus C$ with $y_k \to x_0$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Project each $y_k$ onto $C$.</strong> Let $p_k = \Pi_C(y_k)$ be the projection. By the projection characterization:
            $$
            (y_k - p_k)^\top (x - p_k) \le 0 \quad \forall x \in C
            $$
          </div>

          <div class="proof-step">
            <strong>Step 3: Pass to the limit.</strong> As $k \to \infty$, we have $p_k \to x_0$ (since $y_k \to x_0$ and projections are continuous). Normalize $a_k = (y_k - p_k) / \|y_k - p_k\|_2$ and extract a convergent subsequence $a_k \to a$ with $\|a\|_2 = 1$. Taking limits:
            $$
            a^\top (x - x_0) \le 0 \quad \forall x \in C
            $$
            Rearranging: $a^\top x \le a^\top x_0$ for all $x \in C$.
          </div>
        </div>

        <div class="insight">
          <h4>ðŸ”‘ Why These Theorems Matter</h4>
          <ul>
            <li><b>Duality:</b> The separating hyperplane theorem is the geometric foundation of <b>Lagrangian duality</b> (<a href="../05-duality/index.html">Lecture 05</a>). Specifically, Strong Duality holds because we can separate the set of achievable values from the "better-than-optimal" region in the cost-constraint space.</li>
            <li><b>Optimality:</b> The supporting hyperplane theorem leads to first-order optimality conditions (KKT conditions)</li>
            <li><b>Algorithms:</b> Cutting-plane methods and bundle methods rely on separating hyperplanes</li>
            <li><b>Subgradients:</b> Supporting hyperplanes define subgradients for non-smooth convex functions</li>
          </ul>
          <figure style="text-align: center; margin: 24px 0;">
               <img src="assets/separation-failure.png"
                    alt="Failure of separation for non-convex sets"
                    style="max-width: 60%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 4.3:</i> <b>Cautionary Tale:</b> If the sets are not convex (like the C-shape), a separating hyperplane may not exist. This is why convexity is required for strong duality.</figcaption>
          </figure>
        </div>

        <div class="widget-container" style="margin: 24px 0;">
          <h3 style="margin-top: 0;">Interactive Explorer: Separating Hyperplanes</h3>
          <p><b>Find Hyperplanes that Separate Convex Sets:</b> This widget makes the Separating Hyperplane Theorem tangible:</p>
          <ul style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <li><b>Draw two sets:</b> Click to define vertices of two convex polygons</li>
            <li><b>Drag to move:</b> Move the sets around and watch the separating hyperplane update in real-time</li>
            <li><b>Auto-compute separation:</b> The tool uses the closest-point algorithm (constructive proof logic) to find the optimal separator</li>
            <li><b>Observe the boundary case:</b> See what happens when the sets touch (strict separation becomes non-strict)</li>
            <li><b>Violate separation:</b> If you make the sets overlap, the tool detects the collision and shows no hyperplane exists</li>
          </ul>
          <p><i>Connection to optimization:</i> This is exactly what happens in SVM classificationâ€”finding the maximum-margin separating hyperplane between two classes of data points!</p>
          <div id="widget-separating-hyperplane" style="width: 100%; height: 450px; position: relative;"></div>
        </div>
      </section>


      <section class="section-card" id="section-5">
        <h2>5. Cones, Proper Cones, and Dual Cones</h2>

        <h3>5.1 Cones and Convex Cones</h3>

        <p>A set $K \subseteq \mathbb{R}^n$ is a <a href="#" class="definition-link">cone</a> if it is closed under non-negative scaling:</p>
        $$ x \in K, \ \alpha \ge 0 \implies \alpha x \in K $$

        <p>A <a href="#" class="definition-link">convex cone</a> is a cone that is also a convex set. Equivalently, it is closed under non-negative linear combinations:</p>
        $$ x, y \in K, \ \alpha, \beta \ge 0 \implies \alpha x + \beta y \in K $$

        <div class="example">
            <h4>Examples of Convex Cones</h4>
            <ul>
                <li><b>Non-negative orthant:</b> $\mathbb{R}^n_+ = \{x \in \mathbb{R}^n \mid x_i \ge 0\}$</li>
                <li><b>Second-order cone (Lorentz cone):</b> $\mathcal{Q}^{n+1} = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\|_2 \le t\}$</li>
                <li><b>Norm Cone (Epigraph of a Norm):</b> For any norm $\|\cdot\|$, the set $C = \{(x, t) \in \mathbb{R}^{n+1} \mid \|x\| \le t\}$ is a convex cone. This is the epigraph of the norm function.
                  <br><i>Proof:</i>
                  <ul>
                    <li><b>Cone property:</b> If $(x, t) \in C$, then for $\alpha \ge 0$, $\|\alpha x\| = \alpha \|x\| \le \alpha t$, so $\alpha(x, t) \in C$.</li>
                    <li><b>Convexity:</b> If $(x, t) \in C$ and $(y, s) \in C$, then $\|x+y\| \le \|x\| + \|y\| \le t + s$, so $(x+y, t+s) \in C$.</li>
                  </ul>
                  This generalizes the Second-Order Cone (where the norm is Euclidean).
                </li>
                <li><b>PSD Cone:</b> $\mathbb{S}^n_+ = \{X \in \mathbb{S}^n \mid X \succeq 0\}$</li>
            </ul>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/second-order-cone.png"
                    alt="3D visualization of the second-order cone (ice cream cone)"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.1:</i> The Second-Order Cone in $\mathbb{R}^3$ (ice-cream cone) is defined by $\|x\|_2 \le t$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/hyperbolic-cone.png"
                    alt="3D visualization of a hyperbolic cone"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.2:</i> A Hyperbolic Cone (generalized version). The cross-sections are ellipses that grow as you move up the axis.</figcaption>
             </figure>
        </div>

        <h3>5.2 Proper Cones</h3>

        <p>A <a href="#" class="definition-link">proper cone</a> is a convex cone $K$ that satisfies three additional properties:</p>
        <ol>
          <li><b>Closed:</b> $K$ contains its boundary.</li>
          <li><b>Pointed:</b> $K$ contains no lines ($K \cap -K = \{0\}$).</li>
          <li><b>Solid:</b> $K$ has a non-empty interior.</li>
        </ol>

        <p>Proper cones are geometrically "sharp" (pointed) and "full-dimensional" (solid). They are used to define generalized inequalities.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/cone-zoo.png"
                  alt="Examples of proper and improper cones"
                  style="max-width: 90%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 5.3:</i> The "Cone Zoo". Left: A proper cone (closed, pointed, solid). Center: A wedge (not pointed, contains a line). Right: A flat slice (not solid, empty interior).</figcaption>
        </figure>

        <div class="example">
            <h4>Example: Nonnegative Polynomials</h4>
            <p>The set of polynomials of degree $n$ that are non-negative on an interval $[0,1]$ forms a proper convex cone in the space of coefficients.</p>
            <figure style="text-align: center; margin: 24px 0;">
                 <img src="assets/nonnegative-poly-cone.png"
                      alt="Cone of nonnegative polynomials"
                      style="max-width: 50%; height: auto; border-radius: 8px;" />
                 <figcaption><i>Figure 5.4:</i> Visualizing the cone of polynomials $P(t)$ such that $P(t) \ge 0$ for $t \in [0,1]$. The boundary corresponds to polynomials with roots in the interval.</figcaption>
            </figure>
        </div>

        <h3>5.3 Generalized Inequalities</h3>

        <p>A proper cone $K$ defines a partial ordering $\preceq_K$ on $\mathbb{R}^n$:</p>
        $$
        x \preceq_K y \iff y - x \in K
        $$
        <p>Strict inequality is defined using the interior of the cone:</p>
        $$
        x \prec_K y \iff y - x \in \text{int}(K)
        $$

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/generalized-inequality-cone.png"
                    alt="Visualizing generalized inequality"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.5:</i> Visualizing $x \preceq_K y$. The point $x$ must lie in the "shadow" of $y$ cast by the cone $-K$.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/matrix-inequality-cone.png"
                    alt="Matrix inequality ordering"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.6:</i> Partial ordering in the PSD cone. $A \preceq B$ means $B-A$ is in the PSD cone.</figcaption>
             </figure>
        </div>

        <div class="theorem-box">
          <h4>Properties of Generalized Inequalities</h4>
          <ul>
            <li><b>Reflexive:</b> $x \preceq_K x$</li>
            <li><b>Antisymmetric:</b> $x \preceq_K y \text{ and } y \preceq_K x \implies x = y$</li>
            <li><b>Transitive:</b> $x \preceq_K y \text{ and } y \preceq_K z \implies x \preceq_K z$</li>
            <li><b>Additivity:</b> $x \preceq_K y \implies x + u \preceq_K y + u$</li>
          </ul>
        </div>

        <div class="insight">
             <h4>Minimum vs. Minimal</h4>
             <p>Because the ordering is partial, we distinguish between a <b>minimum</b> element (smaller than everyone, e.g., the origin in $\mathbb{R}^n_+$) and a <b>minimal</b> element (nothing is smaller than it, but it might not compare to everyone).</p>
             <figure style="text-align: center; margin: 24px 0;">
                  <img src="assets/minimum-vs-minimal.png"
                       alt="Minimum vs minimal elements"
                       style="max-width: 60%; height: auto; border-radius: 8px;" />
                  <figcaption><i>Figure 5.7:</i> Left: Minimum element (unique). Right: Minimal elements (red boundary). In vector optimization (Pareto optimality), we seek minimal elements.</figcaption>
             </figure>
        </div>

        <h3>5.4 The Dual Cone</h3>

        <p>The <a href="#" class="definition-link">dual cone</a> of a cone $K$ is the set of all vectors making a non-obtuse angle with every vector in $K$:</p>
        $$
        K^* = \{y \in \mathbb{R}^n \mid y^\top x \ge 0 \ \forall x \in K\}
        $$
        <p>The dual cone $K^*$ is always a closed convex cone, regardless of whether $K$ is convex or closed.</p>

        <figure style="text-align: center; margin: 24px 0;">
             <img src="assets/dual-cone-geometry.png"
                  alt="Geometry of primal and dual cones"
                  style="max-width: 50%; height: auto; border-radius: 8px;" />
             <figcaption><i>Figure 5.8:</i> The dual cone $K^*$ (red) consists of vectors that make an angle $\le 90^\circ$ with every vector in $K$ (blue).</figcaption>
        </figure>

        <div class="theorem-box">
            <h4>Important Dualities</h4>
            <ul>
                <li>$\mathbb{R}^n_+$ is <b>self-dual</b>: $(\mathbb{R}^n_+)^* = \mathbb{R}^n_+$</li>
                <li>$\mathbb{S}^n_+$ is <b>self-dual</b>: $(\mathbb{S}^n_+)^* = \mathbb{S}^n_+$ (under trace inner product). This property is crucial for the symmetry of primal and dual <b>Semidefinite Programs</b> (<a href="../05-duality/index.html">Lecture 05</a>).</li>
                <li>$\mathcal{Q}^{n+1}$ is <b>self-dual</b>: $(\mathcal{Q}^{n+1})^* = \mathcal{Q}^{n+1}$</li>
                <li>$(L_p \text{ norm cone})^* = L_q \text{ norm cone}$ where $1/p + 1/q = 1$.</li>
            </ul>
        </div>

        <div class="row" style="display: flex; gap: 20px; justify-content: center; margin: 24px 0;">
             <figure style="text-align: center; flex: 1;">
               <img src="assets/self-dual-cones.png"
                    alt="The three major self-dual cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.9:</i> The Big Three self-dual cones: Nonnegative Orthant, Second-Order Cone, and PSD Cone.</figcaption>
             </figure>
             <figure style="text-align: center; flex: 1;">
               <img src="assets/dual-norm-cones.png"
                    alt="Dual relationship between L1 and L-infinity cones"
                    style="width: 100%; height: auto; border-radius: 8px;" />
               <figcaption><i>Figure 5.10:</i> Duality of Norm Cones: The dual of the $L_1$ cone is the $L_\infty$ cone.</figcaption>
             </figure>
        </div>
      </section>


      <section class="section-card" id="section-6">
        <h2>6. Topological Toolkit: Closure, Interior, Relative Interior</h2>

        <p>To work precisely with convex sets and optimality conditions, we need clear notions of "inside," "edge," and "outside."</p>

        <h3>6.1 Basic Topological Definitions</h3>

        <p>Let $C \subseteq \mathbb{R}^n$ be any set.</p>

        <ul>
          <li><b>Closure</b> $\mathrm{cl}(C)$: The set of all limits of convergent sequences in $C$. It's the smallest closed set containing $C$.</li>
          <li><b>Interior</b> $\mathrm{int}(C)$: Points with some open ball fully contained in $C$. Intuitively, "strictly inside" $C$.</li>
          <li><b>Boundary</b> $\partial C = \mathrm{cl}(C) \setminus \mathrm{int}(C)$: The "edge" of $C$.</li>
          <li><b>Affine hull</b> $\mathrm{aff}(C)$: The smallest affine set containing $C$.</li>
          <li><b>Relative interior</b> $\mathrm{ri}(C)$: The interior of $C$ <i>relative to</i> $\mathrm{aff}(C)$. Points strictly inside when viewed in the affine hull.</li>
        </ul>

        <div class="example">
          <h4>Example 1: Line Segment in $\mathbb{R}^2$</h4>
          <p>Consider $C = \{(t, 0) \mid 0 \le t \le 1\}$ (a line segment on the $x$-axis).</p>
          <ul>
            <li>$\mathrm{int}(C) = \emptyset$ (no open ball in $\mathbb{R}^2$ fits inside a line)</li>
            <li>$\mathrm{aff}(C) = \{(t, 0) \mid t \in \mathbb{R}\}$ (the entire $x$-axis)</li>
            <li>$\mathrm{ri}(C) = \{(t, 0) \mid 0 < t < 1\}$ (interior relative to the $x$-axis)</li>
          </ul>
        </div>

        <div class="example">
          <h4>Example 1b: A Flat Disk in 3D</h4>
          <p>Consider a flat circular disk floating in 3D space: $C = \{(x, y, 0) \mid x^2 + y^2 \le 1\}$.</p>
          <ul>
            <li><b>Interior:</b> Empty ($\emptyset$). A 3D ball has volume, but this disk is flat, so no 3D ball fits inside it.</li>
            <li><b>Affine Hull:</b> The $xy$-plane ($z=0$).</li>
            <li><b>Relative Interior:</b> The disk without its boundary circle: $\{(x, y, 0) \mid x^2 + y^2 < 1\}$. Viewed "relative" to the plane it lives in, it has an interior!</li>
          </ul>
        </div>

        <div class="example">
          <h4>Example 2: Standard Simplex</h4>
          <p>$\Delta^n = \{x \in \mathbb{R}^n \mid x \ge 0, \mathbf{1}^\top x = 1\}$.</p>
          <ul>
            <li>$\mathrm{int}(\Delta^n) = \emptyset$ (lies in a hyperplane)</li>
            <li>$\mathrm{aff}(\Delta^n) = \{x \mid \mathbf{1}^\top x = 1\}$ (the hyperplane)</li>
            <li>$\mathrm{ri}(\Delta^n) = \{x > 0 \mid \mathbf{1}^\top x = 1\}$ (all coordinates strictly positive)</li>
          </ul>
        </div>

        <h3>6.2 Key Properties for Convex Sets</h3>

        <div class="theorem-box">
          <h4>Facts About Convex Sets</h4>
          <ol>
            <li><b>Closure is Convex:</b> $\mathrm{cl}(C)$ is convex.
              <br><i>Proof:</i> Let $a, b \in \mathrm{cl}(C)$. Then there exist sequences $a_k \to a, b_k \to b$ with $a_k, b_k \in C$. For any $\theta$, the sequence $z_k = \theta a_k + (1-\theta)b_k$ lies in $C$ (by convexity) and converges to $\theta a + (1-\theta)b$. Thus the limit is in $\mathrm{cl}(C)$.
            </li>
            <li>$\mathrm{int}(C)$ (if nonempty) and $\mathrm{ri}(C)$ are convex.</li>
            <li>If $C$ is convex with nonempty interior, then $\mathrm{cl}(C) = \mathrm{cl}(\mathrm{int}(C))$ and $\mathrm{int}(C) = \mathrm{int}(\mathrm{cl}(C))$.</li>
            <li><b>Relative interior of intersection:</b> If $\mathrm{ri}(C) \cap \mathrm{ri}(D) \neq \emptyset$, then:
              $$
              \mathrm{ri}(C \cap D) = \mathrm{ri}(C) \cap \mathrm{ri}(D)
              $$
            </li>
            <li><b>Affine functions:</b> If $f(x) = Ax + b$, then $f(\mathrm{ri}(C)) = \mathrm{ri}(f(C))$ for convex $C$.</li>
          </ol>
        </div>

        <h3>6.3 Why Relative Interior Matters</h3>

        <p>Relative interior is crucial for:</p>
        <ul>
          <li><b>Constraint qualifications:</b> Slater's condition for strong duality (Lecture 05) requires a point in $\mathrm{ri}(\mathrm{dom}(f_0))$</li>
          <li><b>Optimality conditions:</b> KKT conditions require regularity at boundary points</li>
          <li><b>Interior-point methods:</b> Algorithms that approach optimality from the relative interior</li>
        </ul>
      </section>


    <section class="section-card" id="section-8">
      <h2>8. Review & Cheat Sheet</h2>

      <h3>Quick Reference Glossary</h3>


        <p>Essential terms from this lecture for quick lookup:</p>

        <ul style="column-count: 2; column-gap: 2rem;">
          <li><b>Affine combination:</b> $\sum_i \theta_i x_i$ with $\sum_i \theta_i = 1$</li>
          <li><b>Affine set:</b> Contains all affine combinations of its points</li>
          <li><b>Boundary ($\partial C$):</b> $\mathrm{cl}(C) \setminus \mathrm{int}(C)$</li>
          <li><b>Closure ($\mathrm{cl}(C)$):</b> All limit points of sequences in $C$</li>
          <li><b>Cone:</b> $x \in K, \theta \ge 0 \implies \theta x \in K$</li>
          <li><b>Conic combination:</b> $\sum_i \theta_i x_i$ with $\theta_i \ge 0$</li>
          <li><b>Convex combination:</b> $\sum_i \theta_i x_i$ with $\theta_i \ge 0, \sum_i \theta_i = 1$</li>
          <li><b>Convex cone:</b> Cone that is also convex</li>
          <li><b>Convex hull ($\mathrm{conv}(S)$):</b> All convex combinations of points in $S$</li>
          <li><b>Convex set:</b> Contains all line segments between its points</li>
          <li><b>Dual cone ($K^*$):</b> $\{y \mid y^\top x \ge 0 \ \forall x \in K\}$</li>
          <li><b>Ellipsoid:</b> $\{x \mid (x-x_c)^\top P^{-1}(x-x_c) \le 1\}$</li>
          <li><b>Generalized inequality:</b> $x \preceq_K y$ iff $y - x \in K$</li>
          <li><b>Halfspace:</b> $\{x \mid a^\top x \le b\}$</li>
          <li><b>Hyperplane:</b> $\{x \mid a^\top x = b\}$</li>
          <li><b>Interior ($\mathrm{int}(C)$):</b> Points with open ball fully in $C$</li>
          <li><b>Norm ball:</b> $\{x \mid \|x - x_c\| \le r\}$</li>
          <li><b>Polyhedron:</b> $\{x \mid Ax \le b, Cx = d\}$</li>
          <li><b>Polytope:</b> Bounded polyhedron</li>
          <li><b>Proper cone:</b> Convex, closed, pointed, solid</li>
          <li><b>PSD cone ($\mathbb{S}^n_+$):</b> $\{X \succeq 0\}$</li>
          <li><b>Relative interior ($\mathrm{ri}(C)$):</b> Interior relative to $\mathrm{aff}(C)$</li>
          <li><b>Second-order cone ($\mathcal{Q}$):</b> $\{(x,t) \mid \|x\|_2 \le t\}$</li>
          <li><b>Separating hyperplane:</b> Divides two disjoint convex sets</li>
          <li><b>Simplex ($\Delta^n$):</b> $\{x \ge 0 \mid \mathbf{1}^\top x = 1\}$</li>
          <li><b>Supporting hyperplane:</b> Touches boundary, set on one side</li>
        </ul>
    </section>



      <section class="section-card" id="section-9">
    <h2><i data-feather="edit-3"></i> 9. Exercises</h2>
    <p>These problems consolidate all exercises from throughout the lecture and add additional practice.</p>

<div class="problem">
  <h3>P2.1 â€” Convexity of Distance Set</h3>
  <p>Show that the set of points closer to a given point $x_0$ than to another point $y_0$, defined as:</p>$$C = \{x \in \mathbb{R}^n \mid \|x - x_0\|_2 \le \|x - y_0\|_2\}$$<p>is a convex set.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <ul><li><b>Geometric Bisector:</b> The set is the halfspace defined by the perpendicular bisector of the segment $[x_0, y_0]$.</li><li><b>Algebraic Verification:</b> Expanding norms cancels the quadratic term $x^\top x$, leaving a linear inequality.</li></ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>Step 1: Square both sides.</strong> Since norms are non-negative: $ \|x - x_0\|_2^2 \le \|x - y_0\|_2^2 $.</div>
       <div class="proof-step"><strong>Step 2: Expand.</strong> $ (x - x_0)^\top (x - x_0) \le (x - y_0)^\top (x - y_0) \implies x^\top x - 2x_0^\top x + \|x_0\|^2 \le x^\top x - 2y_0^\top x + \|y_0\|^2 $.</div>
       <div class="proof-step"><strong>Step 3: Simplify.</strong> $ 2(y_0 - x_0)^\top x \le \|y_0\|^2 - \|x_0\|^2 $.</div>
       <div class="proof-step"><strong>Conclusion:</strong> This is a linear inequality $a^\top x \le b$, defining a halfspace, which is convex.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.2 â€” Dual of a Subspace</h3>
  <p>Let $V \subseteq \mathbb{R}^n$ be a linear subspace. Prove that its dual cone is the orthogonal complement: $V^* = V^\perp$.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Subspace Duality:</b> Since a subspace contains lines through the origin (both $x$ and $-x$), the condition $y^\top x \ge 0$ forces $y^\top x = 0$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>($V^\perp \subseteq V^*$):</strong> If $y \in V^\perp$, $y^\top x = 0 \ge 0$ for all $x \in V$. So $y \in V^*$.</div>
       <div class="proof-step"><strong>($V^* \subseteq V^\perp$):</strong> If $y \in V^*$, then $y^\top x \ge 0$ for all $x \in V$. Since $-x \in V$, $y^\top (-x) \ge 0 \implies y^\top x \le 0$. Thus $y^\top x = 0$, so $y \in V^\perp$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.3 â€” Convexity of Quadratic Sublevel Set</h3>
  <p>Let $f(x) = x^\top A x + b^\top x + c$ where $A \in \mathbb{S}^n$ is symmetric, $b \in \mathbb{R}^n, c \in \mathbb{R}$. Define the set $C = \{x \in \mathbb{R}^n \mid f(x) \le 0\}$.</p>
       <p><b>(a)</b> Prove that if $A \succeq 0$, then $C$ is convex.</p>
       <p><b>(b)</b> Let $H = \{x \mid g^\top x + h = 0\}$ be a hyperplane. Show that if $A + \lambda g g^\top \succeq 0$ for some $\lambda$, then $C \cap H$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <ul><li><b>Convexity of Quadratics:</b> A quadratic function is convex iff its Hessian $2A$ is PSD. Sublevel sets of convex functions are convex.</li>
       <li><b>Restriction to Subspace:</b> Even if $A$ is not PSD, the function might be convex <i>when restricted</i> to the feasible set (e.g., the hyperplane).</li></ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>(a) Convexity when $A \succeq 0$.</strong> Let $x, y \in C$ and $z = \theta x + (1-\theta)y$ for $\theta \in [0,1]$.
       <br>Expand $f(z)$:
       $$ f(z) = \theta f(x) + (1-\theta)f(y) - \theta(1-\theta)(x-y)^\top A (x-y) $$
       Since $A \succeq 0$, $(x-y)^\top A (x-y) \ge 0$. Also $\theta(1-\theta) \ge 0$.
       Thus $f(z) \le \theta f(x) + (1-\theta)f(y)$. Since $f(x), f(y) \le 0$, we have $f(z) \le 0$. So $z \in C$.</div>
       <div class="proof-step"><strong>(b) Convexity on Hyperplane.</strong> Define $\tilde f(x) = f(x) + \lambda (g^\top x + h)^2$.
       The term $(g^\top x + h)^2$ is zero for all $x \in H$, so $\tilde f(x) = f(x)$ on $H$.
       $$ \tilde f(x) = x^\top (A + \lambda g g^\top) x + (b + 2\lambda h g)^\top x + (c + \lambda h^2) $$
       The Hessian of $\tilde f$ is $2(A + \lambda g g^\top) \succeq 0$, so $\tilde f$ is convex.
       Thus $S = \{x \mid \tilde f(x) \le 0\}$ is convex.
       Since $C \cap H = S \cap H$ (because $f = \tilde f$ on $H$), and the intersection of convex sets $S$ and $H$ is convex, $C \cap H$ is convex.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.4 â€” Relative Interior of the Simplex</h3>
  <p>Show that $\mathrm{ri}(\Delta^n) = \{x \in \mathbb{R}^n \mid x > 0, \mathbf{1}^\top x = 1\}$.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Relative Interior:</b> Points strictly inside the set relative to its affine hull. For the simplex, this means probability distributions with full support (no zero entries).</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">The affine hull is $\{x \mid \mathbf{1}^\top x = 1\}$. A point $x$ is in the relative interior if there is a ball in this plane around $x$ contained in $\Delta^n$. If any $x_i = 0$, we can move slightly negative in that direction while staying in the plane, violating $x \ge 0$. Thus all $x_i > 0$ is required.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.5 â€” Separation by Projection</h3>
  <p>Let $C$ be closed convex, $y \notin C$. Prove $a = y - \Pi_C(y)$ defines a strictly separating hyperplane.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Projection Theorem:</b> The projection $p = \Pi_C(y)$ satisfies $(y-p)^\top (x-p) \le 0$ for all $x \in C$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $p = \Pi_C(y)$ and $a = y - p$. By the projection property: $a^\top (x - p) \le 0 \implies a^\top x \le a^\top p$.</div>
       <div class="proof-step">Since $y \notin C$, $a \neq 0$. $a^\top y = a^\top (p + a) = a^\top p + \|a\|^2 > a^\top p$.</div>
       <div class="proof-step">Thus $a^\top x \le a^\top p < a^\top y$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.6 â€” Self-Duality of Second-Order Cone</h3>
  <p>Prove $\mathcal{Q} = \{(x,t) \mid \|x\|_2 \le t\}$ is self-dual.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Cauchy-Schwarz:</b> The proof hinges on $u^\top v \ge -\|u\|\|v\|$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>($\subseteq$):</strong> If $(y,s), (x,t) \in \mathcal{Q}$, then $y^\top x + st \ge -\|y\|\|x\| + st \ge -st + st = 0$. So $\mathcal{Q} \subseteq \mathcal{Q}^*$.</div>
       <div class="proof-step"><strong>($\supseteq$):</strong> If $(y,s) \in \mathcal{Q}^*$, assume $\|y\| > s$.
       If $s < 0$, test against $(0,1) \in \mathcal{Q} \implies s \ge 0$ (contradiction).
       If $s \ge 0$, test against $(-y/\|y\|, 1) \in \mathcal{Q} \implies -\|y\| + s \ge 0 \implies s \ge \|y\|$ (contradiction).
       Thus $\|y\| \le s$, so $(y,s) \in \mathcal{Q}$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.7 â€” Dual Cone Identities</h3>
  <p>Prove $(K_1 + K_2)^* = K_1^* \cap K_2^*$.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Sum vs Intersection:</b> A linear functional is non-negative on a sum iff it is non-negative on each part.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>($\supseteq$):</strong> If $y \in K_1^* \cap K_2^*$, then $y^\top(x_1+x_2) = y^\top x_1 + y^\top x_2 \ge 0$.</div>
       <div class="proof-step"><strong>($\subseteq$):</strong> If $y \in (K_1+K_2)^*$, taking $x_2=0$ implies $y \in K_1^*$; taking $x_1=0$ implies $y \in K_2^*$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.8 â€” Generalized Inequality Properties</h3>
  <p>Prove reflexivity, antisymmetry, and transitivity of $\preceq_K$ for a proper cone $K$.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Pointedness:</b> Antisymmetry relies on the cone being pointed ($K \cap -K = \{0\}$).</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Reflexive: $0 \in K$. Transitive: $K+K \subseteq K$. Antisymmetric: $y-x \in K$ and $x-y \in K \implies y-x \in K \cap -K = \{0\} \implies x=y$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.9 â€” Voronoi Regions</h3>
  <p>Show $V_i = \{x \mid \|x - x_i\|_2 \le \|x - x_j\|_2 \forall j \neq i\}$ is a polyhedron.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Intersection of Halfspaces:</b> The region is the intersection of halfspaces defined by perpendicular bisectors.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Expand $\|x-x_i\|^2 \le \|x-x_j\|^2$ to get $2(x_j - x_i)^\top x \le \|x_j\|^2 - \|x_i\|^2$. This is a linear inequality. $V_i$ is the intersection of $k-1$ such halfspaces, hence a polyhedron.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.10 â€” Convexity of Norm Cone</h3>
  <p>Show $S = \{(x,t) \mid \|x\| \le t\}$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Epigraph:</b> $S$ is the epigraph of the norm function $f(x)=\|x\|$, which is convex (triangle inequality).</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $u_1, u_2 \in S$. $\lambda u_1 + (1-\lambda)u_2 = (\lambda x_1 + (1-\lambda)x_2, \lambda t_1 + (1-\lambda)t_2)$.
       $\|\lambda x_1 + (1-\lambda)x_2\| \le \lambda\|x_1\| + (1-\lambda)\|x_2\| \le \lambda t_1 + (1-\lambda)t_2$. Thus the combination is in $S$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.11 â€” Convex Hull Properties</h3>
  <p><b>(a)</b> Prove by induction that if $C$ is convex, any convex combination $\sum_{i=1}^k \theta_i x_i$ of points in $C$ lies in $C$ for all $k \ge 2$.</p>
       <p><b>(b)</b> Prove that $\mathrm{conv}(S) = \bigcap \{D \mid S \subseteq D, D \text{ is convex}\}$.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <ul><li><b>Induction on $k$:</b> Reduce a $k$-point combination to a 2-point combination of $x_k$ and a $(k-1)$-point average.</li>
       <li><b>Hull as Intersection:</b> The convex hull is the "smallest" convex set containing $S$.</li></ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>(a) Base Case ($k=2$):</strong> True by definition of convexity.</div>
       <div class="proof-step"><strong>Inductive Step:</strong> Assume true for $k$. Consider $x^* = \sum_{i=1}^{k+1} \theta_i x_i$. If $\theta_{k+1}=1$, $x^*=x_{k+1} \in C$. If $\theta_{k+1} < 1$, let $\alpha = 1-\theta_{k+1} = \sum_{i=1}^k \theta_i$.
       Define $y = \sum_{i=1}^k (\theta_i/\alpha) x_i$. The weights sum to 1, so $y \in C$ by hypothesis.
       Then $x^* = \alpha y + \theta_{k+1} x_{k+1}$. Since $\alpha + \theta_{k+1} = 1$, this is a convex combination of two points in $C$, so $x^* \in C$.</div>
       <div class="proof-step"><strong>(b) Inclusion 1 ($\subseteq$):</strong> Let $D$ be any convex superset of $S$. Since $D$ is convex, it contains all convex combinations of $S$. Thus $\mathrm{conv}(S) \subseteq D$. So $\mathrm{conv}(S) \subseteq \bigcap D$.</div>
       <div class="proof-step"><strong>(b) Inclusion 2 ($\supseteq$):</strong> $\mathrm{conv}(S)$ is itself a convex set containing $S$. Thus it is one of the sets in the intersection. So $\bigcap D \subseteq \mathrm{conv}(S)$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.12 â€” Minkowski Sum of Sets</h3>
  <p>Show that if $X, Y$ are convex, $X+Y$ is convex. Give an example where $X$ is not convex but $X+Y$ is.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Linear Map:</b> Sum is image of product under addition map.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $u, v \in X+Y$. $\lambda u + (1-\lambda)v = \lambda(x_1+y_1) + (1-\lambda)(x_2+y_2) = (\lambda x_1+(1-\lambda)x_2) + (\lambda y_1+(1-\lambda)y_2) \in X+Y$.</div>
       <div class="proof-step">Example: $X=\mathbb{Z}$ (integers), $Y=[0,1]$. $X+Y = \mathbb{R}$ (convex).</div>
  </div>
</div>

<div class="problem">
  <h3>P2.13 â€” Convexity of Thickened Sets</h3>
  <p>Show $C_\varepsilon = \{y \mid \mathrm{dist}(y, C) \le \varepsilon\}$ is convex if $C$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Minkowski Sum:</b> $C_\varepsilon = C + B(0, \varepsilon)$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">$C_\varepsilon$ is the Minkowski sum of $C$ and the ball $B(0, \varepsilon)$. Since both are convex, their sum is convex.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.14 â€” Closure of a Convex Set</h3>
  <p>Show that $\mathrm{cl}(C)$ is convex if $C$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Limits:</b> Convexity inequalities are preserved under limits.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $a, b \in \mathrm{cl}(C)$. There exist sequences $a_k \to a, b_k \to b$ in $C$.
       $z_k = \lambda a_k + (1-\lambda)b_k \in C$.
       $\lim z_k = \lambda a + (1-\lambda)b$. Since limits of points in $C$ are in $\mathrm{cl}(C)$, the combination is in $\mathrm{cl}(C)$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.15 â€” Product of Convex Sets</h3>
  <p>Show $X \times Y$ is convex iff $X$ and $Y$ are convex (assuming non-empty).</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Componentwise:</b> A line in the product projects to lines in components.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">If $X, Y$ convex, $\lambda(x_1, y_1) + (1-\lambda)(x_2, y_2) = (\lambda x_1 + (1-\lambda)x_2, \dots) \in X \times Y$.</div>
       <div class="proof-step">If $X \times Y$ convex, taking $y_1=y_2$ shows $X$ must be convex.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.16 â€” Convexity via Line Intersections</h3>
  <p>Prove that a set $C \subseteq \mathbb{R}^n$ is convex if and only if its intersection with every line is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Reduction to 1D:</b> Convexity is fundamentally a property of line segments. If every 1D slice is valid, the whole set is valid.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>($\Rightarrow$):</strong> Intersection of convex sets ($C$ and a line $L$) is convex.</div>
       <div class="proof-step"><strong>($\Leftarrow$):</strong> Take $x, y \in C$. The line $L$ passing through $x$ and $y$ intersects $C$ in a convex set (by assumption). Thus the segment $[x,y] \subseteq C \cap L \subseteq C$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.17 â€” Midpoint Convexity</h3>
  <p>A set $C$ is <b>midpoint convex</b> if $(a+b)/2 \in C$ for all $a,b \in C$. Show that if $C$ is closed and midpoint convex, it is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Dyadic Rationals:</b> Midpoints allow generating any dyadic fraction $k/2^n$. Closure fills the gaps for all real $\theta$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>Step 1: Dyadics.</strong> By induction, any combination $\lambda a + (1-\lambda)b$ where $\lambda = k/2^n$ is in $C$.</div>
       <div class="proof-step"><strong>Step 2: Density.</strong> Dyadic rationals are dense in $[0,1]$. For any $\theta$, take $\lambda_i \to \theta$ (dyadics).</div>
       <div class="proof-step"><strong>Step 3: Closure.</strong> Since $z_i = \lambda_i a + (1-\lambda_i)b \in C$ and $z_i \to z = \theta a + (1-\theta)b$, and $C$ is closed, $z \in C$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.18 â€” Hyperbolic Sets</h3>
  <p>Show that the set $C = \{x \in \mathbb{R}^n_{++} \mid \prod x_i \ge 1\}$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>AM-GM Inequality:</b> The geometric mean is concave. Alternatively, $\sum \log x_i \ge 0$ defines a superlevel set of a concave function.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $x, y \in C$ and $z = \theta x + (1-\theta)y$.
       By weighted AM-GM on each coordinate: $z_i \ge x_i^\theta y_i^{1-\theta}$.</div>
       <div class="proof-step">Multiply over $i$: $\prod z_i \ge \prod (x_i^\theta y_i^{1-\theta}) = (\prod x_i)^\theta (\prod y_i)^{1-\theta} \ge 1^\theta \cdot 1^{1-\theta} = 1$.</div>
       <div class="proof-step">Thus $z \in C$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.19 â€” Set Classification Challenge</h3>
  <p>Determine which of the following are convex:</p><ol type="a"><li>Slab: $\alpha \le a^\top x \le \beta$</li><li>Wedge: $a_1^\top x \le b_1, a_2^\top x \le b_2$</li><li>Closest to set: $\{x \mid d(x,S) \le d(x,T)\}$</li><li>Translates: $\{x \mid x + S_2 \subseteq S_1\}$ ($S_1$ convex)</li></ol>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Building Blocks:</b> Decompose sets into intersections of halfspaces or use defining properties.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>(a) Convex:</strong> Intersection of two halfspaces ($a^\top x \ge \alpha$ and $a^\top x \le \beta$).</div>
       <div class="proof-step"><strong>(b) Convex:</strong> Intersection of two halfspaces.</div>
       <div class="proof-step"><strong>(c) Not Convex:</strong> Example in $\mathbb{R}$: Closer to $\{-1, 1\}$ than $\{0\}$ is $(-\infty, -0.5] \cup [0.5, \infty)$, which is disconnected.</div>
       <div class="proof-step"><strong>(d) Convex:</strong> $x \in C \iff x + s \in S_1 \ \forall s \in S_2$. For fixed $s$, $\{x \mid x+s \in S_1\}$ is a translate of $S_1$ (convex). $C$ is the intersection of these over all $s \in S_2$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.20 â€” Partial Sum of Convex Sets</h3>
  <p>Let $S_1, S_2 \subseteq \mathbb{R}^{m+n}$. Define the partial sum $S = \{(x, y_1+y_2) \mid (x,y_1) \in S_1, (x,y_2) \in S_2\}$. Show $S$ is convex.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Fiberwise Sum:</b> For each $x$, the slice $S_x$ is the Minkowski sum of slices $(S_1)_x$ and $(S_2)_x$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $z^a = (x^a, y^a), z^b = (x^b, y^b) \in S$.
       $y^a = y_1^a + y_2^a$ with $(x^a, y_i^a) \in S_i$.
       Let $z = \theta z^a + (1-\theta)z^b = (x^\theta, y^\theta)$.
       $x^\theta = \theta x^a + (1-\theta)x^b$.
       $y^\theta = (\theta y_1^a + (1-\theta)y_1^b) + (\theta y_2^a + (1-\theta)y_2^b) =: \tilde y_1 + \tilde y_2$.
       Since $S_i$ are convex, $(x^\theta, \tilde y_i) \in S_i$.
       Thus $z = (x^\theta, \tilde y_1 + \tilde y_2) \in S$.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.21 â€” Perspective of Polyhedra</h3>
  <p>Let $P: \mathbb{R}^{n+1} \to \mathbb{R}^n$ be the perspective map $P(v,t) = v/t$ for $t>0$. Determine $P(C)$ for:</p><ol type="a"><li>$C = \{(v,t) \mid f^\top v + gt = h\}$</li><li>$C = \{(v,t) \mid f^\top v + gt \le h\}$</li></ol>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Projective Geometry:</b> Perspective maps hyperplanes to hyperplanes or halfspaces, depending on whether they pass through the origin.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>(a)</strong> $f^\top (ty) + gt = h \implies t(f^\top y + g) = h$.
       If $h=0$, $f^\top y + g = 0$ (Hyperplane).
       If $h \neq 0$, $t = h/(f^\top y + g) > 0 \implies h(f^\top y + g) > 0$ (Open Halfspace).</div>
       <div class="proof-step"><strong>(b)</strong> $t(f^\top y + g) \le h$.
       If $h>0$, always feasible (whole space).
       If $h=0$, $f^\top y + g \le 0$ (Halfspace).
       If $h<0$, $f^\top y + g < 0$ (Open Halfspace).</div>
  </div>
</div>

<div class="problem">
  <h3>P2.22 â€” Invertible Linear-Fractional Functions</h3>
  <p>Let $f(x) = (Ax+b)/(c^\top x+d)$ with $\mathrm{dom}(f) = \{x \mid c^\top x+d > 0\}$. Show that if $\begin{bmatrix} A & b \\ c^\top & d \end{bmatrix}$ is nonsingular, then $f$ is invertible and $f^{-1}$ is linear-fractional.</p>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Homogeneous Coordinates:</b> $y = f(x) \iff (y,1) \sim Q(x,1)$ projectively. Inverting $Q$ inverts the map.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">Let $Q = \begin{bmatrix} A & b \\ c^\top & d \end{bmatrix}$ and $y = u/t$ where $\begin{bmatrix} u \\ t \end{bmatrix} = Q \begin{bmatrix} x \\ 1 \end{bmatrix}$.
       Then $Q \begin{bmatrix} x \\ 1 \end{bmatrix} = t \begin{bmatrix} y \\ 1 \end{bmatrix}$.
       Invert: $\begin{bmatrix} x \\ 1 \end{bmatrix} = t Q^{-1} \begin{bmatrix} y \\ 1 \end{bmatrix}$.
       Let $Q^{-1} = \begin{bmatrix} E & f \\ g^\top & h \end{bmatrix}$.
       Then $x = t(Ey+f)$ and $1 = t(g^\top y+h)$.
       Thus $x = (Ey+f)/(g^\top y+h)$. This is linear-fractional.</div>
  </div>
</div>

<div class="problem">
  <h3>P2.23 â€” Preimages of Sets under LF Maps</h3>
  <p>Let $f(x) = (Ax+b)/(c^\top x+d)$. Find the preimage $f^{-1}(C)$ for:</p><ol type="a"><li>Halfspace: $C = \{y \mid g^\top y \le h\}$</li><li>Ellipsoid: $C = \{y \mid y^\top P y \le 1\}$</li></ol>
  <div class="recap-box">
    <h4><i data-feather="key"></i> Recap & Key Concepts</h4>
    <p><b>Substitution:</b> Substitute $y = f(x)$ and clear the denominator $c^\top x + d > 0$.</p>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step"><strong>(a)</strong> $g^\top \frac{Ax+b}{c^\top x+d} \le h \iff g^\top(Ax+b) \le h(c^\top x+d) \iff (A^\top g - h c)^\top x \le hd - g^\top b$. (Halfspace).</div>
       <div class="proof-step"><strong>(b)</strong> $\frac{(Ax+b)^\top}{c^\top x+d} P \frac{Ax+b}{c^\top x+d} \le 1 \iff (Ax+b)^\top P (Ax+b) \le (c^\top x+d)^2$. (Quadratic/SOC constraint).</div>
  </div>
</div>
    </section>


<section class="section-card" id="section-10">
      <h2>10. Readings & Resources</h2>
      <ul class="link-list">
        <li><strong>Required Reading:</strong> Boyd & Vandenberghe, Chapter 2 (Convex Sets).</li>
        <li><strong>Supplementary:</strong> Rockafellar, <em>Convex Analysis</em>, Sections 1-6 (for rigorous topology and relative interior).</li>
        <li><strong>Interactive:</strong> Explore the <a href="#widget-convex-geometry-lab">Convex Geometry Lab</a> to build intuition for set operations.</li>
      </ul>
    </section>


<footer class="site-footer">
      <div class="container">
        <p>Â© <span id="year"></a> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- Widget Loaders -->
  <script type="module">
    import { initEllipsoidExplorer } from './widgets/js/ellipsoid-explorer.js';
    initEllipsoidExplorer('widget-ellipsoid-explorer');
  </script>
  <script type="module">
    import { initPolyhedronVisualizer } from './widgets/js/polyhedron-visualizer.js';
    initPolyhedronVisualizer('widget-polyhedron-visualizer');
  </script>
  <script type="module">
    import { initConvexGeometryLab } from './widgets/js/convex-geometry-lab.js';
    initConvexGeometryLab('widget-convex-geometry-lab');
  </script>
  <script type="module">
    import { initSeparatingHyperplane } from './widgets/js/separating-hyperplane.js';
    initSeparatingHyperplane('widget-separating-hyperplane');
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
