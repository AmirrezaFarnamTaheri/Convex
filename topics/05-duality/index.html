<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>05. Duality: Lagrangian, KKT, Strong Duality ‚Äî Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
</head>
<body>
  <!-- Header with navigation -->
  <header class="site-header">
    <div class="container header-inner">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html">All Lectures</a>
        <a href="#widgets">Interactive</a>
        <a href="#readings">Readings</a>
      </nav>
    </div>
  </header>

  <!-- Main content -->
  <main class="container" style="padding: 32px 0 60px;">
    <!-- Lecture header -->
    <article class="section-card" style="margin-bottom: 32px;">
      <h1 style="margin-top: 0;">05. Duality: Lagrangian, KKT, Strong Duality</h1>
      <div class="meta">
        Date: 2025-11-18 ¬∑ Duration: 90 min ¬∑ Tags: duality, theory, KKT, Lagrangian
      </div>

      <!-- Brief introduction -->
      <section style="margin-top: 16px;">
        <p><strong>Overview:</strong> This lecture covers duality theory in convex optimization‚Äîthe mathematical framework that connects every optimization problem to a "dual" problem, establishes optimality conditions, and provides the foundation for modern algorithms. We develop the Lagrangian function, prove weak and strong duality theorems, derive the KKT conditions, and explore applications across problem classes.</p>
        <p><strong>Prerequisites:</strong> <a href="../04-convex-opt-problems/index.html">Lecture 04</a> (convex optimization problem formulations), <a href="../03-convex-functions/index.html">Lecture 03</a> (convex functions and subgradients)</p>
      </section>
    </article>

    <!-- Learning objectives -->
    <section class="section-card" style="margin-bottom: 32px;">
      <h2>Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul style="line-height: 1.8;">
        <li>Construct the Lagrangian function and derive the dual function for any convex problem</li>
        <li>Formulate the dual problem and understand the primal-dual relationship</li>
        <li>Apply weak duality to obtain lower bounds on optimal values</li>
        <li>State and prove strong duality under Slater's condition</li>
        <li>Derive and verify the Karush-Kuhn-Tucker (KKT) optimality conditions</li>
        <li>Use complementary slackness to analyze solution structure</li>
        <li>Interpret dual variables as shadow prices and sensitivity coefficients</li>
        <li>Formulate duals for LP, QP, and SDP problems</li>
      </ul>
    </section>

    <!-- Section 1: The Lagrangian and Dual Function -->
    <section class="section-card" id="section-1">
      <h2>1. The Lagrangian and Dual Function</h2>

      <h3>1.1 The Primal Problem</h3>
      <p>Consider the <strong>primal problem</strong> in standard form:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <p style="margin: 0;">
          $
          \begin{aligned}
          \text{minimize} \quad & f_0(x) \\
          \text{subject to} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
          & h_j(x) = 0, \quad j = 1, \dots, p
          \end{aligned}
          $
        </p>
      </div>

      <p>with variable $x \in \mathbb{R}^n$, optimal value $p^*$, and feasible set $\mathcal{F}$.</p>

      <h3>1.2 The Lagrangian Function</h3>
      <p>The <a href="#" class="definition-link">Lagrangian</a> $L: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is defined as:</p>

      <p style="text-align: center;">
        $
        L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $
      </p>

      <p>where:</p>
      <ul>
        <li>$\lambda \in \mathbb{R}^m$ are the <a href="#" class="definition-link">dual variables</a> (or <strong>Lagrange multipliers</strong>) for inequality constraints</li>
        <li>$\nu \in \mathbb{R}^p$ are the dual variables for equality constraints</li>
        <li>The domain is $\mathcal{D} = \text{dom}(f_0) \cap \bigcap_{i=1}^m \text{dom}(f_i) \cap \bigcap_{j=1}^p \text{dom}(h_j)$</li>
      </ul>

      <p><strong>Intuition:</strong> The Lagrangian augments the objective with weighted constraint violations. It transforms a constrained problem into an unconstrained one by penalizing constraint violations.</p>

      <h3>1.3 The Lagrange Dual Function</h3>
      <p>The <a href="#" class="definition-link">Lagrange dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is:</p>

      <p style="text-align: center;">
        $
        g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) = \inf_{x \in \mathcal{D}} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $
      </p>

      <div class="proof-box">
        <h4>Theorem: Concavity of the Dual Function</h4>
        <p><strong>Statement:</strong> The dual function $g(\lambda, \nu)$ is concave, even if the primal problem is not convex.</p>

        <div class="proof-step">
          <strong>Proof:</strong> For any $(\lambda_1, \nu_1)$ and $(\lambda_2, \nu_2)$, and $\theta \in [0, 1]$:
          $
          \begin{aligned}
          g(\theta \lambda_1 + (1-\theta) \lambda_2, \theta \nu_1 + (1-\theta) \nu_2) &= \inf_x L(x, \theta \lambda_1 + (1-\theta) \lambda_2, \theta \nu_1 + (1-\theta) \nu_2) \\
          &= \inf_x \left[ \theta L(x, \lambda_1, \nu_1) + (1-\theta) L(x, \lambda_2, \nu_2) \right] \\
          &\ge \theta \inf_x L(x, \lambda_1, \nu_1) + (1-\theta) \inf_x L(x, \lambda_2, \nu_2) \\
          &= \theta g(\lambda_1, \nu_1) + (1-\theta) g(\lambda_2, \nu_2)
          \end{aligned}
          $
          Thus $g$ is concave (pointwise infimum of affine functions in $(\lambda, \nu)$).
        </div>
      </div>

      <h3>1.4 Computing the Dual Function</h3>
      <p>To compute $g(\lambda, \nu)$, we minimize the Lagrangian over $x$:</p>
      <ol>
        <li>Form $L(x, \lambda, \nu)$</li>
        <li>Compute $\inf_x L(x, \lambda, \nu)$ (often by setting $\nabla_x L = 0$ if differentiable)</li>
        <li>The result is $g(\lambda, \nu)$</li>
      </ol>

      <p><strong>Example:</strong> For an LP minimize $c^T x$ s.t. $Ax = b$, $x \ge 0$:</p>
      <p style="text-align: center;">
        $
        L(x, \lambda, \nu) = c^\top x - \lambda^\top x + \nu^\top (Ax - b)
        $
      </p>
      <p>Taking $\inf_x$: if $c - \lambda + A^\top \nu \ne 0$, the infimum is $-\infty$. Otherwise, $g(\lambda, \nu) = -b^\top \nu$.</p>

      <figure style="margin: 16px 0; text-align: center;">
        <img src="../../static/assets/topics/05-duality/saddle-point-illustration.png" alt="Illustration of a saddle point" style="max-width: 500px; height: auto; border-radius: 8px;" />
        <figcaption style="font-size: 13px; color: var(--muted); margin-top: 8px;">
          The Lagrangian exhibits a saddle point structure: minimized over $x$ (primal variables), maximized over $\lambda, \nu$ (dual variables). Source: Statistical Odds & Ends.
        </figcaption>
      </figure>

      <!-- Widget 1: Lagrangian Explainer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Lagrangian Explainer</h3>
        <p><strong>Purpose:</strong> Visualize how the Lagrangian function $L(x, \lambda, \nu)$ changes as dual variables $\lambda, \nu$ vary.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Adjust $\lambda$ (penalty on inequality constraints) and see Lagrangian surface update</li>
          <li>Observe the infimum $g(\lambda, \nu)$ as a function of dual variables</li>
          <li>Understand the saddle-point structure</li>
        </ul>
        <div id="widget-1" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 2: The Dual Problem and Weak Duality -->
    <section class="section-card" id="section-2">
      <h2>2. The Dual Problem and Weak Duality</h2>

      <h3>2.1 Lower Bound Property</h3>
      <div class="proof-box">
        <h4>Lemma: Dual Function Provides Lower Bound</h4>
        <p><strong>Statement:</strong> For any $\lambda \succeq 0$ (componentwise) and any $\nu$, we have $g(\lambda, \nu) \le p^*$.</p>

        <div class="proof-step">
          <strong>Proof:</strong> Let $\tilde{x}$ be any feasible point for the primal. Then $f_i(\tilde{x}) \le 0$ and $h_j(\tilde{x}) = 0$. Thus:
          $
          \begin{aligned}
          L(\tilde{x}, \lambda, \nu) &= f_0(\tilde{x}) + \sum_{i=1}^m \lambda_i f_i(\tilde{x}) + \sum_{j=1}^p \nu_j h_j(\tilde{x}) \\
          &\le f_0(\tilde{x}) \quad \text{(since $\lambda_i \ge 0$ and $f_i(\tilde{x}) \le 0$)}
          \end{aligned}
          $
          Taking the infimum over all $x$ (including feasible $\tilde{x}$):
          $
          g(\lambda, \nu) = \inf_x L(x, \lambda, \nu) \le L(\tilde{x}, \lambda, \nu) \le f_0(\tilde{x})
          $
          This holds for all feasible $\tilde{x}$, so $g(\lambda, \nu) \le p^*$.
        </div>
      </div>

      <h3>2.2 The Dual Problem</h3>
      <p>The <a href="#" class="definition-link">Lagrange dual problem</a> is:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <p style="margin: 0;">
          $
          \begin{aligned}
          \text{maximize} \quad & g(\lambda, \nu) \\
          \text{subject to} \quad & \lambda \succeq 0
          \end{aligned}
          $
        </p>
      </div>

      <p>with dual optimal value $d^*$. Key observations:</p>
      <ul>
        <li>The dual is always a <strong>concave maximization</strong> (equivalently, convex minimization of $-g$)</li>
        <li>The dual is convex even if the primal is not convex</li>
        <li>Variables: $\lambda \in \mathbb{R}^m$, $\nu \in \mathbb{R}^p$</li>
      </ul>

      <h3>2.3 Weak Duality Theorem</h3>
      <div class="proof-box">
        <h4>Theorem: <a href="#" class="definition-link">Weak Duality</a></h4>
        <p><strong>Statement:</strong> $d^* \le p^*$ always holds.</p>

        <div class="proof-step">
          <strong>Proof:</strong> This is immediate from the lower bound property: for any dual feasible $(\lambda, \nu)$ with $\lambda \succeq 0$, we have $g(\lambda, \nu) \le p^*$. Taking the supremum over all such $(\lambda, \nu)$ gives $d^* \le p^*$.
        </div>
      </div>

      <h3>2.4 The Duality Gap</h3>
      <p>The <a href="#" class="definition-link">duality gap</a> is $p^* - d^* \ge 0$. It measures how far the best dual bound is from the primal optimum.</p>
      <ul>
        <li>If $p^* - d^* = 0$, we have <a href="#" class="definition-link">strong duality</a></li>
        <li>If $p^* - d^* > 0$, we have a <strong>duality gap</strong></li>
      </ul>

      <h3>2.5 Max-Min Interpretation</h3>
      <p>Weak duality can be stated as:</p>
      <p style="text-align: center;">
        $
        \sup_{\lambda \succeq 0, \nu} \inf_x L(x, \lambda, \nu) \le \inf_x \sup_{\lambda \succeq 0, \nu} L(x, \lambda, \nu)
        $
      </p>
      <p>Strong duality means these are equal (saddle point property).</p>

      <!-- Widget 2: Duality Visualizer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Primal-Dual Visualizer</h3>
        <p><strong>Purpose:</strong> Visualize primal and dual problems for a 2D LP, showing feasible regions and optimal points.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>See primal feasible region (polyhedron) and dual feasible region</li>
          <li>Observe primal optimal $x^*$ and dual optimal $(\lambda^*, \nu^*)$</li>
          <li>Verify strong duality: $c^\top x^* = b^\top \nu^*$</li>
        </ul>
        <div id="widget-2" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>

      <!-- Widget 4: Weak vs Strong Duality Race -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Duality Gap Animation</h3>
        <p><strong>Purpose:</strong> Animate convergence of primal and dual objectives, showing duality gap shrinking.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Watch primal objective $f_0(x^{(k)})$ descend and dual $g(\lambda^{(k)}, \nu^{(k)})$ ascend</li>
          <li>See the gap $p^* - d^*$ close to zero (strong duality)</li>
          <li>Explore cases where gap remains (weak duality)</li>
        </ul>
        <div id="widget-4" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 3: Strong Duality and Slater's Condition -->
    <section class="section-card" id="section-3">
      <h2>3. Strong Duality and Slater's Condition</h2>

      <h3>3.1 When Does Strong Duality Hold?</h3>
      <p>Strong duality ($p^* = d^*$) does not always hold. Example: Consider a non-convex problem where we break the assumptions.</p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad x^3 \quad \text{s.t.} \quad x \ge 1
        $
      </p>
      <p>The primal is easy: $x^* = 1, p^* = 1$. The dual function is $g(\lambda) = \inf_x (x^3 - \lambda(x-1))$.
      For any $\lambda \ge 0$, as $x \to -\infty$, $x^3 - \lambda x \to -\infty$. Thus $g(\lambda) = -\infty$.
      So $d^* = -\infty$. The duality gap is $\infty$. This happens because $f_0(x)=x^3$ is not convex on $\mathbb{R}$ (only on $\mathbb{R}_+$), and the domain isn't restricted.</p>

      <div class="insight">
        <h4>üí° Geometric Interpretation of Duality</h4>
        <p>We can visualize the primal and dual problems using a <b>hyperplane lifting</b> argument in the space of (constraint value, objective value). Let $\mathcal{G} = \{(f_1(x), \dots, f_m(x), f_0(x)) \mid x \in \mathcal{D}\}$.</p>
        <ul>
          <li>The primal problem is finding the point in $\mathcal{G}$ that intersects the vertical axis ($u=0$) at the lowest height.</li>
          <li>The dual problem corresponds to finding a non-vertical supporting hyperplane to the set $\mathcal{A} = \mathcal{G} + \mathbb{R}^m_+ \times \mathbb{R}_+$ that passes below the set.</li>
          <li>The intercept of this hyperplane with the vertical axis is the dual value $g(\lambda)$.</li>
          <li><b>Strong Duality</b> holds if the supporting hyperplane at the optimal point is non-vertical. This non-verticality is exactly what Slater's condition ensures!</li>
        </ul>
      </div>

      <p>For convex problems, we have a powerful condition:</p>

      <div class="proof-box">
        <h4>Theorem: <a href="#" class="definition-link">Slater's Condition</a> for Strong Duality</h4>
        <p><strong>Statement:</strong> For a convex problem (convex $f_0, f_i$ and affine $h_j$), if there exists a point $\tilde{x} \in \text{relint}(\mathcal{D})$ such that:</p>
        <ul>
          <li>$f_i(\tilde{x}) < 0$ for $i = 1, \dots, m$ (strict inequality)</li>
          <li>$h_j(\tilde{x}) = 0$ for $j = 1, \dots, p$</li>
        </ul>
        <p>then <strong>strong duality</strong> holds: $p^* = d^*$.</p>

        <div class="proof-step">
          <strong>Step 1: Define the set of achievable values.</strong>
          Consider the set of values $(\text{constraint}, \text{objective})$ in $\mathbb{R}^{m+1}$:
          $$ \mathcal{A} = \{(u, t) \mid \exists x, f_i(x) \le u_i, f_0(x) \le t\} $$
          Since $f_i$ are convex, this set $\mathcal{A}$ is convex.
        </div>

        <div class="proof-step">
          <strong>Step 2: Apply Separating Hyperplane Theorem.</strong>
          Assume $d^* < p^*$ (duality gap). We want to find a contradiction.
          The point $(0, p^*)$ is on the boundary of $\mathcal{A}$. But strictly speaking, $(0, d^*)$ is not in $\mathcal{A}$ if we assume the gap.
          Let's separate $\mathcal{A}$ from the ray $(-\infty, d^*)$ in the objective dimension?
          Standard proof: Consider the set $\mathcal{B} = \{(0, t) \mid t < p^*\}$. This is disjoint from $\mathcal{A}$.
          By the Separating Hyperplane Theorem, there exists a hyperplane $(\lambda, \mu)$ separating $\mathcal{A}$ and $\mathcal{B}$.
          $$ \lambda^\top u + \mu t \ge \alpha \quad \forall (u, t) \in \mathcal{A} $$
          $$ \lambda^\top \cdot 0 + \mu t < \alpha \quad \forall t < p^* $$
        </div>

        <div class="proof-step">
          <strong>Step 3: Analyze Dual Variables.</strong>
          From the second inequality, $\mu \ge 0$. Also $\lambda \ge 0$ (otherwise we could send $u_i \to \infty$ in $\mathcal{A}$).
          If $\mu > 0$, we can divide by $\mu$ to recover the standard Lagrangian multiplier $\tilde{\lambda} = \lambda/\mu$. Then $\inf L(x, \tilde{\lambda}) \ge \alpha/\mu \approx p^*$, implying $d^* \ge p^*$, so $d^* = p^*$.
        </div>

        <div class="proof-step">
          <strong>Step 4: Use Slater's Point to ensure $\mu > 0$.</strong>
          Suppose for contradiction that $\mu = 0$. Then the separation inequality becomes $\lambda^\top u \ge 0$ for all $u \in \mathcal{A}$.
          Applying this to the Slater point $\tilde{x}$: let $\tilde{u}_i = f_i(\tilde{x})$ and $\tilde{t} = f_0(\tilde{x})$. Then $(\tilde{u}, \tilde{t}) \in \mathcal{A}$.
          The inequality implies $\sum_{i=1}^m \lambda_i f_i(\tilde{x}) \ge 0$.
          <br>However, we know:
          <ul>
            <li>$\lambda \succeq 0$ and $\lambda \neq 0$ (since $(\lambda, \mu) \neq 0$ and $\mu=0$).</li>
            <li>$f_i(\tilde{x}) < 0$ for all $i$ (strictly feasible).</li>
          </ul>
          Since $\lambda$ has at least one positive component $\lambda_k > 0$, and $f_k(\tilde{x}) < 0$, the term $\lambda_k f_k(\tilde{x})$ is strictly negative. All other terms are non-positive.
          Thus, $\sum \lambda_i f_i(\tilde{x}) < 0$.
          <br>This contradicts $\sum \lambda_i f_i(\tilde{x}) \ge 0$. Therefore, the assumption $\mu=0$ must be false.
          <br>Conclusion: $\mu > 0$, which allows us to normalize the dual variables and prove $p^* = d^*$.
        </div>

        <div class="insight">
          <h4>Why Interior Points Matter</h4>
          <p>Slater's condition requires a point in the <b>relative interior</b> of the feasible set. Geometrically, this ensures the feasible set has "volume" and doesn't collapse into a lower-dimensional degenerate shape where the supporting hyperplane could become vertical ($\mu=0$). A vertical hyperplane corresponds to an infinite dual value or a gap, signifying that the constraints are "infinitely hard" to satisfy in a differential sense.</p>
        </div>
      </div>

      <h3>3.2 Example: Strong Duality for LP</h3>
      <p>Consider the LP:</p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad c^\top x \quad \text{s.t.} \quad Ax = b, \; x \ge 0
        $
      </p>
      <p>The dual is:</p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad b^\top \nu \quad \text{s.t.} \quad A^\top \nu \preceq c
        $
      </p>
      <p>By LP duality theory (a special case of convex duality), strong duality holds if both are feasible. The geometric proof relies on polyhedral separation (<a href="../02-convex-sets/index.html">Lecture 02</a>).</p>
    </section>

    <!-- Section 4: KKT Optimality Conditions -->
    <section class="section-card" id="section-4">
      <h2>4. Karush-Kuhn-Tucker (KKT) Optimality Conditions</h2>

      <h3>4.1 Motivation</h3>
      <p>The <strong>KKT conditions</strong> provide necessary (and for convex problems, sufficient) conditions for a point to be optimal. They generalize the Lagrange multiplier conditions from calculus.</p>

      <h3>4.2 The KKT Conditions</h3>
      <p>Let $x^*$ be a candidate optimal point, and $(\lambda^*, \nu^*)$ be candidate dual variables. The <a href="#" class="definition-link">KKT conditions</a> are:</p>

      <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
        <ol>
          <li><strong>Stationarity:</strong> $\nabla f_0(x^*) + \sum_{i=1}^m \lambda_i^* \nabla f_i(x^*) + \sum_{j=1}^p \nu_j^* \nabla h_j(x^*) = 0$</li>
          <li><strong>Primal feasibility:</strong> $f_i(x^*) \le 0$, $h_j(x^*) = 0$</li>
          <li><strong>Dual feasibility:</strong> $\lambda^* \succeq 0$</li>
          <li><strong>Complementary slackness:</strong> $\lambda_i^* f_i(x^*) = 0$ for all $i$</li>
        </ol>
      </div>

      <h3>4.3 Complementary Slackness</h3>
      <p>The complementary slackness condition $\lambda_i^* f_i(x^*) = 0$ has a powerful interpretation:</p>
      <ul>
        <li>If $\lambda_i^* > 0$, then $f_i(x^*) = 0$ (constraint $i$ is <strong>active</strong>)</li>
        <li>If $f_i(x^*) < 0$ (constraint $i$ is <strong>inactive</strong>), then $\lambda_i^* = 0$</li>
      </ul>
      <p><strong>Intuition:</strong> Non-zero dual variables correspond to binding constraints. Slack constraints have zero dual variables.</p>

      <div class="proof-box">
        <h4>Theorem: KKT Conditions for Convex Problems</h4>
        <p><strong>Statement:</strong> For a convex problem with differentiable $f_0, f_i, h_j$, if strong duality holds and $x^*, (\lambda^*, \nu^*)$ are primal and dual optimal, then they satisfy the KKT conditions. Conversely, if the KKT conditions hold for some $(x^*, \lambda^*, \nu^*)$, then $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal.</p>

        <div class="proof-step">
          <strong>Necessity (‚áí):</strong> Suppose $x^*$ is primal optimal and strong duality holds. Then $x^*$ minimizes $L(x, \lambda^*, \nu^*)$, so $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$ (stationarity). Primal and dual feasibility follow by definition. Complementary slackness follows from $g(\lambda^*, \nu^*) = f_0(x^*)$ at optimality.
        </div>

        <div class="proof-step">
          <strong>Sufficiency (‚áê):</strong> Suppose $(x^*, \lambda^*, \nu^*)$ satisfy KKT. Then:
          $
          \begin{aligned}
          g(\lambda^*, \nu^*) &= \inf_x L(x, \lambda^*, \nu^*) \\
          &\le L(x^*, \lambda^*, \nu^*) \quad \text{(by definition of inf)} \\
          &= f_0(x^*) + \sum_i \lambda_i^* f_i(x^*) + \sum_j \nu_j^* h_j(x^*) \\
          &= f_0(x^*) \quad \text{(complementary slackness and $h_j(x^*) = 0$)}
          \end{aligned}
          $
          By weak duality, $g(\lambda^*, \nu^*) \le p^*$. But $f_0(x^*) \ge p^*$ (since $x^*$ is feasible). Thus $g(\lambda^*, \nu^*) = f_0(x^*) = p^* = d^*$, so $x^*$ is optimal.
        </div>
      </div>

      <h3>4.4 Using KKT to Solve Problems</h3>
      <p>For small problems, we can solve the KKT system directly:</p>
      <ol>
        <li>Write out the stationarity condition: $\nabla_x L = 0$</li>
        <li>Write primal and dual feasibility</li>
        <li>Write complementary slackness</li>
        <li>Solve the resulting system of equations and inequalities</li>
      </ol>

      <!-- Widget 3: KKT Condition Checker -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: KKT Condition Checker</h3>
        <p><strong>Purpose:</strong> Verify which KKT conditions are satisfied for a candidate solution.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Input candidate $x^*$, $\lambda^*$, $\nu^*$ for a simple problem</li>
          <li>Check stationarity, feasibility, complementary slackness individually</li>
          <li>Get feedback on which conditions fail (if any)</li>
        </ul>
        <div id="widget-3" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>

      <!-- Widget 6: Complementary Slackness Explorer -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Complementary Slackness Explorer</h3>
        <p><strong>Purpose:</strong> Interactive demonstration of complementary slackness for a 2D LP.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Visualize constraints: active (binding) vs inactive (slack)</li>
          <li>Display $\lambda_i^*$ for each constraint</li>
          <li>Verify $\lambda_i^* f_i(x^*) = 0$ for all $i$</li>
        </ul>
        <div id="widget-6" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 5: Perturbation and Sensitivity Analysis -->
    <section class="section-card" id="section-5">
      <h2>5. Perturbation and Sensitivity Analysis</h2>

      <h3>5.1 Perturbed Problem</h3>
      <p>Consider perturbing the RHS of constraints:</p>
      <p style="text-align: center;">
        $
        \begin{aligned}
        \text{minimize} \quad & f_0(x) \\
        \text{subject to} \quad & f_i(x) \le u_i, \quad i = 1, \dots, m \\
        & h_j(x) = v_j, \quad j = 1, \dots, p
        \end{aligned}
        $
      </p>
      <p>Let $p^*(u, v)$ be the optimal value as a function of $(u, v)$. The unperturbed problem has $(u, v) = (0, 0)$.</p>

      <div class="proof-box">
        <h4>Theorem: Sensitivity via Dual Variables</h4>
        <p><strong>Statement:</strong> If strong duality holds and $(\lambda^*, \nu^*)$ is dual optimal, then:</p>
        <p style="text-align: center;">
          $
          \lambda_i^* = -\frac{\partial p^*}{\partial u_i}\bigg|_{u=0}, \quad \nu_j^* = -\frac{\partial p^*}{\partial v_j}\bigg|_{v=0}
          $
        </p>
        <p>(assuming differentiability)</p>

        <div class="proof-step">
          <strong>Interpretation:</strong> The dual variable $\lambda_i^*$ measures the rate of change of the optimal value with respect to constraint $i$. This is the <strong>shadow price</strong> of constraint $i$.
        </div>

        <div class="proof-step">
          <strong>Economic Interpretation:</strong> In resource allocation, $\lambda_i^*$ is the marginal value of relaxing constraint $i$ by one unit. A large $\lambda_i^*$ indicates that constraint $i$ is "expensive" (tightly binding).
        </div>
      </div>

      <h3>5.2 Example: Water Filling</h3>
      <p>In communication systems, "water filling" allocates power across channels. The dual variable represents the "water level" (Lagrange multiplier), and active constraints correspond to filled channels.</p>

      <!-- Widget 5: Shadow Prices & Sensitivity -->
      <div style="margin: 24px 0; padding: 16px; background: var(--panel); border: 1px solid var(--border); border-radius: 10px;">
        <h3 style="margin-top: 0;">Interactive: Shadow Prices & Sensitivity Analysis</h3>
        <p><strong>Purpose:</strong> Perturb constraints and observe how optimal value $p^*(u)$ changes; verify $\lambda^* = -\nabla p^*(0)$.</p>
        <ul style="font-size: 14px; line-height: 1.6;">
          <li>Adjust RHS $u_i$ of constraint $i$ and see $p^*(u)$ update</li>
          <li>Compare numerical derivative to dual variable $\lambda_i^*$</li>
          <li>Understand economic interpretation (shadow price)</li>
        </ul>
        <div id="widget-5" style="width: 100%; height: 400px; position: relative;">
          <!-- Widget will be rendered here -->
        </div>
      </div>
    </section>

    <!-- Section 6: Duality for Specific Problem Classes -->
    <section class="section-card" id="section-6">
      <h2>6. Duality for Specific Problem Classes</h2>

      <h3>6.1 Linear Programming Duality</h3>
      <p><strong>Primal:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad c^\top x \quad \text{s.t.} \quad Ax = b, \; x \ge 0
        $
      </p>

      <p><strong>Dual:</strong></p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad b^\top \nu \quad \text{s.t.} \quad A^\top \nu \preceq c
        $
      </p>

      <p><strong>Key properties:</strong></p>
      <ul>
        <li>Strong duality holds if both are feasible</li>
        <li>Dual of dual is primal (symmetric duality)</li>
        <li>Complementary slackness: $(c - A^\top \nu^*)^\top x^* = 0$</li>
      </ul>

      <h3>6.2 Quadratic Programming Duality</h3>
      <p><strong>Primal QP:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad \frac{1}{2} x^\top P x + q^\top x \quad \text{s.t.} \quad Ax = b, \; x \ge 0
        $
      </p>
      <p>where $P \succeq 0$.</p>

      <p><strong>Dual QP:</strong></p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad -\frac{1}{2} \nu^\top A P^{-1} A^\top \nu - (q + P^{-1} A^\top \nu)^\top x^* + b^\top \nu
        $
      </p>
      <p>(more complex; derived via Lagrangian).</p>

      <h3>6.3 Semidefinite Programming Duality</h3>
      <p><strong>Primal SDP:</strong></p>
      <p style="text-align: center;">
        $
        \text{minimize} \quad \text{tr}(C X) \quad \text{s.t.} \quad \text{tr}(A_i X) = b_i, \; X \succeq 0
        $
      </p>

      <p><strong>Dual SDP:</strong></p>
      <p style="text-align: center;">
        $
        \text{maximize} \quad b^\top y \quad \text{s.t.} \quad \sum_{i=1}^p y_i A_i + S = C, \; S \succeq 0
        $
      </p>

      <p><strong>Properties:</strong></p>
      <ul>
        <li>Weak duality always holds</li>
        <li>Strong duality holds under Slater's condition</li>
        <li>Complementary slackness: $X^* S^* = 0$ (matrix product)</li>
      </ul>

      <h3>6.4 Conic Duality</h3>
      <p>General conic programs have dual cones (see <a href="../02-convex-sets/index.html">Lecture 02</a> for the definition of dual cones). For a cone $K$ and its dual $K^*$:</p>
      <p style="text-align: center;">
        $
        \text{Primal: } \min c^\top x \text{ s.t. } Ax = b, \; x \in K
        $
      </p>
      <p style="text-align: center;">
        $
        \text{Dual: } \max b^\top \nu \text{ s.t. } c - A^\top \nu \in K^*
        $
      </p>
    </section>

    <!-- Section 7: Examples and Applications -->
    <section class="section-card" id="section-7">
      <h2>7. Examples and Applications</h2>

      <h3>7.1 Support Vector Machines (SVM)</h3>
      <p>The primal SVM problem (soft margin) is:</p>
      <p style="text-align: center;">
        $
        \min_{w, b, \xi} \frac{1}{2} \|w\|_2^2 + C \sum_i \xi_i \quad \text{s.t.} \quad y_i (w^\top x_i + b) \ge 1 - \xi_i, \; \xi_i \ge 0
        $
      </p>

      <p>The dual SVM is:</p>
      <p style="text-align: center;">
        $
        \max_\alpha \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j \quad \text{s.t.} \quad 0 \le \alpha_i \le C, \; \sum_i \alpha_i y_i = 0
        $
      </p>

      <p>The dual formulation enables the "kernel trick" for nonlinear classification.</p>

      <h3>7.2 Minimum-Volume Ellipsoid</h3>
      <p>Finding the minimum-volume ellipsoid enclosing points has a dual interpretation related to optimal experimental design.</p>

      <h3>7.3 Network Flow</h3>
      <p>The max-flow min-cut theorem is a consequence of LP duality applied to network flow problems.</p>
    </section>

    <!-- Readings -->
    <section class="section-card" id="readings" style="margin-bottom: 32px;">
      <h2>9. Readings & Resources</h2>
      <ul class="link-list">
        <li><strong>Boyd & Vandenberghe, Convex Optimization:</strong> Chapter 5 ‚Äî Duality</li>
        <li><strong>Bertsekas, Convex Optimization Theory:</strong> Chapter 4 ‚Äî Lagrange Multiplier Theory</li>
        <li><strong>Rockafellar, Convex Analysis:</strong> Section 28 ‚Äî Saddle-Functions and Minimax Theory</li>
        <li><strong>Nocedal & Wright, Numerical Optimization:</strong> Chapter 12 ‚Äî Theory of Constrained Optimization</li>
      </ul>
    </section>

    <!-- SECTION 10: PROBLEM SET -->
    <section class="section-card" id="section-10">
      <h2>10. Problem Set & Solutions</h2>
      <p>These problems consolidate the duality theory and provide practice in deriving duals, verifying KKT conditions, and applying sensitivity analysis.</p>

      <!-- Problem 5.1 -->
      <div class="problem">
        <h3>P5.1 ‚Äî Derive the Dual of a Simple QP</h3>
        <p>Consider the QP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \frac{1}{2} x^\top x + c^\top x \quad \text{s.t.} \quad Ax = b
          $
        </p>
        <p><strong>(a)</strong> Form the Lagrangian.</p>
        <p><strong>(b)</strong> Compute the dual function $g(\nu)$.</p>
        <p><strong>(c)</strong> Write the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Conjugate Relation:</b> The dual function of a QP is explicitly derived from the convex conjugate of the quadratic form. Specifically, $\inf_x (\frac{1}{2}x^\top x + c^\top x) = -\frac{1}{2}\|c\|^2$. Adding constraints shifts the linear term.</li>
            <li><b>Unconstrained Dual:</b> Since the primal only has equality constraints, the dual variables $\nu$ are free (unconstrained). The dual problem is an unconstrained concave maximization of a quadratic form.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Lagrangian.</strong>
            $
            L(x, \nu) = \frac{1}{2} x^\top x + c^\top x + \nu^\top (Ax - b)
            $
          </div>

          <div class="proof-step">
            <strong>Part (b): Dual function.</strong> To find $g(\nu) = \inf_x L(x, \nu)$, we minimize over $x$:
            $
            \nabla_x L = x + c + A^\top \nu = 0 \implies x^* = -(c + A^\top \nu)
            $
            Substituting back:
            $
            \begin{aligned}
            g(\nu) &= \frac{1}{2} (c + A^\top \nu)^\top (c + A^\top \nu) + c^\top (-(c + A^\top \nu)) - b^\top \nu \\
            &= -\frac{1}{2} (c + A^\top \nu)^\top (c + A^\top \nu) - b^\top \nu \\
            &= -\frac{1}{2} \|c + A^\top \nu\|_2^2 - b^\top \nu
            \end{aligned}
            $
          </div>

          <div class="proof-step">
            <strong>Part (c): Dual problem.</strong>
            $
            \text{maximize} \quad -\frac{1}{2} \|c + A^\top \nu\|_2^2 - b^\top \nu
            $
            This is an unconstrained concave maximization (or convex minimization of the negative).
          </div>
        </div>
      </div>

      <!-- Problem 5.2 -->
      <div class="problem">
        <h3>P5.2 ‚Äî Verify KKT Conditions for a 2D Problem</h3>
        <p>Consider:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x_1^2 + x_2^2 \quad \text{s.t.} \quad x_1 + x_2 \ge 1, \; x_1, x_2 \ge 0
          $
        </p>
        <p>Verify that $(x_1^*, x_2^*) = (1/2, 1/2)$ with $\lambda^* = (1, 0, 0)$ satisfies the KKT conditions.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Stationarity (Force Balance):</b> The gradient of the objective $\nabla f_0$ is balanced by the forces from active constraints $\nabla f_i$. At the optimum, no net force exists to move the point while staying feasible.</li>
            <li><b>Complementary Slackness Logic:</b> Dual variables act as "switches". If a constraint is loose (inactive), the switch must be off ($\lambda_i=0$). If the switch is on ($\lambda_i > 0$), the constraint must be tight (active).</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Step 1: Reformulate with standard form.</strong> Convert to minimization with $f_0(x) = x_1^2 + x_2^2$, constraints $-x_1 - x_2 \le -1$, $-x_1 \le 0$, $-x_2 \le 0$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Stationarity.</strong> The Lagrangian is:
            $
            L(x, \lambda) = x_1^2 + x_2^2 + \lambda_1 (-x_1 - x_2 + 1) + \lambda_2 (-x_1) + \lambda_3 (-x_2)
            $
            $
            \nabla_x L = \begin{bmatrix} 2x_1 - \lambda_1 - \lambda_2 \\ 2x_2 - \lambda_1 - \lambda_3 \end{bmatrix}
            $
            At $(x^*, \lambda^*) = ((1/2, 1/2), (1, 0, 0))$:
            $
            \nabla_x L = \begin{bmatrix} 2(1/2) - 1 - 0 \\ 2(1/2) - 1 - 0 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Step 3: Primal feasibility.</strong>
            $
            -x_1^* - x_2^* + 1 = -1/2 - 1/2 + 1 = 0 \le 0 \quad \checkmark
            $
            $
            -x_1^* = -1/2 \le 0, \quad -x_2^* = -1/2 \le 0 \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Step 4: Dual feasibility.</strong> $\lambda^* = (1, 0, 0) \succeq 0$ $\checkmark$
          </div>

          <div class="proof-step">
            <strong>Step 5: Complementary slackness.</strong>
            $
            \lambda_1^* (-x_1^* - x_2^* + 1) = 1 \cdot 0 = 0 \quad \checkmark
            $
            $
            \lambda_2^* (-x_1^*) = 0 \cdot (-1/2) = 0, \quad \lambda_3^* (-x_2^*) = 0 \cdot (-1/2) = 0 \quad \checkmark
            $
          </div>

          <div class="proof-step">
            <strong>Conclusion.</strong> All KKT conditions are satisfied, so $(1/2, 1/2)$ is optimal.
          </div>
        </div>
      </div>

      <!-- Problem 5.3 -->
      <div class="problem">
        <h3>P5.3 ‚Äî LP Duality: Derive and Verify</h3>
        <p>Consider the LP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad 3x_1 + 2x_2 \quad \text{s.t.} \quad x_1 + x_2 \ge 4, \; 2x_1 + x_2 \ge 5, \; x_1, x_2 \ge 0
          $
        </p>
        <p><strong>(a)</strong> Derive the dual LP.</p>
        <p><strong>(b)</strong> Solve both primal and dual graphically.</p>
        <p><strong>(c)</strong> Verify strong duality.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Standard LP Dual Construction:</b> The dual of a minimization LP with $\ge$ constraints is a maximization LP with $\le$ constraints. The constraint matrix is transposed ($A \to A^\top$) and the cost/RHS vectors swap roles ($b \leftrightarrow c$).</li>
            <li><b>Strong Duality in LP:</b> For Linear Programs, strong duality holds if either problem is feasible. The only gap occurs in pathological cases where both are infeasible.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Derive dual.</strong> Rewrite in standard form:
            $
          \text{min } c^\top x \text{ s.t. } -A x \le -b, \; x \ge 0
            $
            where $c = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$, $A = \begin{bmatrix} 1 & 1 \\ 2 & 1 \end{bmatrix}$, $b = \begin{bmatrix} 4 \\ 5 \end{bmatrix}$.

            The dual is:
            $
            \text{maximize} \quad 4\lambda_1 + 5\lambda_2
            $
            $
            \text{subject to} \quad \lambda_1 + 2\lambda_2 \le 3, \; \lambda_1 + \lambda_2 \le 2, \; \lambda_1, \lambda_2 \ge 0
            $
          </div>

          <div class="proof-step">
            <strong>Part (b): Graphical solution.</strong>
            <ul>
              <li><strong>Primal:</strong> Plot feasible region $x_1 + x_2 \ge 4$, $2x_1 + x_2 \ge 5$, $x_1, x_2 \ge 0$. Minimize $3x_1 + 2x_2$ at vertex $(1, 3)$ with $p^* = 9$.</li>
              <li><strong>Dual:</strong> Plot feasible region $\lambda_1 + 2\lambda_2 \le 3$, $\lambda_1 + \lambda_2 \le 2$, $\lambda_1, \lambda_2 \ge 0$. Maximize $4\lambda_1 + 5\lambda_2$ at vertex $(1, 1)$ with $d^* = 9$.</li>
            </ul>
          </div>

          <div class="proof-step">
            <strong>Part (c): Verify strong duality.</strong> Since $p^* = d^* = 9$, strong duality holds.
          </div>
        </div>
      </div>

      <!-- Problem 5.4 -->
      <div class="problem">
        <h3>P5.4 ‚Äî Slater's Condition</h3>
        <p>Consider the problem:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x^2 \quad \text{s.t.} \quad (x - 1)^2 \le 0
          $
        </p>
        <p><strong>(a)</strong> Is Slater's condition satisfied?</p>
        <p><strong>(b)</strong> Does strong duality hold?</p>
        <p><strong>(c)</strong> Compute $p^*$ and $d^*$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Slater's Necessity:</b> Slater's condition (strict feasibility) is a sufficient condition for strong duality. When it fails (e.g., the feasible set has no interior), strong duality may break, as seen in this example where $p^* > d^*$.</li>
            <li><b>Constraint Singularity:</b> The constraint $(x-1)^2 \le 0$ describes a single point but has a vanishing gradient at that point. This singularity prevents the dual variable from "pricing" the constraint correctly, leading to a duality gap.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Slater's condition.</strong> The constraint $(x - 1)^2 \le 0$ is satisfied only when $x = 1$ (since squares are nonnegative). There is no point with $(x - 1)^2 < 0$ (strict inequality). Thus, Slater's condition is NOT satisfied.
          </div>

          <div class="proof-step">
            <strong>Part (b): Strong duality.</strong> Without Slater's condition, strong duality may not hold. Let's check.
          </div>

          <div class="proof-step">
            <strong>Part (c): Compute $p^*$ and $d^*$.</strong>
            <ul>
              <li><strong>Primal:</strong> The only feasible point is $x = 1$, so $p^* = 1^2 = 1$.</li>
              <li><strong>Dual:</strong> The Lagrangian is $L(x, \lambda) = x^2 + \lambda (x - 1)^2$. Taking $\inf_x$:
                $
                \nabla_x L = 2x + 2\lambda (x - 1) = 0 \implies x = \frac{\lambda}{\lambda + 1}
                $
                Substituting:
                $
                g(\lambda) = \left(\frac{\lambda}{\lambda + 1}\right)^2 + \lambda \left(\frac{\lambda}{\lambda + 1} - 1\right)^2 = -\frac{\lambda^2}{(\lambda + 1)^2}
                $
                As $\lambda \to \infty$, $g(\lambda) \to -1$. But $g(\lambda) \le 0$ for all $\lambda \ge 0$, so $d^* = 0$.
              </li>
            </ul>
            Thus $p^* = 1 > 0 = d^*$, and there is a duality gap. Strong duality does NOT hold.
          </div>
        </div>
      </div>

      <!-- Problem 5.5 -->
      <div class="problem">
        <h3>P5.5 ‚Äî Sensitivity Analysis: Shadow Prices</h3>
        <p>Consider the LP:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x_1 + x_2 \quad \text{s.t.} \quad x_1 + 2x_2 \ge 3, \; x_1, x_2 \ge 0
          $
        </p>
        <p>The optimal solution is $x^* = (3, 0)$ with $\lambda^* = 1$ for the first constraint.</p>
        <p><strong>(a)</strong> Interpret $\lambda^* = 1$ as a shadow price.</p>
        <p><strong>(b)</strong> Perturb the RHS to $3 + u$ and compute $p^*(u)$ for small $u$.</p>
        <p><strong>(c)</strong> Verify $\frac{dp^*}{du}\big|_{u=0} = -\lambda^*$.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Shadow Prices:</b> The optimal dual variable $\lambda_i^*$ represents the "shadow price" of the $i$-th constraint: it is the rate of improvement in the optimal objective value per unit of relaxation of the constraint.</li>
            <li><b>Sensitivity Formula:</b> The relation $\nabla p^*(0) = -\lambda^*$ quantifies sensitivity. If $\lambda^*$ is large, the constraint is a major bottleneck; relaxing it yields significant gains.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Shadow price interpretation.</strong> $\lambda^* = 1$ means that if we relax the constraint $x_1 + 2x_2 \ge 3$ to $x_1 + 2x_2 \ge 3 - u$ (i.e., perturb RHS by $+u$), the optimal value decreases at rate $\lambda^* = 1$. In other words, each unit decrease in the RHS requirement saves 1 unit of cost.
          </div>

          <div class="proof-step">
            <strong>Part (b): Perturbed problem.</strong>
            $
            \text{minimize} \quad x_1 + x_2 \quad \text{s.t.} \quad x_1 + 2x_2 \ge 3 + u, \; x_1, x_2 \ge 0
            $
            The new optimal solution (for small $u$) is $x^*(u) = (3 + u, 0)$ (moving along the $x_1$ axis), so:
            $
            p^*(u) = (3 + u) + 0 = 3 + u
            $
          </div>

          <div class="proof-step">
            <strong>Part (c): Verify sensitivity.</strong>
            $
            \frac{dp^*}{du}\bigg|_{u=0} = 1
            $
            And indeed, $-\lambda^* = -1 \cdot (-1) = 1$ (note: sign convention depends on how perturbation is defined). The magnitude matches the shadow price.
          </div>
        </div>
      </div>

      <!-- Problem 5.6 -->
      <div class="problem">
        <h3>P5.6 ‚Äî SVM Dual Formulation</h3>
        <p>For the hard-margin SVM:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \frac{1}{2} \|w\|_2^2 \quad \text{s.t.} \quad y_i (w^\top x_i + b) \ge 1, \; i = 1, \dots, n
          $
        </p>
        <p><strong>(a)</strong> Write the Lagrangian.</p>
        <p><strong>(b)</strong> Derive the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Dual Representation:</b> The KKT stationarity condition $\nabla_w L = 0$ implies $w = \sum \alpha_i y_i x_i$. This shows the optimal weights lie in the span of the data points.</li>
            <li><b>The Kernel Trick:</b> Since the dual objective involves data only through dot products $\langle x_i, x_j \rangle$, we can replace the Euclidean inner product with any valid kernel function $K(x_i, x_j)$, enabling non-linear classification in infinite-dimensional spaces.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Lagrangian.</strong>
            $
            L(w, b, \alpha) = \frac{1}{2} \|w\|_2^2 + \sum_{i=1}^n \alpha_i (1 - y_i (w^\top x_i + b))
            $
            where $\alpha_i \ge 0$ are dual variables.
          </div>

          <div class="proof-step">
            <strong>Part (b): Dual function.</strong> Minimize over $w$ and $b$:
            $
            \nabla_w L = w - \sum_i \alpha_i y_i x_i = 0 \implies w = \sum_i \alpha_i y_i x_i
            $
            $
            \frac{\partial L}{\partial b} = -\sum_i \alpha_i y_i = 0 \implies \sum_i \alpha_i y_i = 0
            $
            Substituting $w = \sum_i \alpha_i y_i x_i$ back:
            $
            \begin{aligned}
            g(\alpha) &= \frac{1}{2} \left\|\sum_i \alpha_i y_i x_i\right\|_2^2 + \sum_i \alpha_i - \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j \\
            &= \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j
            \end{aligned}
            $
          </div>

          <div class="proof-step">
            <strong>Dual problem:</strong>
            $
            \text{maximize} \quad \sum_i \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j
            $
            $
            \text{subject to} \quad \alpha_i \ge 0, \; \sum_i \alpha_i y_i = 0
            $
            This is a QP in $\alpha$, enabling the kernel trick: replace $x_i^\top x_j$ with $K(x_i, x_j)$.
          </div>
        </div>
      </div>

      <!-- Problem 5.7 -->
      <div class="problem">
        <h3>P5.7 ‚Äî Complementary Slackness in Portfolio Optimization</h3>
        <p>Consider the portfolio problem (Lecture 04):</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad x^\top \Sigma x \quad \text{s.t.} \quad \mu^\top x \ge r_{\text{target}}, \; \mathbf{1}^\top x = 1, \; x \ge 0
          $
        </p>
        <p>Suppose at optimality, only asset 3 has $x_3^* = 0$ (all others positive), and the return constraint is active.</p>
        <p><strong>(a)</strong> What can you conclude about the dual variable $\lambda_3$ for constraint $x_3 \ge 0$?</p>
        <p><strong>(b)</strong> What does complementary slackness say about the return constraint?</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Reduced Cost Interpretation:</b> The dual variable for the non-negativity constraint ($x_i \ge 0$) is the "reduced cost". If $x_i^*=0$, then $\lambda_i > 0$ implies that the asset is "too expensive" relative to its risk/return contribution‚Äîinvesting in it would worsen the objective.</li>
            <li><b>Complementary Slackness in Finance:</b> If an asset is not held ($x_i^*=0$), the non-negativity constraint is active. If an asset <i>is</i> held ($x_i^* > 0$), the constraint is inactive, so its shadow price $\lambda_i^*$ must be zero (marginal benefit equals marginal cost).</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): Dual variable $\lambda_3$.</strong> The constraint is $x_3 \ge 0$, or equivalently $-x_3 \le 0$ in standard form. The complementary slackness condition is $\lambda_3 x_3^* = 0$.
            Since $x_3^* = 0$, this condition is trivially satisfied for any $\lambda_3 \ge 0$.
            <br>However, we can infer more from the stationarity condition. The KKT stationarity condition is:
            $$ \nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*) = 0 $$
            For this problem:
            $$ 2(\Sigma x^*)_3 - \nu_{\text{ret}} \mu_3 - \nu_{\text{budget}} \cdot 1 - \lambda_3 = 0 $$
            Solving for $\lambda_3$:
            $$ \lambda_3 = 2(\Sigma x^*)_3 - \nu_{\text{ret}} \mu_3 - \nu_{\text{budget}} $$
            Since $\lambda_3 \ge 0$, this tells us that the marginal benefit of investing in asset 3 (based on return and covariance) is less than or equal to the "shadow price" cost. If $\lambda_3 > 0$, it strictly indicates that the non-negativity constraint is binding and preventing the objective from improving further (i.e., we would want to short-sell asset 3 if allowed).
          </div>

          <div class="proof-step">
            <strong>Part (b): Return constraint.</strong> The return constraint $\mu^\top x \ge r_{\text{target}}$ (or $-\mu^\top x \le -r_{\text{target}}$) is active, meaning $\mu^\top x^* = r_{\text{target}}$. The complementary slackness condition is $\nu_{\text{ret}} (\mu^\top x^* - r_{\text{target}}) = 0$, which is satisfied.
            Typically, if a constraint is active, its associated dual variable $\nu_{\text{ret}}$ is positive ($\nu_{\text{ret}} > 0$), reflecting the "cost" or sensitivity of the optimal value to the return requirement.
          </div>
        </div>
      </div>

      <!-- Problem 5.8 -->
      <div class="problem">
        <h3>P5.8 ‚Äî Entropy Maximization Dual</h3>
        <p>Consider the entropy maximization problem:</p>
        <p style="text-align: center;">
          $
          \text{minimize} \quad \sum_{i=1}^n x_i \log x_i \quad \text{s.t.} \quad Ax = b, \; \mathbf{1}^\top x = 1, \; x > 0
          $
        </p>
        <p>Derive the dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Geometric Programming Connection:</b> The dual of minimizing entropy (or maximizing likelihood) naturally leads to Log-Sum-Exp functions. This connects information theory primal problems to geometric programming duals.</li>
            <li><b>Maximum Entropy Principle:</b> The primal seeks the distribution closest to uniform (max entropy) satisfying moment constraints. The dual finds the parameters of the corresponding exponential family distribution.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Step 1: Conjugate of negative entropy.</strong>
            The objective function is $f_0(x) = \sum x_i \log x_i$. This is separable, so we can find the conjugate of the scalar function $\phi(u) = u \log u$.
            $\phi^*(y) = \sup_{u > 0} (uy - u \log u)$.
            Setting derivative to zero: $y - (\log u + 1) = 0 \implies \log u = y - 1 \implies u = e^{y-1}$.
            Substituting back: $\phi^*(y) = e^{y-1} y - e^{y-1}(y-1) = e^{y-1}(y - y + 1) = e^{y-1}$.
            Thus, $f_0^*(y) = \sum_{i=1}^n e^{y_i - 1}$.
          </div>

          <div class="proof-step">
            <strong>Step 2: Dual Function.</strong>
            The problem has equality constraints $Ax = b$ and $\mathbf{1}^\top x = 1$. Let $\nu \in \mathbb{R}^m$ be dual variables for $Ax=b$ and $\mu \in \mathbb{R}$ for $\mathbf{1}^\top x = 1$.
            The dual function is:
            $$ g(\nu, \mu) = \inf_x \left( f_0(x) + \nu^\top(Ax - b) + \mu(\mathbf{1}^\top x - 1) \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu + \inf_x \left( f_0(x) + (A^\top \nu + \mu \mathbf{1})^\top x \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - \sup_x \left( -(A^\top \nu + \mu \mathbf{1})^\top x - f_0(x) \right) $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - f_0^*(-(A^\top \nu + \mu \mathbf{1})) $$
          </div>

          <div class="proof-step">
            <strong>Step 3: Substitute Conjugate.</strong>
            $$ g(\nu, \mu) = -b^\top \nu - \mu - \sum_{i=1}^n e^{-(A^\top \nu)_i - \mu - 1} $$
            $$ g(\nu, \mu) = -b^\top \nu - \mu - e^{-\mu-1} \sum_{i=1}^n e^{-(A^\top \nu)_i} $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Dual Problem.</strong>
            maximize $g(\nu, \mu)$.
            We can analytically maximize over $\mu$. Let $S(\nu) = \sum_{i=1}^n e^{-(A^\top \nu)_i}$.
            $$ \frac{\partial g}{\partial \mu} = -1 - e^{-\mu-1} S(\nu) \cdot (-1) = -1 + e^{-\mu-1} S(\nu) = 0 $$
            $$ e^{-\mu-1} = \frac{1}{S(\nu)} \implies -\mu-1 = -\log S(\nu) \implies \mu = \log S(\nu) - 1 $$
            Substitute $\mu$ back into $g$:
            $$ g(\nu) = -b^\top \nu - (\log S(\nu) - 1) - \frac{1}{S(\nu)} S(\nu) $$
            $$ g(\nu) = -b^\top \nu - \log S(\nu) + 1 - 1 = -b^\top \nu - \log\left(\sum_{i=1}^n e^{-(A^\top \nu)_i}\right) $$
            The dual problem is:
            $$ \text{maximize} \quad -b^\top \nu - \log\left(\sum_{i=1}^n e^{-a_i^\top \nu}\right) $$
            This is an unconstrained geometric programming dual (Log-Sum-Exp).
          </div>
        </div>
      </div>

      <!-- Problem 5.9 -->
      <div class="problem">
        <h3>P5.9 ‚Äî Derivation of SDP Duality</h3>
        <p>Semidefinite programming (SDP) is a powerful generalization of linear programming. In this problem, you will derive the dual of a standard form SDP.</p>
        <p>Consider the primal SDP:</p>
        $$
        \begin{aligned}
        \text{minimize} \quad & \text{tr}(CX) \\
        \text{subject to} \quad & \text{tr}(A_i X) = b_i, \quad i = 1, \dots, m \\
        & X \succeq 0
        \end{aligned}
        $$
        <p>where $C, A_1, \dots, A_m \in \mathbb{S}^n$ are symmetric matrices, and $X \in \mathbb{S}^n$ is the variable.</p>
        <p><strong>(a)</strong> Form the Lagrangian $L(X, y, S)$ using the trace inner product.</p>
        <p><strong>(b)</strong> Derive the dual function $g(y, S) = \inf_X L(X, y, S)$.</p>
        <p><strong>(c)</strong> State the full dual problem.</p>


      <div class="recap-box" style="background: var(--surface-2); border: 1px dashed var(--primary-300); padding: 16px; border-radius: 8px; margin-bottom: 16px;">
        <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
        <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
            <li><b>Matrix Lagrange Multipliers:</b> For a matrix inequality constraint $X \succeq 0$, the Lagrange multiplier is a matrix $S$ in the dual cone (which is also the PSD cone). The inner product is the trace $\mathrm{tr}(SX)$.</li>
            <li><b>SDP Duality Structure:</b> The standard primal SDP optimizes a linear function of a matrix variable subject to affine constraints. Its dual optimizes a vector variable subject to a Linear Matrix Inequality (LMI). This asymmetry is characteristic of conic duality.</li>
        </ul>
      </div>

<div class="solution">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Part (a): The Lagrangian.</strong>
            We associate dual variables $y \in \mathbb{R}^m$ with the equality constraints $\text{tr}(A_i X) = b_i$.
            We associate a dual matrix variable $S \in \mathbb{S}^n$ with the inequality constraint $X \succeq 0$.
            Note that $X \succeq 0$ is equivalent to $-X \preceq 0$. The generalized Lagrangian term for inequality $G(x) \preceq 0$ with dual variable $\Lambda \succeq 0$ is $\text{tr}(\Lambda^\top G(x))$.
            Here, we use the convention of adding weighted constraints. Since we require $X \succeq 0$, we can view this as a constraint $-X \in \mathbb{S}^n_-$. The term in the Lagrangian is typically subtracted: $-\text{tr}(SX)$ with $S \succeq 0$.
            Alternatively, write the constraints as $b_i - \text{tr}(A_i X) = 0$ and $X \succeq 0$.
            $$ L(X, y, S) = \text{tr}(CX) + \sum_{i=1}^m y_i (b_i - \text{tr}(A_i X)) - \text{tr}(SX) $$
            where $S \succeq 0$.
            Rearranging terms to group by $X$:
            $$ L(X, y, S) = \text{tr}(CX) - \sum_{i=1}^m y_i \text{tr}(A_i X) - \text{tr}(SX) + \sum_{i=1}^m y_i b_i $$
            Using linearity of trace:
            $$ L(X, y, S) = \text{tr}\left( \left( C - \sum_{i=1}^m y_i A_i - S \right) X \right) + b^\top y $$
          </div>

          <div class="proof-step">
            <strong>Part (b): The Dual Function.</strong>
            The dual function is $g(y, S) = \inf_X L(X, y, S)$.
            The Lagrangian is an affine function of $X$.
            $$ L(X, y, S) = \text{tr}(M X) + b^\top y \quad \text{where } M = C - \sum_{i=1}^m y_i A_i - S $$
            We need to minimize $\text{tr}(MX)$ over $X \in \mathbb{S}^n$.
            If $M \neq 0$, we can choose $X = -k M$. Then $\text{tr}(MX) = -k \text{tr}(M^2) = -k \|M\|_F^2$. As $k \to \infty$, this goes to $-\infty$.
            Thus, the infimum is finite only if $M = 0$.
            $$ g(y, S) = \begin{cases} b^\top y & \text{if } C - \sum_{i=1}^m y_i A_i - S = 0 \\ -\infty & \text{otherwise} \end{cases} $$
          </div>

          <div class="proof-step">
            <strong>Part (c): The Dual Problem.</strong>
            We maximize the dual function subject to dual feasibility ($S \succeq 0$).
            $$
            \begin{aligned}
            \text{maximize} \quad & b^\top y \\
            \text{subject to} \quad & C - \sum_{i=1}^m y_i A_i - S = 0 \\
            & S \succeq 0
            \end{aligned}
            $$
            We can eliminate the slack matrix $S$ by writing the equality as an inequality:
            $$ S = C - \sum_{i=1}^m y_i A_i $$
            The constraint $S \succeq 0$ becomes:
            $$ C - \sum_{i=1}^m y_i A_i \succeq 0 \iff \sum_{i=1}^m y_i A_i \preceq C $$
            So the standard dual SDP is:
            $$
            \begin{aligned}
            \text{maximize} \quad & b^\top y \\
            \text{subject to} \quad & \sum_{i=1}^m y_i A_i \preceq C
            \end{aligned}
            $$
          </div>
        </div>
      </div>
    </section>
  </main>

  <!-- Footer -->
  <footer class="site-footer">
    <div class="container">
      <p style="margin: 0;">
        ¬© <span id="year"></a> Convex Optimization Course ¬∑
        <a href="../../README.md" style="color: var(--brand);">About</a>
      </p>
    </div>
  </footer>

  <!-- Load Pyodide for Python widgets (optional) -->
  <script defer src="https://cdn.jsdelivr.net/pyodide/v0.26.4/full/pyodide.js"></script>

  <!-- Widget loaders -->
  <script type="module">
    import { initLagrangianExplainer } from './widgets/js/lagrangian-explainer.js';
    initLagrangianExplainer('widget-1');
  </script>
  <script type="module">
    import { initDualityVisualizer } from './widgets/js/duality-visualizer.js';
    initDualityVisualizer('widget-2');
  </script>
  <script type="module">
    import { initKKTChecker } from './widgets/js/kkt-checker.js';
    initKKTChecker('widget-3');
  </script>
  <script type="module">
    import { initDualityRace } from './widgets/js/duality-race.js';
    initDualityRace('widget-4');
  </script>
  <script type="module">
    import { initShadowPrices } from './widgets/js/shadow-prices.js';
    initShadowPrices('widget-5');
  </script>
  <script type="module">
    import { initComplementarySlacknessExplorer } from './widgets/js/complementary-slackness.js';
    initComplementarySlacknessExplorer('widget-6');
  </script>

  <!-- Global utilities -->
  <script src="../../static/js/math-renderer.js"></script>
<script src="../../static/js/ui.js"></script>
<script src="../../static/js/toc.js"></script>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
