<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>03. Convex Functions: Definitions, Characterizations, and Operations â€” Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/lecture-styles.css" />
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">
          <img src="../../static/assets/branding/logo.svg" alt="Logo" />
          <span>Convex Optimization</span>
        </a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../02-convex-sets/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../04-convex-opt-problems/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header card-v2">
      <h1>03. Convex Functions: Definitions, Characterizations, and Operations</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-04</span>
        <span>Duration: 90 min</span>
        <span>Tags: functions, theory, optimization, characterization</span>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture develops the theory of convex functions, which form the foundation for convex optimization. We present multiple equivalent characterizations (Jensen's inequality, epigraph, first-order conditions, second-order conditions), prove key properties, and establish operations that preserve convexity. The lecture culminates with a comprehensive toolkit for recognizing and constructing convex functions in practice.</p>
        <p><strong>Prerequisites:</strong> <a href="../00-linear-algebra-primer/index.html">Lecture 00: Linear Algebra</a> (gradients, Hessians, eigenvalues) and <a href="../02-convex-sets/index.html">Lecture 02: Convex Sets</a> (convex sets, epigraphs, operations).</p>
        <p><strong>Forward Connections:</strong> Convex functions are the building blocks of convex optimization problems. First-order and second-order conditions lead directly to optimality conditions (Lecture 04-05). Operations preserving convexity enable sophisticated modeling (Lecture 06-07).</p>
      </div>
    </header>

    <section class="card-v2">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <ul>
        <li><b>Master Multiple Characterizations:</b> State and prove equivalences between Jensen's inequality, epigraph convexity, first-order conditions, and second-order conditions.</li>
        <li><b>Apply First-Order Conditions:</b> Use the tangent line property to verify convexity and derive inequalities.</li>
        <li><b>Use Second-Order Conditions:</b> Verify convexity via Hessian positive semidefiniteness.</li>
        <li><b>Understand Strong Convexity:</b> Define strong convexity and explain its importance for convergence rates and uniqueness.</li>
        <li><b>Recognize Convexity-Preserving Operations:</b> Apply nonnegative combinations, compositions, pointwise maxima, and perspective operations to construct complex convex functions.</li>
        <li><b>Master the Conjugate Function:</b> Define the convex conjugate (Fenchel conjugate) and understand its role in duality theory.</li>
        <li><b>Apply Quasi-convexity:</b> Distinguish convex from quasi-convex functions and understand when quasi-convexity suffices for optimization.</li>
      </ul>
    </section>

    <!-- SECTION 1: DEFINITIONS AND EXTENDED VALUES -->
    <section class="card-v2" id="section-1">
      <h2>1. Definitions and Extended Values</h2>

      <h3>1.1 Extended-Value Extension</h3>
      <p>A key trick in convex analysis is to encode constraints directly into the function. Let $f: D \subseteq \mathbb{R}^n \to \mathbb{R}$. We define its <b>extended-value extension</b> $\tilde{f}: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ as:</p>
      $$ \tilde{f}(x) = \begin{cases} f(x) & x \in D \\ +\infty & x \notin D \end{cases} $$
      <p>This allows us to write unconstrained optimization problems $\min \tilde{f}(x)$ that are equivalent to constrained problems $\min_{x \in D} f(x)$.</p>

      <h3>1.2 Definition of Convexity</h3>
      <p>A function $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ is <b>convex</b> if:</p>
      <ol>
        <li>Its domain $\mathrm{dom}\, f = \{x \mid f(x) < +\infty\}$ is a convex set.</li>
        <li>For all $x, y \in \mathrm{dom}\, f$ and $\theta \in [0, 1]$:
          $$ f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta)f(y) $$
        </li>
      </ol>
      <p><b>Strict Convexity:</b> The inequality is strict ($<$) for $x \neq y$ and $\theta \in (0, 1)$.
      <br><b>Concavity:</b> $f$ is concave if $-f$ is convex.</p>

      <h3>1.3 Epigraph Characterization</h3>
      <div class="theorem-box">
        <h4>Theorem: Convexity $\iff$ Convex Epigraph</h4>
        <p>A function $f$ is convex if and only if its <b>epigraph</b> is a convex set:
        $$ \mathrm{epi}\, f = \{ (x, t) \in \mathbb{R}^{n+1} \mid f(x) \le t \} $$
        </p>
      </div>
      <div class="proof-enhanced">
        <h4>Proof</h4>
        <div class="proof-step">
          <strong>($\Rightarrow$)</strong> Assume $f$ convex. Let $(x, t), (y, s) \in \mathrm{epi}\, f$. For $\theta \in [0, 1]$, let $z = \theta x + (1-\theta)y$ and $r = \theta t + (1-\theta)s$.
          $$ f(z) \le \theta f(x) + (1-\theta)f(y) \le \theta t + (1-\theta)s = r $$
          Thus $(z, r) \in \mathrm{epi}\, f$.
        </div>
        <div class="proof-step">
          <strong>($\Leftarrow$)</strong> Assume $\mathrm{epi}\, f$ convex. Let $x, y \in \mathrm{dom}\, f$. Then $(x, f(x))$ and $(y, f(y))$ are in $\mathrm{epi}\, f$.
          By convexity of epi, $(\theta x + (1-\theta)y, \theta f(x) + (1-\theta)f(y)) \in \mathrm{epi}\, f$.
          The definition of epi means $f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta)f(y)$.
        </div>
      </div>

      <div class="widget-container" style="margin: 24px 0;">
        <h3 style="margin-top: 0;">Interactive Inspector: Understanding Convexity</h3>
        <p>Visualize the relationship between Jensen's inequality (chords above graph) and the epigraph.</p>
        <div id="widget-convex-function-inspector" style="width: 100%; position: relative;"></div>
      </div>
    </section>

    <!-- SECTION 2: CONVEXITY TESTS -->
    <section class="card-v2" id="section-2">
      <h2>2. Tests for Convexity</h2>

      <h3>2.1 Restriction to a Line</h3>
      <div class="theorem-box">
        <h4>Theorem: Reduction to 1D</h4>
        <p>$f: \mathbb{R}^n \to \mathbb{R}$ is convex if and only if for all $x \in \mathrm{dom}\, f$ and directions $v$, the function $g(t) = f(x + tv)$ is convex on its domain.</p>
      </div>
      <p>This is the most powerful tool for proving convexity of matrix functions (like $\log \det X$).</p>

      <h3>2.2 First-Order Condition</h3>
      <p>If $f$ is differentiable, $f$ is convex if and only if $\mathrm{dom}\, f$ is convex and:</p>
      $$ f(y) \ge f(x) + \nabla f(x)^\top (y - x) \quad \forall x, y \in \mathrm{dom}\, f $$
      <p><b>Geometric meaning:</b> The first-order Taylor approximation is a <b>global underestimator</b>.</p>

      <h3>2.3 Second-Order Condition</h3>
      <p>If $f$ is twice differentiable, $f$ is convex if and only if $\mathrm{dom}\, f$ is convex and:</p>
      $$ \nabla^2 f(x) \succeq 0 \quad \text{(Hessian is Positive Semidefinite)} $$
      <p>for all $x \in \mathrm{dom}\, f$.
      <br><b>Strict convexity:</b> $\nabla^2 f(x) \succ 0$ implies strict convexity (but converse is false, e.g., $x^4$).
      <br><b>Strong convexity:</b> $\nabla^2 f(x) \succeq mI$ for $m > 0$.</p>

      <div class="widget-container" style="margin: 24px 0;">
        <h3 style="margin-top: 0;">Interactive: Hessian Eigenvalue Map</h3>
        <p>Explore regions where the Hessian is PSD (convex) vs. indefinite (saddle/concave).</p>
        <div id="widget-hessian-heatmap" style="width: 100%; height: 450px; position: relative;"></div>
      </div>
    </section>

    <!-- SECTION 3: OPERATIONS PRESERVING CONVEXITY -->
    <section class="card-v2" id="section-3">
      <h2>3. Operations Preserving Convexity</h2>

      <p>Complex convex functions are built from simple "atoms" using these rules (the "calculus of convexity").</p>

      <h3>3.1 Nonnegative Weighted Sum</h3>
      <p>$f = \sum \alpha_i f_i$ is convex if $f_i$ are convex and $\alpha_i \ge 0$. (Includes integrals/expectations).</p>

      <h3>3.2 Composition with Affine Mapping</h3>
      <p>$g(x) = f(Ax + b)$ is convex if $f$ is convex.
      <br><i>Example:</i> $\|Ax - b\|^2$ is convex.</p>

      <h3>3.3 Pointwise Maximum and Supremum</h3>
      <p>$f(x) = \sup_{y \in \mathcal{A}} g(x, y)$ is convex if $g(x, y)$ is convex in $x$ for each $y$.
      <br><i>Example:</i> $\lambda_{\max}(X) = \sup_{\|v\|=1} v^\top X v$ is convex (sup of linear functions).</p>

      <h3>3.4 Scalar Composition</h3>
      <p>$f(x) = h(g(x))$ is convex if:</p>
      <ul>
        <li>$g$ convex, $h$ convex & nondecreasing. (e.g., $e^{g(x)}$)</li>
        <li>$g$ concave, $h$ convex & nonincreasing. (e.g., $1/g(x)$ for $g > 0$)</li>
      </ul>

      <h3>3.5 Vector Composition</h3>
      <p>$f(x) = h(g_1(x), \dots, g_k(x))$ is convex if $h$ is convex and nondecreasing in each argument, and $g_i$ are convex. (e.g., $\log \sum e^{g_i(x)}$).</p>

      <h3>3.6 Minimization (Partial Infimum)</h3>
      <p>$g(x) = \inf_{y \in C} f(x, y)$ is convex if $f(x, y)$ is jointly convex in $(x, y)$ and $C$ is a convex set.
      <br><i>Example:</i> Distance to a convex set $d(x, C) = \inf_{y \in C} \|x - y\|$.</p>

      <h3>3.7 Perspective Transform</h3>
      <p>If $f$ is convex, its perspective $g(x, t) = t f(x/t)$ (for $t > 0$) is convex.
      <br><i>Example:</i> $f(x) = x^\top x \implies g(x, t) = x^\top x / t$ (quadratic-over-linear).</p>

      <div class="widget-container" style="margin: 24px 0;">
        <h3 style="margin-top: 0;">Interactive Builder: Constructing Convex Functions</h3>
        <p>Verify convexity rules by combining functions.</p>
        <div id="widget-operations-preserving" style="width: 100%; height: 500px; position: relative;"></div>
      </div>
    </section>

    <!-- SECTION 4: CANONICAL EXAMPLES -->
    <section class="card-v2" id="section-4">
      <h2>4. Canonical Examples (Zero to Hero)</h2>

      <h3>A) Log-Sum-Exp (LSE)</h3>
      <p>$\mathrm{LSE}(x) = \log(\sum_{i=1}^n e^{x_i})$.</p>
      <div class="proof-enhanced">
        <h4>Proof of Convexity (Hessian Test)</h4>
        <p>Gradient: $\nabla f(x)_i = \frac{e^{x_i}}{\sum e^{x_k}} = p_i$ (softmax vector).</p>
        <p>Hessian: $\nabla^2 f(x) = \mathrm{diag}(p) - pp^\top$.</p>
        <p>For any $v$: $v^\top \nabla^2 f v = \sum p_i v_i^2 - (\sum p_i v_i)^2$.
        Since $\sum p_i = 1, p_i > 0$, this is $\mathbb{E}[V^2] - (\mathbb{E}[V])^2 = \mathrm{Var}(V) \ge 0$.
        Thus Hessian is PSD $\implies$ LSE is convex.</p>
      </div>

      <h3>B) Geometric Mean</h3>
      <p>$G(x) = (\prod_{i=1}^n x_i)^{1/n}$ on $\mathbb{R}_{++}^n$.</p>
      <div class="proof-enhanced">
        <h4>Proof of Concavity</h4>
        <p>$\log G(x) = \frac{1}{n} \sum \log x_i$ is concave (sum of concave logs).
        Since $G$ is <b>log-concave</b> and homogeneous of degree 1, it is concave.
        Alternatively, check Hessian: $v^\top \nabla^2 G v \propto (\sum v_i/x_i)^2 - n \sum (v_i/x_i)^2 \le 0$ by Cauchy-Schwarz.</p>
      </div>

      <h3>C) Quadratic-Over-Linear</h3>
      <p>$f(x, y) = x^2 / y$ for $y > 0$. Convex via perspective of $x^2$. Generalizes to $x^\top x / y$.</p>

      <h3>D) Matrix Fractional Function</h3>
      <p>$f(x, Y) = x^\top Y^{-1} x$ for $Y \in \mathbb{S}_{++}^n$.</p>
      <div class="proof-enhanced">
        <h4>Proof of Convexity (Epigraph)</h4>
        <p>Epigraph: $x^\top Y^{-1} x \le t, Y \succ 0$.
        By Schur Complement:
        $$ \begin{bmatrix} Y & x \\ x^\top & t \end{bmatrix} \succeq 0 $$
        This is a Linear Matrix Inequality (LMI), which defines a convex set. Thus $f$ is convex.</p>
      </div>

      <h3>E) Log-Determinant</h3>
      <p>$f(X) = \log \det X$ on $\mathbb{S}_{++}^n$.</p>
      <div class="proof-enhanced">
        <h4>Proof of Concavity (Line Restriction)</h4>
        <p>Let $Z(t) = X + tV$. $g(t) = \log \det Z(t)$.
        $$ g'(t) = \mathrm{tr}(Z(t)^{-1}V) $$
        $$ g''(t) = -\mathrm{tr}(Z(t)^{-1} V Z(t)^{-1} V) = -\|Z(t)^{-1/2} V Z(t)^{-1/2}\|_F^2 \le 0 $$
        Since $g''(t) \le 0$ for all lines, $f(X)$ is concave.</p>
      </div>
    </section>

    <!-- SECTION 5: CONJUGATE AND DUALITY -->
    <section class="card-v2" id="section-5">
      <h2>5. Convex Conjugate</h2>

      <p>The conjugate $f^*(y) = \sup_x (y^\top x - f(x))$ is always convex (sup of affine functions).</p>
      <ul>
        <li><b>Negative Entropy:</b> $f(x) = x \log x \implies f^*(y) = e^{y-1}$.</li>
        <li><b>Log-Sum-Exp:</b> $f(x) = \mathrm{LSE}(x) \implies f^*(y)$ is negative entropy on simplex.</li>
        <li><b>Quadratic:</b> $f(x) = \frac{1}{2}x^\top Q x \implies f^*(y) = \frac{1}{2}y^\top Q^{-1} y$.</li>
        <li><b>Norm:</b> $f(x) = \|x\| \implies f^*(y) = I_{\|y\|_* \le 1}$ (indicator of dual ball).</li>
      </ul>
    </section>

    <!-- SECTION 6: QUASI-CONVEX FUNCTIONS -->
    <section class="card-v2" id="section-6-quasi">
      <h2>6. Quasi-Convex Functions</h2>

      <h3>6.1 Definition</h3>
      <p>A function $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ is <b>quasi-convex</b> if its domain is convex and all its <b>sublevel sets</b> are convex:</p>
      $$ S_\alpha = \{x \in \mathrm{dom}\, f \mid f(x) \le \alpha\} $$
      <p>is a convex set for all $\alpha \in \mathbb{R}$.</p>
      <p><b>Quasi-concave:</b> $f$ is quasi-concave if $-f$ is quasi-convex (equivalently, all superlevel sets $\{x \mid f(x) \ge \alpha\}$ are convex).</p>
      <p><b>Quasilinear:</b> $f$ is quasilinear if it is both quasi-convex and quasi-concave (i.e., all sublevel and superlevel sets are convex).</p>

      <div class="insight">
        <h4>ðŸ’¡ Intuition</h4>
        <p>Quasi-convexity is a weaker property than convexity. It means the function has "convex contour lines" (unimodal along lines) but doesn't require the graph to curve upward everywhere. Optimization of quasi-convex functions can be done via bisection on the optimal value.</p>
      </div>

      <h3>6.2 Characterization via Jensen-like Inequality</h3>
      <p>$f$ is quasi-convex if and only if for all $x, y \in \mathrm{dom}\, f$ and $\theta \in [0, 1]$:</p>
      $$ f(\theta x + (1-\theta)y) \le \max\{f(x), f(y)\} $$
      <p>(Compare to convexity: $f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta)f(y)$.)</p>

      <h3>6.3 Canonical Examples</h3>
      <div class="example">
        <h4>1. Linear-Fractional Functions</h4>
        <p>Let $f(x) = \frac{a^\top x + b}{c^\top x + d}$ with domain $\{x \mid c^\top x + d > 0\}$.</p>
        <p><b>Claim:</b> $f$ is quasilinear.</p>
        <p><i>Proof:</i> The sublevel set $\{x \mid \frac{a^\top x + b}{c^\top x + d} \le \alpha\}$ is equivalent to $\{x \mid a^\top x + b \le \alpha(c^\top x + d)\}$ (since denominator > 0). This defines a halfspace, which is convex. Similarly for superlevel sets.</p>
      </div>

      <div class="example">
        <h4>2. Distance Ratio</h4>
        <p>$f(x) = \frac{\|x - a\|_2}{\|x - b\|_2}$ is quasi-convex on $\{x \mid \|x - b\|_2 > 0\}$. The sublevel sets are Apollonius circles (convex balls).</p>
      </div>

      <div class="example">
        <h4>3. Product on Orthant</h4>
        <p>$f(x_1, x_2) = x_1 x_2$ on $\mathbb{R}_{++}^2$. This function is <b>quasi-concave</b>.</p>
        <p><i>Proof:</i> Superlevel sets are $\{x \in \mathbb{R}_{++}^2 \mid x_1 x_2 \ge \alpha\} = \{x \mid x_2 \ge \alpha/x_1\}$. Since $h(u) = \alpha/u$ is convex for $u > 0$, the set above the graph (epigraph) is convex.</p>
      </div>
    </section>

    <!-- SECTION 7: WORKED PROBLEMS -->
    <section class="card-v2" id="section-7">
      <h2>7. Worked Problems</h2>

      <div class="problem">
        <h3>Problem 3.1: Jensen's Inequality Properties</h3>
        <p><b>(a)</b> Prove $f(x) \le \frac{b-x}{b-a}f(a) + \frac{x-a}{b-a}f(b)$ for $x \in [a, b]$.
        <br><i>Solution:</i> This is the definition of convexity with $\theta = \frac{b-x}{b-a}$.</p>
      </div>

      <div class="problem">
        <h3>Problem 3.18: Matrix Convexity</h3>
        <p><b>(a)</b> Prove $\mathrm{tr}(X^{-1})$ is convex on $\mathbb{S}_{++}^n$.
        <br><i>Solution:</i> Line restriction $g(t) = \mathrm{tr}((X+tV)^{-1})$. $g''(t) = 2 \mathrm{tr}(Z^{-1} V Z^{-1} V Z^{-1})$. Since $Z^{-1}$ and $V Z^{-1} V$ are PSD (or using cyclic trace to form norms), trace is positive.
        <br><b>(b)</b> Prove $(\det X)^{1/n}$ is concave.
        <br><i>Solution:</i> See Section 4B (Geometric Mean of eigenvalues).</p>
      </div>

      <div class="problem">
        <h3>Problem 3.20: Composition Examples</h3>
        <p><b>(a)</b> $\|Ax - b\|$ is convex (Norm $\circ$ Affine).
        <br><b>(b)</b> $-\log \det (A_0 + x_1 A_1 + \dots)$ is convex (Log-det $\circ$ Affine).</p>
      </div>
    </section>

    <footer class="site-footer">
      <div class="container">
        <p>Â© <span id="year"></span> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/theme-switcher.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- Widget Loaders -->
  <script type="module">
    import { initConvexFunctionInspector } from './widgets/js/convex-function-inspector.js';
    initConvexFunctionInspector('widget-convex-function-inspector');
  </script>
  <script type="module">
    import { initHessianHeatmap } from './widgets/js/hessian-heatmap.js';
    initHessianHeatmap('widget-hessian-heatmap');
  </script>
  <script type="module">
    import { initOperationsPreserving } from './widgets/js/operations-preserving.js';
    initOperationsPreserving('widget-operations-preserving');
  </script>
</body>
</html>
